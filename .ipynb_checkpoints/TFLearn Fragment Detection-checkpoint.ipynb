{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLearn Fragment Detection\n",
    "\n",
    "Catherine has prepared datafiles with sentences turned into fragments. I will use as input 60,000 fragments and 60,000 sentences. The fragments will come from the sentences. In the future the fragments will not be descendants of the input sentences. The labels will be either a 1 or 0, where 1 indicates a sentence and 0 indicates a fragment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import re\n",
    "from nltk.util import ngrams, trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['With 92% of dawson creek residents canadian-born, and 93% speaking only english, the city has few visible minorities.', 'With 92% of Dawson Creek residents being Canadian-born, and 93% speaking only English, the city has few visible minorities.', 'By the end of the year, the texians all mexican troops from texas.', 'By the end of the year, the Texians had driven all Mexican troops from Texas.', 'In northern manitoba, quartz to make arrowheads.', 'In Northern Manitoba, quartz was mined to make arrowheads.', 'There significant fictionalisation, however.', 'There was significant fictionalisation, however.', \"Extremeolation from society and community also apparent in crane's work.\", \"Extreme isolation from society and community is also apparent in Crane's work.\"]\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open(\"./removingPOS/updatedSentences/conjunctionSentences/detailedRemoval.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        asArray = line.split(\" ||| \")\n",
    "        fragment = asArray[2].strip()\n",
    "        fragment = re.sub(\"\\ \\.\", \".\", fragment)\n",
    "        fragment = re.sub(\"\\,\\.\", \".\", fragment)\n",
    "        texts.append(fragment.capitalize())\n",
    "        labels.append(0)\n",
    "        texts.append(asArray[0].strip())\n",
    "        labels.append(1)\n",
    "        \n",
    "with open(\"./removingPOS/updatedSentences/nounSentences/detailedRemoval.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        asArray = line.split(\" ||| \")\n",
    "        fragment = asArray[2].strip()\n",
    "        fragment = re.sub(\"\\ \\.\", \".\", fragment)\n",
    "        fragment = re.sub(\"\\,\\.\", \".\", fragment)\n",
    "        texts.append(fragment.capitalize())\n",
    "        labels.append(0)\n",
    "        texts.append(asArray[0].strip())\n",
    "        labels.append(1)\n",
    "\n",
    "with open(\"./removingPOS/updatedSentences/nounverbSentences/detailedRemoval.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        asArray = line.split(\" ||| \")\n",
    "        fragment = asArray[2].strip()\n",
    "        fragment = re.sub(\"\\ \\.\", \".\", fragment)\n",
    "        fragment = re.sub(\"\\,\\.\", \".\", fragment)\n",
    "        texts.append(fragment.capitalize())\n",
    "        labels.append(0)\n",
    "        texts.append(asArray[0].strip())\n",
    "        labels.append(1)\n",
    "        \n",
    "with open(\"./removingPOS/updatedSentences/verbSentences/detailedRemoval.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "        asArray = line.split(\" ||| \")\n",
    "        fragment = asArray[2].strip()\n",
    "        fragment = re.sub(\"\\ \\.\", \".\", fragment)\n",
    "        fragment = re.sub(\"\\,\\.\", \".\", fragment)\n",
    "        texts.append(fragment.capitalize())\n",
    "        labels.append(0)\n",
    "        texts.append(asArray[0].strip())\n",
    "        labels.append(1)\n",
    "        \n",
    "print(texts[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"An archetypal, it generally close to the facts of sheppard's life, but portrays him as a swashbuckling hero.\", 'In 2005, president kagame also launched a program known.', 'Only in late the bill finalized and forwarded to the senate for consideration.', 'Ashmole met the botanist and collector John Tradescant the younger around 1650.', 'City-to-city relationships communities and special interest groups both locally and abroad to engage in a wide range of exchange activities.', 'They arrived on 14 May.', 'Gained prestige as the oxford of the east in its early years.', 'Laffoon vigorously defended the commissions he had issued and those issued by his predecessors.', 'To the air force permanent in 1928.', 'Unable to return home immediately, Chrisye became distracted by thoughts of his family and began to find playing difficult.']\n",
      "[0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "combined = list(zip(texts,labels))\n",
    "random.shuffle(combined)\n",
    "\n",
    "texts[:], labels[:] = zip(*combined)\n",
    "print(texts[-10:])\n",
    "print(labels[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get parts of speech for text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADV',\n",
       " 'PUNCT',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'NUM',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'NOUN',\n",
       " 'CONJ',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def textStringToPOSArray(text):\n",
    "    doc = nlp(text)\n",
    "    tags = []\n",
    "    for word in doc:\n",
    "        tags.append(word.pos_)\n",
    "    return tags\n",
    "\n",
    "textStringToPOSArray(texts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get POS trigrams for a text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  However, in February 1969 she collapsed with exhaustion and was hospitalised. 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ADV', 'PUNCT', 'ADP'),\n",
       " ('PUNCT', 'ADP', 'PROPN'),\n",
       " ('ADP', 'PROPN', 'NUM'),\n",
       " ('PROPN', 'NUM', 'PRON'),\n",
       " ('NUM', 'PRON', 'VERB'),\n",
       " ('PRON', 'VERB', 'ADP'),\n",
       " ('VERB', 'ADP', 'NOUN'),\n",
       " ('ADP', 'NOUN', 'CONJ'),\n",
       " ('NOUN', 'CONJ', 'VERB'),\n",
       " ('CONJ', 'VERB', 'VERB'),\n",
       " ('VERB', 'VERB', 'PUNCT')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "  return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def getPOSTrigramsForTextString(text):\n",
    "    tags = textStringToPOSArray(text)\n",
    "    tgrams = list(trigrams(tags))\n",
    "    return tgrams\n",
    "\n",
    "print(\"Text: \", texts[3], labels[3])\n",
    "getPOSTrigramsForTextString(texts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turn Trigrams into Dict keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the war Flamininus visited the Nemean Games in Argos and proclaimed the polis free.\n",
      "['ADP>DET>NOUN', 'DET>NOUN>PROPN', 'NOUN>PROPN>VERB', 'PROPN>VERB>DET', 'VERB>DET>PROPN', 'DET>PROPN>PROPN', 'PROPN>PROPN>ADP', 'PROPN>ADP>PROPN', 'ADP>PROPN>CONJ', 'PROPN>CONJ>VERB', 'CONJ>VERB>DET', 'VERB>DET>NOUN', 'DET>NOUN>ADJ', 'NOUN>ADJ>PUNCT']\n"
     ]
    }
   ],
   "source": [
    "def trigramsToDictKeys(trigrams):\n",
    "    keys = []\n",
    "    for trigram in trigrams:\n",
    "        keys.append('>'.join(trigram))\n",
    "    return keys\n",
    "\n",
    "print(texts[2])\n",
    "print(trigramsToDictKeys(getPOSTrigramsForTextString(texts[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()\n",
    "\n",
    "for textString in texts:\n",
    "    c.update(trigramsToDictKeys(getPOSTrigramsForTextString(textString)))\n",
    "\n",
    "total_counts = c\n",
    "\n",
    "print(\"Total words in data set: \", len(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = sorted(total_counts, key=total_counts.get, reverse=True)[:10000]\n",
    "print(vocab[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
