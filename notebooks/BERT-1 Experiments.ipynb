{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First BERT Experiments\n",
    "\n",
    "In this notebook we do some first experiments with BERT: we finetune a BERT model+classifier on each of our datasets separately and compute the accuracy of the resulting classifier on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these experiments we use the `pytorch_transformers` package. It contains a variety of neural network architectures for transfer learning and pretrained models, including BERT and XLNET.\n",
    "\n",
    "Two different BERT models are relevant for our experiments: \n",
    "\n",
    "- BERT-base-uncased: a relatively small BERT model that should already give reasonable results,\n",
    "- BERT-large-uncased: a larger model for real state-of-the-art results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "from pytorch_transformers.modeling_bert import BertForSequenceClassification\n",
    "\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16 if \"base\" in BERT_MODEL else 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 1 if \"base\" in BERT_MODEL else 8\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the same data as for all our previous experiments. Here we load the training, development and test data for a particular prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import glob\n",
    "\n",
    "prefix = \"junkfood_but\"\n",
    "train_file = f\"../data/interim/{prefix}_train_withprompt_diverse200.ndjson\"\n",
    "synth_files = glob.glob(f\"../data/interim/{prefix}_train_withprompt_*.ndjson\")\n",
    "dev_file = f\"../data/interim/{prefix}_dev_withprompt.ndjson\"\n",
    "test_file = f\"../data/interim/{prefix}_test_withprompt.ndjson\"\n",
    "\n",
    "with open(train_file) as i:\n",
    "    train_data = ndjson.load(i)\n",
    "\n",
    "synth_data = []\n",
    "for f in synth_files:\n",
    "    if \"allsynth\" in f:\n",
    "        continue\n",
    "    with open(f) as i:\n",
    "        synth_data += ndjson.load(i)\n",
    "    \n",
    "with open(dev_file) as i:\n",
    "    dev_data = ndjson.load(i)\n",
    "    \n",
    "with open(test_file) as i:\n",
    "    test_data = ndjson.load(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the label vocabulary, which maps every label in the training data to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Schools providing healthy alternatives': 0, 'Students without choice': 1, 'Schools generate money': 2, 'Student choice': 3, 'Students can still bring/access junk food': 4, 'Unclassified Off-Topic': 5, 'School without generating money': 6}\n",
      "{0: 'Schools providing healthy alternatives', 1: 'Students without choice', 2: 'Schools generate money', 3: 'Student choice', 4: 'Students can still bring/access junk food', 5: 'Unclassified Off-Topic', 6: 'School without generating money'}\n"
     ]
    }
   ],
   "source": [
    "label2idx = {}\n",
    "idx2label = {}\n",
    "target_names = []\n",
    "for item in train_data:\n",
    "    if item[\"label\"] not in label2idx:\n",
    "        target_names.append(item[\"label\"])\n",
    "        idx = len(label2idx)\n",
    "        label2idx[item[\"label\"]] = idx\n",
    "        idx2label[idx] = item[\"label\"]\n",
    "    \n",
    "print(label2idx)\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 200\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample(train_data, synth_data, label2idx, number):\n",
    "    \"\"\"Sample a fixed number of items from every label from\n",
    "    the training data and test data.\n",
    "    \"\"\"\n",
    "    new_train_data = []\n",
    "    for label in label2idx:\n",
    "        data_for_label = [i for i in train_data if i[\"label\"] == label]\n",
    "        \n",
    "        # If there is more training data than the required number,\n",
    "        # take a random sample of n examples from the training data.\n",
    "        if len(data_for_label) >= number:\n",
    "            random.shuffle(data_for_label)\n",
    "            new_train_data += data_for_label[:number]\n",
    "            \n",
    "        # If there is less training data than the required number,\n",
    "        # combine training data with synthetic data.\n",
    "        elif len(data_for_label) < number:\n",
    "            \n",
    "            # Automatically add all training data\n",
    "            new_train_data += data_for_label\n",
    "            \n",
    "            # Compute the required number of additional data\n",
    "            rest = number-len(data_for_label)\n",
    "            \n",
    "            # Collect the synthetic data for the label\n",
    "            synth_data_for_label = [i for i in synth_data if i[\"label\"] == label]\n",
    "            \n",
    "            # If there is more synthetic data than required, \n",
    "            # take a random sample from the synthetic data.\n",
    "            if len(synth_data_for_label) > rest:\n",
    "                random.shuffle(synth_data_for_label)\n",
    "                new_train_data += synth_data_for_label[:rest]\n",
    "            # If there is less synthetic data than required,\n",
    "            # sample with replacement from this data until we have\n",
    "            # the required number.\n",
    "            else:\n",
    "                new_train_data += random.choices(synth_data_for_label, k=rest)\n",
    "        \n",
    "    return new_train_data\n",
    "\n",
    "\n",
    "def random_sample(train_data, train_size):\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[:train_size]\n",
    "    return train_data\n",
    "\n",
    "#train_data = train_data + synth_data\n",
    "#train_data = sample(train_data, synth_data, label2idx, 200)\n",
    "#train_data = random_sample(train_data, 200)\n",
    "print(\"Train data size:\", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We load the pretrained model and put it on a GPU if one is available. We also put the model in \"training\" mode, so that we can correctly update its internal parameters on the basis of our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=len(label2idx))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We preprocess the data by turning every example to an `InputFeatures` item. This item has all the attributes we need for finetuning BERT: \n",
    "\n",
    "- input ids: the ids of the tokens in the text\n",
    "- input mask: tells BERT what part of the input it should not look at (such as padding tokens)\n",
    "- segment ids: tells BERT what segment every token belongs to. BERT can take two different segments as input\n",
    "- label id: the id of this item's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/22/2019 13:54:23 - INFO - __main__ -   *** Example ***\n",
      "08/22/2019 13:54:23 - INFO - __main__ -   text: Schools should not allow junk food to be sold on campus but kids will still bring in unhealthy food\n",
      "08/22/2019 13:54:23 - INFO - __main__ -   input_ids: 101 2816 2323 2025 3499 18015 2833 2000 2022 2853 2006 3721 2021 4268 2097 2145 3288 1999 4895 20192 24658 2100 2833 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/22/2019 13:54:23 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/22/2019 13:54:23 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/22/2019 13:54:23 - INFO - __main__ -   label:Students without choice id: 1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MAX_SEQ_LENGTH=100\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_features(examples, label2idx, max_seq_length, tokenizer, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    features = []\n",
    "    for (ex_index, ex) in enumerate(examples):\n",
    "        \n",
    "        # TODO: should deal better with sentences > max tok length\n",
    "        input_ids = tokenizer.encode(\"[CLS] \" + ex[\"text\"] + \" [SEP]\")\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "            \n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[ex[\"label\"]]\n",
    "        if verbose and ex_index == 0:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"text: %s\" % ex[\"text\"])\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label:\" + str(ex[\"label\"]) + \" id: \" + str(label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features\n",
    "\n",
    "train_features = convert_examples_to_features(train_data, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n",
    "dev_features = convert_examples_to_features(dev_data, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = convert_examples_to_features(test_data, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize data loaders for each of our data sets. These data loaders present the data for training (for example, by grouping them into batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "dev_dataloader = get_data_loader(dev_features, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Our evaluation method takes a pretrained model and a dataloader. It has the model predict the labels for the items in the data loader, and returns the loss, the correct labels, and the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, verbose=False):\n",
    "\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "                    \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Let's prepare the training. We set the training parameters and choose an optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n",
    "\n",
    "num_train_steps = int(len(train_data) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=100, t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual training. In each epoch, we present the model with all training data and compute the loss on the training set and the development set. We save the model whenever the development loss improves. We end training when we haven't seen an improvement of the development loss for a specific number of epochs (the patience). \n",
    "\n",
    "Optionally, we use gradient accumulation to accumulate the gradient for several training steps. This is useful when we want to use a larger batch size than our current GPU allows us to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e4452c2e3048ed9f51a109bd3a2032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3125c0c4a5824b32adbd870957e4204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: []\n",
      "Dev loss: 1.6989148616790772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [00:03<01:09,  3.65s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1f451ca558458ca8ff5ea48870f583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404e30e13c5f444b8d19a229a4336901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772]\n",
      "Dev loss: 1.4327359676361084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [00:07<01:04,  3.59s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91aee7c482f244ba9345f40435029bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228d752cef6046f3933056fd3958c106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084]\n",
      "Dev loss: 1.1781285524368286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [00:10<01:00,  3.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e61e76ebeed4f13bfc1511e55615900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952f781be5cc47bf80e04828d65f4a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286]\n",
      "Dev loss: 0.9835451960563659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [00:13<00:56,  3.51s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cb8f163447440ca2ab23fb950800b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaab24153e064ad8861a71352e72c6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659]\n",
      "Dev loss: 0.8797368884086609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [00:17<00:52,  3.49s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7e61ccc0c648cf8882bb0a66c879ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc8e388763f4516a7802db388db07c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609]\n",
      "Dev loss: 0.8484503865242005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [00:20<00:48,  3.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c315d65189e4e05a667dda1478b42bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594bd1adf12645998bc7a5ab7bc9a5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005]\n",
      "Dev loss: 0.694582176208496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [00:24<00:45,  3.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1c3858ccef42ef80afd8c0d378a5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd34f1d9c5246d586dfcebafb43e53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496]\n",
      "Dev loss: 0.5676077306270599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [00:27<00:41,  3.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e2d4f149e04ef58afbe3e60d2edf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7249f96a955e45ec91ecce1fadc98797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599]\n",
      "Dev loss: 0.5432976514101029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [00:31<00:38,  3.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1541e68c9323455b81b6549d737aff3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd0e46f1b0f4619902abc8b13b4d091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029]\n",
      "Dev loss: 0.5378826707601547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [00:34<00:34,  3.45s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa1f92ce212497ea43697a9e8388972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0304d8fd1767413eb4fa7e4477e775ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [00:37<00:29,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547]\n",
      "Dev loss: 0.5682449221611023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d132b5a2be4b2d8da6aa456f040e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1844d59e664a81ac775fc99fb889a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [00:40<00:25,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023]\n",
      "Dev loss: 0.5825568020343781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12b6218229147b790f25934588970f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2851282d2d4f909541ed7afed677de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [00:43<00:21,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781]\n",
      "Dev loss: 0.5587857842445374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade14bfd13d2466eade7975b6c15a314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb2b13d85fd4722b1efb681c6657b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [00:46<00:18,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374]\n",
      "Dev loss: 0.5714442491531372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e249f5a3ba4cb69b9eef6783928375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fe33b559154b1780c161d94248cfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372]\n",
      "Dev loss: 0.5115815937519074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 15/20 [00:49<00:16,  3.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2270a9be57b344ccba63750a3b4db31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b6c62d345645a982b5120a05ad0fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 16/20 [00:52<00:12,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372, 0.5115815937519074]\n",
      "Dev loss: 0.5132488235831261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01ff5fd2cc1404bbb7a2f409f58665d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21eee4d5139462dbb3d7c4fc6a908f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|████████▌ | 17/20 [00:55<00:09,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372, 0.5115815937519074, 0.5132488235831261]\n",
      "Dev loss: 0.6706602990627288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f441450c90f452bab573a6c2baa7bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37130709ca1c49f692e5538917a9cb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 18/20 [00:58<00:06,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372, 0.5115815937519074, 0.5132488235831261, 0.6706602990627288]\n",
      "Dev loss: 0.6222926080226898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4731ce1e0374f98892f68ae3b91a62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0e6086734d437da61be6c9d14fd8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████▌| 19/20 [01:01<00:03,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372, 0.5115815937519074, 0.5132488235831261, 0.6706602990627288, 0.6222926080226898]\n",
      "Dev loss: 0.5124190628528595\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e6f010a3614fe2b80c98aa9223c9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=13, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4c8f99fb344074a4f1348bd6d2565a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.6989148616790772, 1.4327359676361084, 1.1781285524368286, 0.9835451960563659, 0.8797368884086609, 0.8484503865242005, 0.694582176208496, 0.5676077306270599, 0.5432976514101029, 0.5378826707601547, 0.5682449221611023, 0.5825568020343781, 0.5587857842445374, 0.5714442491531372, 0.5115815937519074, 0.5132488235831261, 0.6706602990627288, 0.6222926080226898, 0.5124190628528595]\n",
      "Dev loss: 0.5342526018619538\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"/tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "PATIENCE = 5\n",
    "\n",
    "global_step = 0\n",
    "model.train()\n",
    "loss_history = []\n",
    "best_epoch = 0\n",
    "for epoch in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        outputs = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            lr_this_step = LEARNING_RATE * warmup_linear(global_step/num_train_steps, WARMUP_PROPORTION)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    dev_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"Dev loss:\", dev_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or dev_loss < min(loss_history):\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    if epoch-best_epoch >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    loss_history.append(dev_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We load the pretrained model, set it to evaluation mode and compute its performance on the training, development and test set. We print out an evaluation report for the test set.\n",
    "\n",
    "Note that different runs will give slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /tmp/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/22/2019 13:55:29 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/yves/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "08/22/2019 13:55:29 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 7,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "08/22/2019 13:55:30 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/yves/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173b3b77537441f6aaf985859dfe771f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=10, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test performance: (0.7581699346405228, 0.7581699346405228, 0.7581699346405228, None)\n",
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "   Schools providing healthy alternatives       0.91      0.93      0.92        75\n",
      "                  Students without choice       0.70      0.64      0.67        33\n",
      "                   Schools generate money       0.89      1.00      0.94         8\n",
      "                           Student choice       0.43      0.86      0.57         7\n",
      "Students can still bring/access junk food       0.00      0.00      0.00         3\n",
      "                   Unclassified Off-Topic       0.42      0.45      0.43        11\n",
      "          School without generating money       0.55      0.38      0.44        16\n",
      "\n",
      "                              avg / total       0.75      0.76      0.75       153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model from\", output_model_file)\n",
    "device=\"cpu\"\n",
    "\n",
    "model_state_dict = torch.load(output_model_file, map_location=lambda storage, loc: storage)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "#_, dev_correct, dev_predicted = evaluate(model, dev_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader, verbose=True)\n",
    "\n",
    "#print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
    "#print(\"Development performance:\", precision_recall_fscore_support(dev_correct, dev_predicted, average=\"micro\"))\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schools should not allow junk food to be sold on campus but kids will still bring in unhealthy food#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but some think students should be able to choose what they eat#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but maybe on certain special occasions or at events#Unclassified Off-Topic#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but students may bring it anyway#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but they can choose to sell food that are nutritious and healthy#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but ultimately it is up to the individual student what they eat or drink#Students without choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but should provide healthier choices#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but Can sell healthier options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but familes should have a say in what their kids eat#Students without choice#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but there should be alternatives they sell#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but students should be allowed to bring it to school#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but they could sell healthy options elsewhere#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should have treats on special days#Students without choice#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they could just have a small amount of it instead of the amount they have been selling at#School without generating money#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but they should inform the students as to why#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but serious consideration must be made in choosing replacements for it#Schools providing healthy alternatives#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but it is good to have a balance of healthy and junk food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should also incorporate greater amounts of exercise into the school day#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but allow them to take it with them to school if they so wish#School without generating money#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should provide healthy, nutritious food instead#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but kids are fond of junk foods#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but schools make a sizable profit by selling junk food items in vending machines#School without generating money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but they have to get an incentive to stop offering it#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but can offer healthy food choices in vending machines#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but I can see how the schools want to give the kids a choice#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but in the long run, a person's health choices are personal, and government institutions should not be able to dictate such choices#Unclassified Off-Topic#Student choice\n",
      "Schools should not allow junk food to be sold on campus but parents should also provide education and rules at home around food choices#Unclassified Off-Topic#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should allow children to bring it in their lunch boxes if their parents send it in their lunch#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but the sale of junk food can generate a significant amount of profit#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but they could allow healthier alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should be allowed to bring it from home#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but could offer alternative healthy foods in their place#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should instead promote healthy eating options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but it does generate money#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but give alternate snacks that are healthier#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should provided healthy alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they probably will continue to do so#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but provide a healthy alternative to sugary snack foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but students should be allowed to choose what they eat#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but they should not prohibit it if students bring it on their own#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but it does provide the school system with extra revenue#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but if people want it it, they will still find a way to have it#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should allow for healthy food to be available#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but healthy snacks should be added to school vending machines as part of an initiative aimed at changing kids' eating and fitness habits#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but offer different alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but some say students should be able to make their own choices of what to eat#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but there could be an argument for teaching kids to make decisions in the face of temptation by allowing the food to remain#Students without choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but they should make sure the healthier options are things kids will actually enjoy#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should offer healthy alternatives and encourage children to make better decisions#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but I think that giving the kids healthy choices would be a great replacement#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but instead should provide healthier food alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but allowed to bring healthier food to the school#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should have greater accessibility to nutrient dense foods#School without generating money#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but it needs to follow through at home with their own families#Unclassified Off-Topic#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but instead they should bring some healthy snacks and foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but selling snacks does raise money for the school#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but also not punish students for possessing junk food, since it is readily available and does not constitute an inherent threat that would warrant harsh punishment#Students without choice#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but should provide healthy snacks instead to raise revenue#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they may offer more choices of healthy food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but it should be noted that every child has their own personal decision of what they want to eat#Students without choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but it does help the school make money#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but allow students to bring in whatever foods their family allows#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but many kids prefer junk food#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should have snacks that are healthy alternatives as treats#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but I think they should sell other healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but instead should offer a wider variety of healthier snacks, so there is something for all students to enjoy#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should be allowed to provide healthy snacks and drinks for students to enjoy#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they can slowly integrate healthier choices such as baked potato chips instead of fried#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should incorporate healthy initiatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should have healthy alternatives for the kids to turn too when they do want a snack#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but certain snacks are alright#Schools providing healthy alternatives#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but let students do what they want#Students without choice#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but should respect students' right of free choice#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but they should teach students accurate health information#Schools providing healthy alternatives#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but they should have healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but offer healthy alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but if a student really wants junk food, they can make he more conscious decision to purchase their junk food at a local grocery store#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should instead offer healthier options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but at the end of the day, it's the students choice#Student choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but they should allow students to bring whatever food they wish to consume from home, as long as the school makes an effort to educate students about the risks of unhealthy eating habits#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should also be limited on what quasi-healthy options are available as well (eg#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but some people think students should be able to choose what they eat#Student choice#Student choice\n",
      "Schools should not allow junk food to be sold on campus but should offer healthy alternatives like fruit#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should make sure there are healthy options for snacks to replace the junk food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should offer healthy alternatives to junk food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should having vending machines that sell healthy options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they do#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but students should be allowed to bring junk food to campus if they desire#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but healthy snacks should be#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should be allowed to sell snacks and soda#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should offer reasonable alternative to the type of snacks that you would expect to find at a school#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should sell healthy options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should offer healthy alternative snacks to purchase#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should allow students to choose what they eat by bringing their own snacks if they want#Students can still bring/access junk food#Student choice\n",
      "Schools should not allow junk food to be sold on campus but they should be offering healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but educating students about good food choices still needs to happen because they will have access to junk food off campus#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but have healthy options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should allow kids to bring their own if they want#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but provide alternative healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but here schools are, still selling this junk food that only promotes poor eating habits which could lead to a lot of health complications#School without generating money#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should make sure that something is available to purchase if the children need to#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but they tried to give us a choice between food#School without generating money#Student choice\n",
      "Schools should not allow junk food to be sold on campus but provide public health education of its dangers#Schools providing healthy alternatives#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but in some cases junk food can be sold once a month#Unclassified Off-Topic#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but there could be certain times or events where some junk food may be purchased#Unclassified Off-Topic#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but be allowed to sell healthier alternative snacks and food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they are allowed to bring it themselves#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but ITS NOT GOOD#Unclassified Off-Topic#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but many schools do it because they do not see it as their job to change the diet of their students#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but in some cases junk food is less expensive than healthier options so junk is perhaps all some can afford#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should not interfere with what students bring for lunch from home#School without generating money#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but the school allow snack machines with more nutritious foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they could offer healthy options in place of junk food#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they would be losing a good revenue source#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but it should also educate students and staff alike on why it has opted to do so#Students without choice#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but it is acceptable to eat it there#Unclassified Off-Topic#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but maybe a few things#Unclassified Off-Topic#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but educate kids about healthy eating#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they could offer the option to buy snacks once a week#School without generating money#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but a slight compromise should be sought to make everyone happy#Schools providing healthy alternatives#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but they could offer some snack foods that are low in calories or not as salty or sugary but to be able to still give them a choice#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they cannot enforce eating habits outside of school#School without generating money#School without generating money\n",
      "Schools should not allow junk food to be sold on campus but if it is sold it should be really expensive so that only people that really want junk food will buy it#Unclassified Off-Topic#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but if kids choose to bring so on their own, that is their family's decision#Students can still bring/access junk food#Student choice\n",
      "Schools should not allow junk food to be sold on campus but the schools make money off of it#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but they should at have least allow children to choose between healthy food and snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but make the food less sugary and salty to make it healthy#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but if its taken away, kids will find a way to bring it back to campus#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but it is also important to focus on changing kids' fitness habits#Students without choice#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but they should be prepared for community backlash#School without generating money#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but they can replaced the junk foods by selling some nutritional foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should be transparent about their reasoning and teach kids why unhealthy foods aren't good#Students without choice#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but students should still have the freedom to bring snacks to school for lunch, everyone has a right to eat what they choose#Students can still bring/access junk food#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but should make an effort to teach the kids about better eating habits#Students without choice#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should instead promote healthy eating by filling snack machines with nutritious foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should have alternative healthy snacks available#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should provide healthier snacks for students to have#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but the schools could fill snack machines with more nutritious foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but if they insist it could be healthy options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but instead fill snack machines with nutritious foods#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should allow kids to bring it from home#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but if a club or organization has a fundraiser it may be allowed on special occasions#Unclassified Off-Topic#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but schools could fill the snack machines with healthy choices#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but it is the children's decision to do whatever they want after they are not in school#Students without choice#Students without choice\n",
      "Schools should not allow junk food to be sold on campus but selling junk foods generates money for the school#Schools generate money#Schools generate money\n",
      "Schools should not allow junk food to be sold on campus but they could sell a variety of healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but provide healthy snacks instead#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but we cannot protect our kids from everything bad for them out there#Students without choice#Unclassified Off-Topic\n",
      "Schools should not allow junk food to be sold on campus but teens can make decisions about what they eat when they are not at school#School without generating money#Student choice\n",
      "Schools should not allow junk food to be sold on campus but provide healthy options#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but offer healthy snacks#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but instead offer healthier options to students for purchase#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "Schools should not allow junk food to be sold on campus but should instead replace it with healthy alternatives#Schools providing healthy alternatives#Schools providing healthy alternatives\n",
      "116\n",
      "0.7581699346405228\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for item, predicted, correct in zip(test_data, test_predicted, test_correct):\n",
    "    assert item[\"label\"] == idx2label[correct]\n",
    "    c += (item[\"label\"] == idx2label[predicted])\n",
    "    print(\"{}#{}#{}\".format(item[\"text\"], idx2label[correct], idx2label[predicted]))\n",
    "    \n",
    "print(c)\n",
    "print(c/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
