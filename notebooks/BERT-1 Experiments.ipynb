{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First BERT Experiments\n",
    "\n",
    "In this notebook we do some first experiments with BERT: we finetune a BERT model+classifier on each of our datasets separately and compute the accuracy of the resulting classifier on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these experiments we use the `pytorch_transformers` package. It contains a variety of neural network architectures for transfer learning and pretrained models, including BERT and XLNET.\n",
    "\n",
    "Two different BERT models are relevant for our experiments: \n",
    "\n",
    "- BERT-base-uncased: a relatively small BERT model that should already give reasonable results,\n",
    "- BERT-large-uncased: a larger model for real state-of-the-art results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "from pytorch_transformers.modeling_bert import BertForSequenceClassification\n",
    "\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16 if \"base\" in BERT_MODEL else 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 1 if \"base\" in BERT_MODEL else 8\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the same data as for all our previous experiments. Here we load the training, development and test data for a particular prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import glob\n",
    "\n",
    "prefix = \"eatingmeat_but_xl\"\n",
    "train_file = f\"../data/interim/{prefix}_train_withprompt.ndjson\"\n",
    "synth_files = glob.glob(f\"../data/interim/{prefix}_train_withprompt_*.ndjson\")\n",
    "dev_file = f\"../data/interim/{prefix}_dev_withprompt.ndjson\"\n",
    "test_file = f\"../data/interim/{prefix}_test_withprompt.ndjson\"\n",
    "\n",
    "with open(train_file) as i:\n",
    "    train_data = ndjson.load(i)\n",
    "\n",
    "synth_data = []\n",
    "for f in synth_files:\n",
    "    if \"allsynth\" in f:\n",
    "        continue\n",
    "    with open(f) as i:\n",
    "        synth_data += ndjson.load(i)\n",
    "    \n",
    "with open(dev_file) as i:\n",
    "    dev_data = ndjson.load(i)\n",
    "    \n",
    "with open(test_file) as i:\n",
    "    test_data = ndjson.load(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the label vocabulary, which maps every label in the training data to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Change without mentioning consumption': 0, 'Less meat consumption could harm economy and cut jobs': 1, 'The meat industry is important/thriving and/or exports/demand increasing': 2, 'Eating meat is necessary for good nutrition': 3, 'Eating meat is part of culture/tradition': 4, 'Meat creates jobs and benefits economy': 5, \"Outside of article's scope\": 6, 'People will or should still eat meat': 7, 'Flexitarian w/o connection to environment or jobs': 8, 'Flexitarians benefit environment': 9, 'Meat consumption harms environment': 10}\n",
      "{0: 'Change without mentioning consumption', 1: 'Less meat consumption could harm economy and cut jobs', 2: 'The meat industry is important/thriving and/or exports/demand increasing', 3: 'Eating meat is necessary for good nutrition', 4: 'Eating meat is part of culture/tradition', 5: 'Meat creates jobs and benefits economy', 6: \"Outside of article's scope\", 7: 'People will or should still eat meat', 8: 'Flexitarian w/o connection to environment or jobs', 9: 'Flexitarians benefit environment', 10: 'Meat consumption harms environment'}\n"
     ]
    }
   ],
   "source": [
    "label2idx = {}\n",
    "idx2label = {}\n",
    "target_names = []\n",
    "for item in train_data:\n",
    "    if item[\"label\"] not in label2idx:\n",
    "        target_names.append(item[\"label\"])\n",
    "        idx = len(label2idx)\n",
    "        label2idx[item[\"label\"]] = idx\n",
    "        idx2label[idx] = item[\"label\"]\n",
    "    \n",
    "print(label2idx)\n",
    "print(idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 1516\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample(train_data, synth_data, label2idx, number):\n",
    "    \"\"\"Sample a fixed number of items from every label from\n",
    "    the training data and test data.\n",
    "    \"\"\"\n",
    "    new_train_data = []\n",
    "    for label in label2idx:\n",
    "        data_for_label = [i for i in train_data if i[\"label\"] == label]\n",
    "        \n",
    "        # If there is more training data than the required number,\n",
    "        # take a random sample of n examples from the training data.\n",
    "        if len(data_for_label) >= number:\n",
    "            random.shuffle(data_for_label)\n",
    "            new_train_data += data_for_label[:number]\n",
    "            \n",
    "        # If there is less training data than the required number,\n",
    "        # combine training data with synthetic data.\n",
    "        elif len(data_for_label) < number:\n",
    "            \n",
    "            # Automatically add all training data\n",
    "            new_train_data += data_for_label\n",
    "            \n",
    "            # Compute the required number of additional data\n",
    "            rest = number-len(data_for_label)\n",
    "            \n",
    "            # Collect the synthetic data for the label\n",
    "            synth_data_for_label = [i for i in synth_data if i[\"label\"] == label]\n",
    "            \n",
    "            # If there is more synthetic data than required, \n",
    "            # take a random sample from the synthetic data.\n",
    "            if len(synth_data_for_label) > rest:\n",
    "                random.shuffle(synth_data_for_label)\n",
    "                new_train_data += synth_data_for_label[:rest]\n",
    "            # If there is less synthetic data than required,\n",
    "            # sample with replacement from this data until we have\n",
    "            # the required number.\n",
    "            else:\n",
    "                new_train_data += random.choices(synth_data_for_label, k=rest)\n",
    "        \n",
    "    return new_train_data\n",
    "\n",
    "\n",
    "def random_sample(train_data, train_size):\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[:TRAIN_SIZE]    \n",
    "\n",
    "#train_data = sample(train_data, synth_data, label2idx, 200)\n",
    "print(\"Train data size:\", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We load the pretrained model and put it on a GPU if one is available. We also put the model in \"training\" mode, so that we can correctly update its internal parameters on the basis of our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=len(label2idx))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We preprocess the data by turning every example to an `InputFeatures` item. This item has all the attributes we need for finetuning BERT: \n",
    "\n",
    "- input ids: the ids of the tokens in the text\n",
    "- input mask: tells BERT what part of the input it should not look at (such as padding tokens)\n",
    "- segment ids: tells BERT what segment every token belongs to. BERT can take two different segments as input\n",
    "- label id: the id of this item's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/18/2019 17:10:45 - INFO - __main__ -   *** Example ***\n",
      "08/18/2019 17:10:45 - INFO - __main__ -   text: Large amounts of meat consumption are harming the environment, but decreasing meat consumption could harm meat industry, the economy, and decrease jobs.\n",
      "08/18/2019 17:10:45 - INFO - __main__ -   input_ids: 101 2312 8310 1997 6240 8381 2024 7386 2075 1996 4044 1010 2021 16922 6240 8381 2071 7386 6240 3068 1010 1996 4610 1010 1998 9885 5841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/18/2019 17:10:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/18/2019 17:10:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "08/18/2019 17:10:45 - INFO - __main__ -   label:Less meat consumption could harm economy and cut jobs id: 1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MAX_SEQ_LENGTH=100\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_features(examples, label2idx, max_seq_length, tokenizer, verbose=0):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    features = []\n",
    "    for (ex_index, ex) in enumerate(examples):\n",
    "        \n",
    "        # TODO: should deal better with sentences > max tok length\n",
    "        input_ids = tokenizer.encode(\"[CLS] \" + ex[\"text\"] + \" [SEP]\")\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "            \n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[ex[\"label\"]]\n",
    "        if verbose and ex_index == 0:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"text: %s\" % ex[\"text\"])\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label:\" + str(ex[\"label\"]) + \" id: \" + str(label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features\n",
    "\n",
    "train_features = convert_examples_to_features(train_data, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n",
    "dev_features = convert_examples_to_features(dev_data, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = convert_examples_to_features(test_data, label2idx, MAX_SEQ_LENGTH, tokenizer, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize data loaders for each of our data sets. These data loaders present the data for training (for example, by grouping them into batches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "dev_dataloader = get_data_loader(dev_features, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Our evaluation method takes a pretrained model and a dataloader. It has the model predict the labels for the items in the data loader, and returns the loss, the correct labels, and the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, verbose=False):\n",
    "\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "                    \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Let's prepare the training. We set the training parameters and choose an optimizer and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "\n",
    "NUM_TRAIN_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n",
    "\n",
    "num_train_steps = int(len(train_data) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=100, t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the actual training. In each epoch, we present the model with all training data and compute the loss on the training set and the development set. We save the model whenever the development loss improves. We end training when we haven't seen an improvement of the development loss for a specific number of epochs (the patience). \n",
    "\n",
    "Optionally, we use gradient accumulation to accumulate the gradient for several training steps. This is useful when we want to use a larger batch size than our current GPU allows us to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246bc78777ed44a98059f3b458ed9a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2968e71e7b844b60a2022b6b56abb914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: []\n",
      "Dev loss: 1.5664609840938024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [00:21<06:48, 21.51s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505547e03bd84f528b9cdeaaa534f6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368893c7bced461aad41172e7fd5eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024]\n",
      "Dev loss: 0.6933228160653796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [00:42<06:26, 21.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5138d8a8ce4867afaab7f48003fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c90555c69fb450fb6ecc13a3c0f745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796]\n",
      "Dev loss: 0.5236382186412811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [01:04<06:04, 21.47s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6652eb56e1564b959f5cea437d8887cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acf875f2054137a5858baf15a44857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811]\n",
      "Dev loss: 0.40991569416863577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [01:25<05:43, 21.48s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732a1e5eb6e84a9fbf4a02a366d97c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87130a3a72949c69e7677325b7a5661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577]\n",
      "Dev loss: 0.4081198147365025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [01:47<05:22, 21.49s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df4b2b6033044f0ba02ce543269bdf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa639e4704a48b4a6c80540ccfa8f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [02:08<04:59, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025]\n",
      "Dev loss: 0.4255748135702951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19bd0ac8058483fabeb3060e13d65b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63ed2325e5a45f29b9ebdf28dc8d221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951]\n",
      "Dev loss: 0.4025947153568268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [02:29<04:38, 21.41s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81949a5e2b514805ab64c81ff8b7bf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec494a858964484b68300fd79d8bed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [02:51<04:15, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268]\n",
      "Dev loss: 0.41689251363277435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581e76f44ded45daaab538d1240bbd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d9db11f48f4a289f665b6ed96560e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435]\n",
      "Dev loss: 0.39832896845681326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [03:12<03:55, 21.37s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c6704b62f7448e913e2e6401dae7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5bbcfd55594d4f846db1a53f1509ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326]\n",
      "Dev loss: 0.3872955484049661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [03:34<03:34, 21.42s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb9c57f4b34441ab3ae42cb77488cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1307e3f0499c451cb6d32c35eb62d1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [03:55<03:11, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326, 0.3872955484049661]\n",
      "Dev loss: 0.41526979207992554\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24b9cb11cf644c581a8dce6f48f767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2a2cbb4a54653bf0472f4ad57f0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [04:16<02:50, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326, 0.3872955484049661, 0.41526979207992554]\n",
      "Dev loss: 0.42054374516010284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2c8ef215c442ca87db8df58f6cd20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74457bfcaf9e4226a69b306b14415b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [04:37<02:28, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326, 0.3872955484049661, 0.41526979207992554, 0.42054374516010284]\n",
      "Dev loss: 0.43337044971329824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151607ce7a824b798925e7b7da10c4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6cbd6138c54ebca8824008d51ef16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [04:58<02:06, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326, 0.3872955484049661, 0.41526979207992554, 0.42054374516010284, 0.43337044971329824]\n",
      "Dev loss: 0.4160566447036607\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6da95773c934f679563b1165807051d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=95, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b863a87bb794ce4a962ea637fde8464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [1.5664609840938024, 0.6933228160653796, 0.5236382186412811, 0.40991569416863577, 0.4081198147365025, 0.4255748135702951, 0.4025947153568268, 0.41689251363277435, 0.39832896845681326, 0.3872955484049661, 0.41526979207992554, 0.42054374516010284, 0.43337044971329824, 0.4160566447036607]\n",
      "Dev loss: 0.4174923002719879\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"/tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "PATIENCE = 5\n",
    "\n",
    "global_step = 0\n",
    "model.train()\n",
    "loss_history = []\n",
    "best_epoch = 0\n",
    "for epoch in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        outputs = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            lr_this_step = LEARNING_RATE * warmup_linear(global_step/num_train_steps, WARMUP_PROPORTION)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    dev_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"Dev loss:\", dev_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or dev_loss < min(loss_history):\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        best_epoch = epoch\n",
    "    \n",
    "    if epoch-best_epoch >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    loss_history.append(dev_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We load the pretrained model, set it to evaluation mode and compute its performance on the training, development and test set. We print out an evaluation report for the test set.\n",
    "\n",
    "Note that different runs will give slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /tmp/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/18/2019 17:16:05 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/yves/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "08/18/2019 17:16:05 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 11,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "08/18/2019 17:16:05 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/yves/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a5ca4ab6c846e0bef271907d8aa53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=11, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test performance: (0.926829268292683, 0.926829268292683, 0.926829268292683, None)\n",
      "                                                                          precision    recall  f1-score   support\n",
      "\n",
      "                                   Change without mentioning consumption       0.00      0.00      0.00         1\n",
      "                   Less meat consumption could harm economy and cut jobs       0.98      0.98      0.98        42\n",
      "The meat industry is important/thriving and/or exports/demand increasing       0.90      1.00      0.95        18\n",
      "                             Eating meat is necessary for good nutrition       1.00      0.67      0.80         6\n",
      "                                Eating meat is part of culture/tradition       0.86      0.95      0.90        19\n",
      "                                  Meat creates jobs and benefits economy       0.97      0.95      0.96        40\n",
      "                                              Outside of article's scope       0.83      0.91      0.87        11\n",
      "                                    People will or should still eat meat       0.75      0.60      0.67         5\n",
      "                       Flexitarian w/o connection to environment or jobs       0.92      0.92      0.92        13\n",
      "                                        Flexitarians benefit environment       0.89      1.00      0.94         8\n",
      "                                      Meat consumption harms environment       0.00      0.00      0.00         1\n",
      "\n",
      "                                                             avg / total       0.92      0.93      0.92       164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model from\", output_model_file)\n",
    "device=\"cpu\"\n",
    "\n",
    "model_state_dict = torch.load(output_model_file, map_location=lambda storage, loc: storage)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels=len(label2idx))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "#_, dev_correct, dev_predicted = evaluate(model, dev_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader, verbose=True)\n",
    "\n",
    "#print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
    "#print(\"Development performance:\", precision_recall_fscore_support(dev_correct, dev_predicted, average=\"micro\"))\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large amounts of meat consumption are harming the environment, but decreasing meat consumption could harm meat industry, the economy, and decrease jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but still remain a large and growing part of many cultures' diets around the world#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry provides many jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but livestock production is also a boon to our economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eliminating consumption of meat would hurt the economy and take away many meat-related jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but vv#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry provides jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but animals are so tasty.#People will or should still eat meat#People will or should still eat meat\n",
      "Large amounts of meat consumption are harming the environment, but many Americans have cultural reasons for eating meat, like celebrating holidays.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but some people consume meat and fish only occasionally and in moderation#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but eating it in moderation would help reduce need for meat.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but being a flexitarian eating  meat only sometimes can help#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but Americans are unlikely to change their habits due to the integration of meat into American culture.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but it will also hurt the economy and the industry if consumption decreases.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but huge amounts of pollution also come from developing countries, which are increasing their use of automobiles and coal burning power plants.#Outside of article's scope#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but the industry is thriving and reducing consumption would hurt the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but there are options to reduce the environmental impact while still consuming meat#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is important and accounts for a large amount of jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it has become so essential in our economy and life’s that it would be hard to stop it without having consequences.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the American tradition of eating meat is hurting the earth.#Meat consumption harms environment#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but are an important domestic industry, helping maintain a strong economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eliminating the meat industry would take away jobs and livelihoods that are important to the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but some people have adjusted their diet to limited but not fully stop eating meat.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but it creates a thriving economic industry with lots of jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but some people are vegetarians and only eat meat occasionally.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing intake would harm the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving and reducing consumption could hurt the economy and take away jobs from those in that industry.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the  meat industry is thriving.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but other areas of resource use account for 80% of greenhouse gas emission.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but if people consumed less, it can negatively affect jobs and the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but exports of domestically produced beef is increasing allowing the meat industry to thrive.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but reducing consumption could harm the domestic industry and cost people their jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but it tastes great and a huge part of being an American.#Eating meat is part of culture/tradition#People will or should still eat meat\n",
      "Large amounts of meat consumption are harming the environment, but because the industry is so large and supports so many workers, any reduction of meat consumption could have negative effects on the economy through the loss of wages.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but in america it is the part of culture and traditions#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but its also a healthy and responsible choice#Eating meat is necessary for good nutrition#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing it would hurt the economy and take away jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but we don't want to lose jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but if we do away with eating meat, the economy will be drastically damaged.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but some people feel that tradition is more important than the continued health of the planet.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but if consumed in moderation, can be less harmful to the environment.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but American exports are increasing since more countries are incorporating meat into their daily diets.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but also helping the economy because meat is a large export as more countries become Americanized.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the elimination of meat in human nutrition can cause nutritional deficiencies and cause people to lose many jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the economy behind meat production is booming.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eliminating meat by Americans would be like giving up an essential part of their culture and traditions.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but can be eaten in moderation.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but it is a difficult situation because stopping the meat industry would harm the economy as many parts of the world are also adopting meat into their diets.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but it is also providing a ton of jobs in the domestic industry.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but meat exports are increasing and creating a more profitable business.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but there is a large likelihood that the vast tracks of farmland needed for grazing animals would not be left empty, there would be another, perhaps more harmful to the environment industry to use the land and resources.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but caring and raising the livestock produces jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the economy also benefits from the jobs created and revenue provided through raising livestock for food.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but some people try to have a stricter diet with eating meat.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but Americans enjoy consuming meat so much that the industry is thriving.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could damage the meat industry, hurt the economy and take away precious jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but moving to a 'flexitarian' society to curtail some of the damage being done.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but if eaten responsibly and in moderation, meat can be a valuable part of a regular diet.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption would destroy an important US industry.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but eliminating the meat industry would hurt the economy in many ways.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but should be reduced to moderate intake.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but for people like me, a flexitarian, I need red meat and turkey to maintain my iron levels - so I am very careful to eat the healthiest possible meats.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could harm the U.S. domestic industry, negatively impact the economy and cause the loss of jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the economy depends on meats and its exports to survive and thrive.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry provides many jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could hurt the economy  and increase unemployment.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but eliminating meat would be like giving up an essential  part of our culture and traditions.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is still thriving.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could harm peoples' livelihood.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but are important part of the economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry supports the economy and workers.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eating meat is an essential part of many cultures and traditions.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but if cut it would cause precious jobs to be lost and hurt our economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but people need the iron in meat to survive.#Eating meat is necessary for good nutrition#Eating meat is necessary for good nutrition\n",
      "Large amounts of meat consumption are harming the environment, but reducing or stopping meat consumption will have an adverse effect on economies and jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing the amount of meat consumed could damage and alter the economy drastically.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but eating meat is an essential part of American culture and traditions.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving because of American diets and exports.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but contribute economically to society.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving and provides many jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it is producing Jobs for Americans.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but if the population moved to a more plant-based diet there would be an increase in water usage to raise plants and an increase in greenhouse gases to move the plants to processing plants and then to end-users.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but it is important to the American economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but meat consumption helps an important domestic industry, creating jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption will hurt the economy and take away jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but flexitarians can change that.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but they only account for 20% of the world's total greenhouse gases, there are other factors at play that we need to start regulating in order to take care of the other 80%.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but Americans continue to consume.#People will or should still eat meat#People will or should still eat meat\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving because beef produced domestically is a huge export and is helping the economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it is important to make sure animal populations are kept under control.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but the population's need is too great to be ignored.#People will or should still eat meat#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is crucial to the world's economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but a lot of people are employed in the meat producing industry.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the industry for producing meat is helping to create many jobs for people which would be lost if people stop eating meat.#Meat creates jobs and benefits economy#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but CAN BE HEALTH FOR SOME PEOPLE#Eating meat is necessary for good nutrition#Eating meat is necessary for good nutrition\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could hurt the economy and take away jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but eating meat is a part of American culture and tradition, representing holidays and local pride.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but there is a way for Americans to still eat meat while reducing the environmental impact of their dietary choices.#Flexitarians benefit environment#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but it is part of the american gastronomy and will be very dificult to eliminate it comsuption#Eating meat is necessary for good nutrition#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but many people still adopt the American tradition of meat consumption.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could damage a booming industry thus leading to job loss and economic downturn.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but meat consumption is an American tradition and part of the culture.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but getting rid of meat entirely could be hurting a vital economic sector.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is a thriving staple for the U.S. economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is very important the economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it could be resolved in a substainable way if the practices are done correctly#Change without mentioning consumption#Flexitarians benefit environment\n",
      "Large amounts of meat consumption are harming the environment, but meat consumption is on the rise with more and more countries increasing their meat consumption.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could hurt the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing consumption could take away precious jobs and hurt the economy#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but it is an american tradition.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but some would say that human effect on the environment in any way is minimal.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but abruptly reducing the amount of meat eaten could harm the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but are also helping our economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but our bodies have health needs that include consuming meat from time to time, which forces our hands to knowingly cause harm.#Eating meat is necessary for good nutrition#Eating meat is necessary for good nutrition\n",
      "Large amounts of meat consumption are harming the environment, but unilaterally stopping eating meat, can also hurt the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving, with more and more meat being exported.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but they are also helping boost our economy and keeping many people employed.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it's hard to do anything about it because meat consumption is a large part of American culture and is quickly becoming a part of cultures around the world.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry provides jobs#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eliminating meat entirely would cripple the meat industry, making people lose jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the economy would be hurt by stopping meat production because it provides a lot of jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but it creates jobs and have economic benefits.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry creates many jobs and contributes to a healthy economy#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but some people choose to be flexitarians#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but there are flexitarians, people who belueve that most of their diet should be plant-based, with occasional meat consumption.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could damage an important  domestic industry, hurting the economy and taking away precious jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but meat and fish are part of most healthy diets in moderation.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but taste good#People will or should still eat meat#People will or should still eat meat\n",
      "Large amounts of meat consumption are harming the environment, but even more people keep integrating meat into their daily lives.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but Americans feel that it is an important part of their culture.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the stated claim#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but what harm is actually being done.#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but is fueling a thriving meat industry.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but are helping the economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but it is also very beneficial for the economy and it creates a lot of jobs by producing and exporting meat.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eating meat occasionally can still be healthy for you.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption could take away jobs and hurt the economy.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but it is a booming industry both domestically and internationally.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but if everyone stopped eating meat it could have a large impact on our economy as many people would lose their jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is thriving and accounts for many jobs, as well as several pivotal culinary pieces of American culture.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but by stopping meat consumption you could damage the economy and cost people their jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but meat consumption is such a big part of American culture, it is likely to continue and even grow.#Meat creates jobs and benefits economy#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but some people that call themselves \"Flexitarians\" choose to eat meat in moderation.#Flexitarian w/o connection to environment or jobs#Flexitarian w/o connection to environment or jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry continues to thrive as more and more meat is consumed.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but increasing export to other countries.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but it is part of the culture of the people.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry also creates good jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but meat is one essential component for a well-balanced meal.#Eating meat is necessary for good nutrition#Eating meat is necessary for good nutrition\n",
      "Large amounts of meat consumption are harming the environment, but helping keep alot of domestic jobs.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is a dominating force in the American domestic market.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but decreasing the amounts of meat consumed could damage an important domestic industry since exports are increasing.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but meat consumption continues to rise.#People will or should still eat meat#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but there#Outside of article's scope#Outside of article's scope\n",
      "Large amounts of meat consumption are harming the environment, but they are benefiting the global economy.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but reducing meat consumption can hurt the economy and take away precious jobs.#Less meat consumption could harm economy and cut jobs#Less meat consumption could harm economy and cut jobs\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is doing an all time high amount of business.#The meat industry is important/thriving and/or exports/demand increasing#The meat industry is important/thriving and/or exports/demand increasing\n",
      "Large amounts of meat consumption are harming the environment, but it's a classic American food.#Flexitarian w/o connection to environment or jobs#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but many jobs are provided by the meat industry.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but the meat industry is important economically, and some believe that responsible meat consumption is acceptable as a small part of a mostly plant-based diet.#Meat creates jobs and benefits economy#Meat creates jobs and benefits economy\n",
      "Large amounts of meat consumption are harming the environment, but eliminating meat would be giving up a part of their culture.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but for some Americans eliminating meat would be like giving up an essential part of our culture and traditions.#Eating meat is part of culture/tradition#Eating meat is part of culture/tradition\n",
      "Large amounts of meat consumption are harming the environment, but there may be a negative economic impact to reducing meat consumption and also exporting meats as part of our international trade economy.#Less meat consumption could harm economy and cut jobs#Meat creates jobs and benefits economy\n",
      "152\n",
      "0.926829268292683\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for item, predicted, correct in zip(test_data, test_predicted, test_correct):\n",
    "    assert item[\"label\"] == idx2label[correct]\n",
    "    c += (item[\"label\"] == idx2label[predicted])\n",
    "    print(\"{}#{}#{}\".format(item[\"text\"], idx2label[correct], idx2label[predicted]))\n",
    "    \n",
    "print(c)\n",
    "print(c/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
