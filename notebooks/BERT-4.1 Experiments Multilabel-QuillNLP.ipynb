{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel BERT Experiments\n",
    "\n",
    "In this notebook we do some first experiments with BERT: we finetune a BERT model+classifier on each of our datasets separately and compute the accuracy of the resulting classifier on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these experiments we use the `pytorch_transformers` package. It contains a variety of neural network architectures for transfer learning and pretrained models, including BERT and XLNET.\n",
    "\n",
    "Two different BERT models are relevant for our experiments: \n",
    "\n",
    "- BERT-base-uncased: a relatively small BERT model that should already give reasonable results,\n",
    "- BERT-large-uncased: a larger model for real state-of-the-art results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilabel import EATINGMEAT_BECAUSE_MAP, EATINGMEAT_BUT_MAP, JUNKFOOD_BECAUSE_MAP, JUNKFOOD_BUT_MAP\n",
    "\n",
    "LABEL_MAP = JUNKFOOD_BUT_MAP\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "BATCH_SIZE = 16 if \"base\" in BERT_MODEL else 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 1 if \"base\" in BERT_MODEL else 8\n",
    "MAX_SEQ_LENGTH = 100\n",
    "PREFIX = \"junkfood_but\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the same data as for all our previous experiments. Here we load the training, development and test data for a particular prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Schools providing healthy alternatives': 137, 'Students without choice': 46, 'Unclassified Off-Topic': 32, 'School without generating money': 26, 'Student choice': 24, 'Schools generate money': 16, 'Students can still bring/access junk food': 3})\n",
      "2556\n"
     ]
    }
   ],
   "source": [
    "import ndjson\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "train_file = f\"../data/interim/{PREFIX}_train_withprompt.ndjson\"\n",
    "synth_files = glob.glob(f\"../data/interim/{PREFIX}_train_withprompt_allsynth.ndjson\")\n",
    "dev_file = f\"../data/interim/{PREFIX}_dev_withprompt.ndjson\"\n",
    "test_file = f\"../data/interim/{PREFIX}_test_withprompt.ndjson\"\n",
    "\n",
    "with open(train_file) as i:\n",
    "    train_data = ndjson.load(i)\n",
    "\n",
    "synth_data = []\n",
    "for f in synth_files:\n",
    "    with open(f) as i:\n",
    "        synth_data += ndjson.load(i)\n",
    "    \n",
    "with open(dev_file) as i:\n",
    "    dev_data = ndjson.load(i)\n",
    "    \n",
    "with open(test_file) as i:\n",
    "    test_data = ndjson.load(i)\n",
    "    \n",
    "labels = Counter([item[\"label\"] for item in train_data])\n",
    "print(labels)\n",
    "print(len(synth_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the label vocabulary, which maps every label in the training data to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_multilabel(items):\n",
    "    return [{\"text\": item[\"text\"], \"label\": LABEL_MAP[item[\"label\"]]} for item in items]\n",
    "\n",
    "train_data = map_to_multilabel(train_data)\n",
    "dev_data = map_to_multilabel(dev_data)\n",
    "synth_data = map_to_multilabel(synth_data)\n",
    "test_data = map_to_multilabel(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from quillnlp.models.bert.preprocessing import preprocess, create_label_vocabulary\n",
    "\n",
    "label2idx = create_label_vocabulary(train_data)\n",
    "idx2label = {v:k for k,v in label2idx.items()}\n",
    "target_names = [idx2label[s] for s in range(len(idx2label))]\n",
    "\n",
    "MAX_SEQ_LENGTH = 100\n",
    "train_dataloader = preprocess(train_data, BERT_MODEL, label2idx, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "dev_dataloader = preprocess(dev_data, BERT_MODEL, label2idx, MAX_SEQ_LENGTH, BATCH_SIZE)\n",
    "test_dataloader = preprocess(test_data, BERT_MODEL, label2idx, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We load the pretrained model and put it on a GPU if one is available. We also put the model in \"training\" mode, so that we can correctly update its internal parameters on the basis of our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from quillnlp.models.bert.models import get_multilabel_bert_classifier\n",
    "\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = get_multilabel_bert_classifier(BERT_MODEL, len(label2idx), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f11271794b4ffbae8801ce68ac52d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee3fefd70942688e3ca596e699fe69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: []\n",
      "Dev loss: 0.46770793199539185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [00:04<01:30,  4.76s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7463d77755c1407b8a0e20b5d76e3bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27751db24bb454bb986c9204bc21f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185]\n",
      "Dev loss: 0.3351816892623901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [00:09<01:24,  4.69s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c34b095a918415dbb37c8bf5ab599fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7c12f8232c4e2db81c1f16b135346f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185, 0.3351816892623901]\n",
      "Dev loss: 0.2613398343324661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [00:13<01:18,  4.65s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793cc678111341b8b013431479e6e09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719d4038ebc54522bbc242ccd3b6bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185, 0.3351816892623901, 0.2613398343324661]\n",
      "Dev loss: 0.2466729998588562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [00:18<01:13,  4.62s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f585b97f6cc470dac1f9842178352e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd09e3cd4a6042338d0873caebb3fe0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185, 0.3351816892623901, 0.2613398343324661, 0.2466729998588562]\n",
      "Dev loss: 0.21184660196304322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [00:22<01:08,  4.59s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedf9d7004144d789bb31ed6f2420058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e0aa17f97e423daa9fbd27ae6c5411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185, 0.3351816892623901, 0.2613398343324661, 0.2466729998588562, 0.21184660196304322]\n",
      "Dev loss: 0.20426980555057525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [00:27<01:04,  4.58s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327c9e435c2d485d972e9d15011d1aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70f0841daa84e5fa20fdcbc2556835a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluation iteration', max=5, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss history: [0.46770793199539185, 0.3351816892623901, 0.2613398343324661, 0.2466729998588562, 0.21184660196304322, 0.20426980555057525]\n",
      "Dev loss: 0.1862332671880722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [00:32<00:59,  4.57s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0283c8833841159a66011d4e94d074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training iteration', max=18, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from quillnlp.models.bert.train import train\n",
    "\n",
    "batch_size = 16 if \"base\" in BERT_MODEL else 2\n",
    "gradient_accumulation_steps = 1 if \"base\" in BERT_MODEL else 8\n",
    "output_model_file = train(model, train_dataloader, dev_dataloader, batch_size, gradient_accumulation_steps, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quillnlp.models.bert.train import evaluate\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "print(\"Loading model from\", output_model_file)\n",
    "device=\"cpu\"\n",
    "\n",
    "model = get_multilabel_bert_classifier(BERT_MODEL, len(label2idx), model_file=output_model_file, device=device)\n",
    "model.eval()\n",
    "\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader, device)\n",
    "\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "print(classification_report(test_correct, test_predicted, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correct = 0\n",
    "fp, fn, tp, tn = 0, 0, 0, 0\n",
    "for c, p in zip(test_correct, test_predicted):\n",
    "    if sum(c == p) == len(c):\n",
    "        all_correct +=1\n",
    "    for ci, pi in zip(c, p):\n",
    "        if pi == 1 and ci == 1:\n",
    "            tp += 1\n",
    "            same = 1\n",
    "        elif pi == 1 and ci == 0:\n",
    "            fp += 1\n",
    "        elif pi == 0 and ci == 1:\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "            same =1\n",
    "            \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(\"P:\", precision)\n",
    "print(\"R:\", recall)\n",
    "print(\"A:\", all_correct/len(test_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item, predicted, correct in zip(test_data, test_predicted, test_correct):\n",
    "    correct_labels = [idx2label[i] for i, l in enumerate(correct) if l == 1]\n",
    "    predicted_labels = [idx2label[i] for i, l in enumerate(predicted) if l == 1]\n",
    "    print(\"{}#{}#{}\".format(item[\"text\"], \";\".join(correct_labels), \";\".join(predicted_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
