{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import re\n",
    "from nltk.util import ngrams, trigrams\n",
    "import csv\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #### Your code ####\n",
    "    net = tflearn.input_data([None, 1200])                          # Input\n",
    "    net = tflearn.fully_connected(net, 200, activation='ReLU')      # Hidden\n",
    "    net = tflearn.fully_connected(net, 25, activation='ReLU')      # Hidden\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')   # Output\n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "    model = tflearn.DNN(net)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load('./model.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the vocab index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADP>DET>NOUN': 0,\n",
       " 'NOUN>ADP>DET': 1,\n",
       " 'ADJ>NOUN>PUNCT': 2,\n",
       " 'DET>ADJ>NOUN': 3,\n",
       " 'DET>NOUN>ADP': 4,\n",
       " 'ADJ>NOUN>ADP': 5,\n",
       " 'NOUN>ADP>NOUN': 6,\n",
       " 'DET>NOUN>PUNCT': 7,\n",
       " 'ADP>ADJ>NOUN': 8,\n",
       " 'ADP>DET>ADJ': 9,\n",
       " 'VERB>DET>NOUN': 10,\n",
       " 'NOUN>NOUN>PUNCT': 11,\n",
       " 'VERB>ADP>DET': 12,\n",
       " 'DET>NOUN>VERB': 13,\n",
       " 'ADP>NOUN>PUNCT': 14,\n",
       " 'VERB>VERB>ADP': 15,\n",
       " 'NOUN>ADP>ADJ': 16,\n",
       " 'NOUN>VERB>VERB': 17,\n",
       " 'ADJ>NOUN>VERB': 18,\n",
       " 'ADJ>ADJ>NOUN': 19,\n",
       " 'ADJ>NOUN>NOUN': 20,\n",
       " 'NOUN>ADP>PROPN': 21,\n",
       " 'DET>NOUN>NOUN': 22,\n",
       " 'VERB>ADJ>NOUN': 23,\n",
       " 'PROPN>PROPN>PUNCT': 24,\n",
       " 'NOUN>NOUN>ADP': 25,\n",
       " 'VERB>DET>ADJ': 26,\n",
       " 'NOUN>VERB>ADP': 27,\n",
       " 'NOUN>PUNCT>NOUN': 28,\n",
       " 'NOUN>PUNCT>VERB': 29,\n",
       " 'VERB>ADP>NOUN': 30,\n",
       " 'ADP>NOUN>ADP': 31,\n",
       " 'ADP>NUM>PUNCT': 32,\n",
       " 'NOUN>ADP>NUM': 33,\n",
       " 'ADP>DET>PROPN': 34,\n",
       " 'NOUN>PUNCT>CONJ': 35,\n",
       " 'NOUN>CONJ>NOUN': 36,\n",
       " 'ADP>PROPN>PUNCT': 37,\n",
       " 'VERB>NOUN>ADP': 38,\n",
       " 'PROPN>PROPN>PROPN': 39,\n",
       " 'DET>PROPN>PROPN': 40,\n",
       " 'VERB>ADP>PROPN': 41,\n",
       " 'NOUN>NOUN>VERB': 42,\n",
       " 'NUM>NOUN>PUNCT': 43,\n",
       " 'VERB>PART>VERB': 44,\n",
       " 'VERB>ADV>VERB': 45,\n",
       " 'PUNCT>DET>NOUN': 46,\n",
       " 'ADP>PROPN>PROPN': 47,\n",
       " 'VERB>ADP>ADJ': 48,\n",
       " 'NOUN>VERB>DET': 49,\n",
       " 'NOUN>PART>VERB': 50,\n",
       " 'ADP>NUM>NOUN': 51,\n",
       " 'VERB>NOUN>PUNCT': 52,\n",
       " 'NOUN>VERB>ADV': 53,\n",
       " 'ADV>VERB>ADP': 54,\n",
       " 'ADP>NOUN>NOUN': 55,\n",
       " 'NOUN>CONJ>VERB': 56,\n",
       " 'NUM>NOUN>ADP': 57,\n",
       " 'ADJ>NOUN>CONJ': 58,\n",
       " 'NOUN>VERB>ADJ': 59,\n",
       " 'NOUN>PUNCT>DET': 60,\n",
       " 'NOUN>NOUN>NOUN': 61,\n",
       " 'CONJ>ADJ>NOUN': 62,\n",
       " 'NOUN>PART>NOUN': 63,\n",
       " 'PROPN>PROPN>VERB': 64,\n",
       " 'PROPN>VERB>DET': 65,\n",
       " 'DET>NOUN>PART': 66,\n",
       " 'PART>VERB>DET': 67,\n",
       " 'NOUN>PUNCT>ADJ': 68,\n",
       " 'PROPN>VERB>VERB': 69,\n",
       " 'PUNCT>NOUN>NOUN': 70,\n",
       " 'PROPN>PART>NOUN': 71,\n",
       " 'PUNCT>PROPN>VERB': 72,\n",
       " 'PROPN>NUM>PUNCT': 73,\n",
       " 'VERB>ADP>NUM': 74,\n",
       " 'PUNCT>NOUN>PUNCT': 75,\n",
       " 'NOUN>PUNCT>ADP': 76,\n",
       " 'ADP>PROPN>NUM': 77,\n",
       " 'PROPN>PUNCT>PROPN': 78,\n",
       " 'PROPN>ADP>PROPN': 79,\n",
       " 'VERB>VERB>PUNCT': 80,\n",
       " 'NOUN>PUNCT>PROPN': 81,\n",
       " 'PUNCT>PRON>VERB': 82,\n",
       " 'ADJ>ADP>DET': 83,\n",
       " 'VERB>NUM>NOUN': 84,\n",
       " 'ADP>ADJ>ADJ': 85,\n",
       " 'DET>ADJ>ADJ': 86,\n",
       " 'PUNCT>ADJ>NOUN': 87,\n",
       " 'PUNCT>CONJ>VERB': 88,\n",
       " 'CONJ>NOUN>PUNCT': 89,\n",
       " 'PROPN>VERB>ADP': 90,\n",
       " 'NOUN>VERB>NOUN': 91,\n",
       " 'DET>NOUN>CONJ': 92,\n",
       " 'ADP>NOUN>CONJ': 93,\n",
       " 'PRON>VERB>VERB': 94,\n",
       " 'PROPN>PROPN>ADP': 95,\n",
       " 'PUNCT>NOUN>VERB': 96,\n",
       " 'NOUN>ADV>VERB': 97,\n",
       " 'ADV>ADP>DET': 98,\n",
       " 'PART>NOUN>PUNCT': 99,\n",
       " 'ADV>VERB>DET': 100,\n",
       " 'VERB>ADV>ADP': 101,\n",
       " 'PUNCT>VERB>ADP': 102,\n",
       " 'NOUN>NOUN>CONJ': 103,\n",
       " 'ADP>NOUN>VERB': 104,\n",
       " 'VERB>ADJ>ADP': 105,\n",
       " 'CONJ>DET>NOUN': 106,\n",
       " 'PROPN>NOUN>PUNCT': 107,\n",
       " 'PROPN>CONJ>PROPN': 108,\n",
       " 'NOUN>PUNCT>ADV': 109,\n",
       " 'PART>ADJ>NOUN': 110,\n",
       " 'PROPN>ADP>DET': 111,\n",
       " 'VERB>NOUN>NOUN': 112,\n",
       " 'PUNCT>VERB>DET': 113,\n",
       " 'NOUN>CONJ>ADJ': 114,\n",
       " 'PUNCT>DET>ADJ': 115,\n",
       " 'PART>VERB>NOUN': 116,\n",
       " 'NOUN>ADP>VERB': 117,\n",
       " 'DET>NOUN>ADV': 118,\n",
       " 'PRON>VERB>DET': 119,\n",
       " 'PART>VERB>ADP': 120,\n",
       " 'VERB>ADV>ADJ': 121,\n",
       " 'PUNCT>VERB>NOUN': 122,\n",
       " 'CONJ>NOUN>NOUN': 123,\n",
       " 'VERB>VERB>VERB': 124,\n",
       " 'PRON>VERB>ADP': 125,\n",
       " 'CONJ>VERB>ADP': 126,\n",
       " 'NOUN>VERB>PUNCT': 127,\n",
       " 'ADP>PROPN>PART': 128,\n",
       " 'ADP>PROPN>ADP': 129,\n",
       " 'ADJ>NOUN>PART': 130,\n",
       " 'ADV>VERB>PUNCT': 131,\n",
       " 'ADV>ADJ>NOUN': 132,\n",
       " 'VERB>VERB>DET': 133,\n",
       " 'VERB>ADJ>PUNCT': 134,\n",
       " 'PROPN>VERB>ADJ': 135,\n",
       " 'CONJ>VERB>DET': 136,\n",
       " 'VERB>ADJ>ADJ': 137,\n",
       " 'ADP>PROPN>VERB': 138,\n",
       " 'PROPN>VERB>ADV': 139,\n",
       " 'ADJ>PUNCT>NOUN': 140,\n",
       " 'PUNCT>PROPN>PROPN': 141,\n",
       " 'PRON>VERB>ADV': 142,\n",
       " 'PART>VERB>ADJ': 143,\n",
       " 'ADJ>NOUN>ADV': 144,\n",
       " 'PUNCT>CONJ>DET': 145,\n",
       " 'PROPN>PUNCT>VERB': 146,\n",
       " 'ADP>DET>NUM': 147,\n",
       " 'VERB>ADV>PUNCT': 148,\n",
       " 'PUNCT>ADP>DET': 149,\n",
       " 'NUM>NOUN>VERB': 150,\n",
       " 'DET>NUM>NOUN': 151,\n",
       " 'NOUN>VERB>PART': 152,\n",
       " 'DET>ADJ>PUNCT': 153,\n",
       " 'PART>NOUN>ADP': 154,\n",
       " 'NOUN>PUNCT>PRON': 155,\n",
       " 'VERB>VERB>PART': 156,\n",
       " 'NUM>ADJ>NOUN': 157,\n",
       " 'DET>VERB>NOUN': 158,\n",
       " 'VERB>DET>PROPN': 159,\n",
       " 'NUM>ADP>DET': 160,\n",
       " 'ADP>NOUN>PART': 161,\n",
       " 'PUNCT>CONJ>NOUN': 162,\n",
       " 'NOUN>ADV>PUNCT': 163,\n",
       " 'CONJ>NOUN>VERB': 164,\n",
       " 'PART>NOUN>VERB': 165,\n",
       " 'ADV>VERB>NOUN': 166,\n",
       " 'NOUN>ADJ>NOUN': 167,\n",
       " 'NOUN>CONJ>DET': 168,\n",
       " 'DET>PROPN>NOUN': 169,\n",
       " 'ADP>NUM>PROPN': 170,\n",
       " 'PUNCT>PROPN>PUNCT': 171,\n",
       " 'ADP>PRON>VERB': 172,\n",
       " 'CONJ>NOUN>ADP': 173,\n",
       " 'PROPN>ADV>VERB': 174,\n",
       " 'ADJ>ADP>NOUN': 175,\n",
       " 'PROPN>PUNCT>DET': 176,\n",
       " 'ADV>VERB>ADJ': 177,\n",
       " 'ADP>NUM>ADP': 178,\n",
       " 'NOUN>NUM>PUNCT': 179,\n",
       " 'PUNCT>ADJ>VERB': 180,\n",
       " 'ADJ>ADP>ADJ': 181,\n",
       " 'NOUN>DET>NOUN': 182,\n",
       " 'PUNCT>NOUN>ADP': 183,\n",
       " 'VERB>VERB>ADV': 184,\n",
       " 'VERB>CONJ>VERB': 185,\n",
       " 'ADP>NOUN>NUM': 186,\n",
       " 'ADJ>CONJ>ADJ': 187,\n",
       " 'PROPN>NOUN>VERB': 188,\n",
       " 'VERB>VERB>ADJ': 189,\n",
       " 'VERB>PROPN>PROPN': 190,\n",
       " 'PRON>VERB>ADJ': 191,\n",
       " 'PROPN>ADP>NUM': 192,\n",
       " 'CONJ>VERB>NOUN': 193,\n",
       " 'ADV>DET>NOUN': 194,\n",
       " 'ADP>VERB>NOUN': 195,\n",
       " 'NUM>PUNCT>NUM': 196,\n",
       " 'CONJ>VERB>ADJ': 197,\n",
       " 'ADV>ADP>NOUN': 198,\n",
       " 'ADV>ADJ>ADP': 199,\n",
       " 'VERB>NOUN>CONJ': 200,\n",
       " 'NOUN>PART>ADJ': 201,\n",
       " 'NOUN>ADV>ADP': 202,\n",
       " 'PROPN>PROPN>CONJ': 203,\n",
       " 'DET>PROPN>PUNCT': 204,\n",
       " 'CONJ>VERB>VERB': 205,\n",
       " 'DET>NOUN>ADJ': 206,\n",
       " 'ADP>DET>VERB': 207,\n",
       " 'ADV>PUNCT>VERB': 208,\n",
       " 'NUM>NOUN>NOUN': 209,\n",
       " 'VERB>ADV>ADV': 210,\n",
       " 'PROPN>PART>ADJ': 211,\n",
       " 'PRON>ADV>VERB': 212,\n",
       " 'DET>PROPN>ADP': 213,\n",
       " 'VERB>VERB>NOUN': 214,\n",
       " 'PUNCT>VERB>ADJ': 215,\n",
       " 'PROPN>PUNCT>CONJ': 216,\n",
       " 'ADP>PROPN>CONJ': 217,\n",
       " 'ADV>ADJ>PUNCT': 218,\n",
       " 'NUM>PUNCT>NOUN': 219,\n",
       " 'PUNCT>VERB>VERB': 220,\n",
       " 'ADJ>NOUN>ADJ': 221,\n",
       " 'DET>ADJ>PROPN': 222,\n",
       " 'CONJ>ADV>VERB': 223,\n",
       " 'DET>ADP>DET': 224,\n",
       " 'ADV>PUNCT>DET': 225,\n",
       " 'PUNCT>NUM>PUNCT': 226,\n",
       " 'PROPN>PROPN>NOUN': 227,\n",
       " 'ADJ>PART>VERB': 228,\n",
       " 'NOUN>ADJ>VERB': 229,\n",
       " 'ADV>NUM>NOUN': 230,\n",
       " 'DET>PROPN>VERB': 231,\n",
       " 'PUNCT>CONJ>ADJ': 232,\n",
       " 'PUNCT>NOUN>CONJ': 233,\n",
       " 'PUNCT>ADP>NOUN': 234,\n",
       " 'CONJ>DET>ADJ': 235,\n",
       " 'CONJ>VERB>ADV': 236,\n",
       " 'PART>VERB>PUNCT': 237,\n",
       " 'NUM>PUNCT>DET': 238,\n",
       " 'ADP>ADJ>PUNCT': 239,\n",
       " 'VERB>NOUN>VERB': 240,\n",
       " 'PUNCT>ADV>VERB': 241,\n",
       " 'CONJ>PROPN>PROPN': 242,\n",
       " 'PUNCT>ADP>ADJ': 243,\n",
       " 'NUM>PUNCT>PROPN': 244,\n",
       " 'VERB>PRON>ADP': 245,\n",
       " 'PROPN>PUNCT>NOUN': 246,\n",
       " 'NOUN>VERB>PROPN': 247,\n",
       " 'PUNCT>DET>PROPN': 248,\n",
       " 'NOUN>PROPN>PROPN': 249,\n",
       " 'DET>ADV>ADJ': 250,\n",
       " 'NUM>NOUN>CONJ': 251,\n",
       " 'PROPN>VERB>NOUN': 252,\n",
       " 'ADP>VERB>DET': 253,\n",
       " 'NOUN>VERB>NUM': 254,\n",
       " 'ADP>NUM>CONJ': 255,\n",
       " 'PROPN>PUNCT>ADP': 256,\n",
       " 'DET>ADJ>ADP': 257,\n",
       " 'PROPN>NOUN>ADP': 258,\n",
       " 'ADJ>NUM>NOUN': 259,\n",
       " 'VERB>PUNCT>CONJ': 260,\n",
       " 'PROPN>VERB>PROPN': 261,\n",
       " 'CONJ>NUM>NOUN': 262,\n",
       " 'VERB>ADP>VERB': 263,\n",
       " 'PART>VERB>VERB': 264,\n",
       " 'PROPN>PROPN>PART': 265,\n",
       " 'VERB>NOUN>PART': 266,\n",
       " 'ADV>ADP>ADJ': 267,\n",
       " 'PROPN>VERB>PART': 268,\n",
       " 'CONJ>PROPN>VERB': 269,\n",
       " 'PART>NOUN>NOUN': 270,\n",
       " 'VERB>PROPN>ADP': 271,\n",
       " 'ADJ>VERB>VERB': 272,\n",
       " 'ADJ>PUNCT>ADJ': 273,\n",
       " 'ADV>VERB>PART': 274,\n",
       " 'ADP>ADP>DET': 275,\n",
       " 'VERB>PROPN>PART': 276,\n",
       " 'NOUN>PRON>VERB': 277,\n",
       " 'PUNCT>ADV>PUNCT': 278,\n",
       " 'NUM>PUNCT>VERB': 279,\n",
       " 'ADP>DET>PUNCT': 280,\n",
       " 'ADP>ADJ>NUM': 281,\n",
       " 'NOUN>NOUN>PART': 282,\n",
       " 'ADV>ADV>PUNCT': 283,\n",
       " 'PUNCT>CONJ>ADV': 284,\n",
       " 'PUNCT>CONJ>PROPN': 285,\n",
       " 'ADJ>PROPN>PROPN': 286,\n",
       " 'ADV>ADP>PROPN': 287,\n",
       " 'NUM>PUNCT>CONJ': 288,\n",
       " 'PROPN>VERB>NUM': 289,\n",
       " 'NOUN>NOUN>ADV': 290,\n",
       " 'NOUN>ADJ>ADP': 291,\n",
       " 'PUNCT>VERB>NUM': 292,\n",
       " 'PROPN>PART>VERB': 293,\n",
       " 'VERB>ADP>PRON': 294,\n",
       " 'NUM>ADP>NUM': 295,\n",
       " 'CONJ>PROPN>PUNCT': 296,\n",
       " 'ADJ>VERB>NOUN': 297,\n",
       " 'ADV>ADV>VERB': 298,\n",
       " 'ADV>VERB>ADV': 299,\n",
       " 'PUNCT>ADV>ADP': 300,\n",
       " 'VERB>NUM>ADP': 301,\n",
       " 'ADP>VERB>ADP': 302,\n",
       " 'ADV>ADV>ADP': 303,\n",
       " 'VERB>PROPN>PUNCT': 304,\n",
       " 'PUNCT>NUM>NOUN': 305,\n",
       " 'CONJ>PRON>VERB': 306,\n",
       " 'VERB>PART>ADP': 307,\n",
       " 'DET>ADP>NOUN': 308,\n",
       " 'ADV>VERB>VERB': 309,\n",
       " 'ADP>PROPN>NOUN': 310,\n",
       " 'ADP>PUNCT>NOUN': 311,\n",
       " 'PROPN>PUNCT>ADV': 312,\n",
       " 'PUNCT>VERB>ADV': 313,\n",
       " 'ADV>DET>ADJ': 314,\n",
       " 'NUM>PROPN>NUM': 315,\n",
       " 'ADJ>ADJ>ADJ': 316,\n",
       " 'PUNCT>ADP>NUM': 317,\n",
       " 'ADV>PRON>VERB': 318,\n",
       " 'NUM>NOUN>ADV': 319,\n",
       " 'NOUN>PUNCT>NUM': 320,\n",
       " 'ADJ>VERB>ADP': 321,\n",
       " 'NOUN>VERB>PRON': 322,\n",
       " 'ADP>ADJ>PROPN': 323,\n",
       " 'PROPN>PUNCT>ADJ': 324,\n",
       " 'NUM>CONJ>NUM': 325,\n",
       " 'NOUN>CONJ>NUM': 326,\n",
       " 'NOUN>DET>ADJ': 327,\n",
       " 'PUNCT>CONJ>ADP': 328,\n",
       " 'ADP>DET>ADP': 329,\n",
       " 'DET>NOUN>DET': 330,\n",
       " 'DET>ADJ>NUM': 331,\n",
       " 'PROPN>CONJ>VERB': 332,\n",
       " 'PRON>VERB>PART': 333,\n",
       " 'PROPN>ADP>ADJ': 334,\n",
       " 'PRON>VERB>NOUN': 335,\n",
       " 'PUNCT>ADP>PROPN': 336,\n",
       " 'NOUN>ADJ>PUNCT': 337,\n",
       " 'VERB>ADP>ADP': 338,\n",
       " 'NOUN>NOUN>ADJ': 339,\n",
       " 'VERB>PUNCT>VERB': 340,\n",
       " 'ADJ>PUNCT>CONJ': 341,\n",
       " 'NOUN>ADP>PRON': 342,\n",
       " 'ADV>PUNCT>ADP': 343,\n",
       " 'PRON>ADP>DET': 344,\n",
       " 'DET>ADJ>VERB': 345,\n",
       " 'ADJ>NOUN>DET': 346,\n",
       " 'ADJ>NOUN>PROPN': 347,\n",
       " 'ADJ>NUM>PUNCT': 348,\n",
       " 'NOUN>ADP>ADV': 349,\n",
       " 'VERB>PRON>PUNCT': 350,\n",
       " 'PUNCT>CONJ>PRON': 351,\n",
       " 'ADJ>ADP>NUM': 352,\n",
       " 'VERB>ADV>DET': 353,\n",
       " 'NUM>PUNCT>PRON': 354,\n",
       " 'PUNCT>ADJ>ADP': 355,\n",
       " 'VERB>NUM>PUNCT': 356,\n",
       " 'PART>VERB>ADV': 357,\n",
       " 'VERB>VERB>CONJ': 358,\n",
       " 'ADJ>ADJ>PUNCT': 359,\n",
       " 'ADV>PUNCT>NOUN': 360,\n",
       " 'NOUN>NUM>NOUN': 361,\n",
       " 'NOUN>CONJ>ADV': 362,\n",
       " 'PROPN>NOUN>NOUN': 363,\n",
       " 'CONJ>ADJ>ADJ': 364,\n",
       " 'ADJ>PROPN>PUNCT': 365,\n",
       " 'DET>VERB>VERB': 366,\n",
       " 'ADJ>VERB>DET': 367,\n",
       " 'NUM>PUNCT>ADP': 368,\n",
       " 'ADJ>ADP>PROPN': 369,\n",
       " 'VERB>ADJ>PART': 370,\n",
       " 'ADP>NUM>ADJ': 371,\n",
       " 'CONJ>VERB>PART': 372,\n",
       " 'ADJ>PUNCT>VERB': 373,\n",
       " 'PRON>VERB>NUM': 374,\n",
       " 'NUM>CONJ>VERB': 375,\n",
       " 'DET>VERB>DET': 376,\n",
       " 'NUM>ADP>NOUN': 377,\n",
       " 'NOUN>ADP>ADP': 378,\n",
       " 'ADP>PRON>PUNCT': 379,\n",
       " 'ADP>ADJ>ADP': 380,\n",
       " 'NUM>PROPN>PUNCT': 381,\n",
       " 'DET>ADJ>CONJ': 382,\n",
       " 'PROPN>ADP>NOUN': 383,\n",
       " 'CONJ>VERB>NUM': 384,\n",
       " 'PROPN>PART>PROPN': 385,\n",
       " 'VERB>DET>ADV': 386,\n",
       " 'VERB>DET>VERB': 387,\n",
       " 'DET>ADV>VERB': 388,\n",
       " 'ADP>DET>ADV': 389,\n",
       " 'ADV>PUNCT>PRON': 390,\n",
       " 'ADP>VERB>ADJ': 391,\n",
       " 'ADV>PUNCT>PROPN': 392,\n",
       " 'ADP>ADP>NOUN': 393,\n",
       " 'PROPN>VERB>PUNCT': 394,\n",
       " 'PRON>VERB>PUNCT': 395,\n",
       " 'PUNCT>ADJ>ADJ': 396,\n",
       " 'ADV>PART>VERB': 397,\n",
       " 'PUNCT>PROPN>CONJ': 398,\n",
       " 'ADV>PUNCT>ADJ': 399,\n",
       " 'ADV>ADP>NUM': 400,\n",
       " 'PART>VERB>PROPN': 401,\n",
       " 'ADP>NOUN>ADJ': 402,\n",
       " 'DET>VERB>ADJ': 403,\n",
       " 'PUNCT>VERB>PROPN': 404,\n",
       " 'PART>VERB>PRON': 405,\n",
       " 'CONJ>VERB>PUNCT': 406,\n",
       " 'ADJ>PROPN>NOUN': 407,\n",
       " 'ADP>NOUN>ADV': 408,\n",
       " 'PROPN>CONJ>DET': 409,\n",
       " 'VERB>ADV>NUM': 410,\n",
       " 'DET>ADP>ADJ': 411,\n",
       " 'NOUN>ADV>ADV': 412,\n",
       " 'DET>NUM>PUNCT': 413,\n",
       " 'NUM>ADP>ADJ': 414,\n",
       " 'ADJ>VERB>ADJ': 415,\n",
       " 'VERB>ADJ>CONJ': 416,\n",
       " 'PUNCT>ADJ>PUNCT': 417,\n",
       " 'DET>VERB>ADP': 418,\n",
       " 'ADV>PUNCT>CONJ': 419,\n",
       " 'ADP>PUNCT>DET': 420,\n",
       " 'ADV>VERB>PROPN': 421,\n",
       " 'CONJ>ADP>DET': 422,\n",
       " 'CONJ>DET>PROPN': 423,\n",
       " 'PRON>PART>VERB': 424,\n",
       " 'VERB>ADP>ADV': 425,\n",
       " 'VERB>PRON>VERB': 426,\n",
       " 'VERB>NUM>ADJ': 427,\n",
       " 'VERB>DET>NUM': 428,\n",
       " 'ADJ>VERB>ADV': 429,\n",
       " 'ADJ>DET>NOUN': 430,\n",
       " 'ADP>ADV>NUM': 431,\n",
       " 'PUNCT>VERB>PUNCT': 432,\n",
       " 'CONJ>NUM>PUNCT': 433,\n",
       " 'ADV>VERB>NUM': 434,\n",
       " 'PROPN>CONJ>ADJ': 435,\n",
       " 'ADP>ADP>ADJ': 436,\n",
       " 'PUNCT>PROPN>PART': 437,\n",
       " 'NOUN>PROPN>VERB': 438,\n",
       " 'VERB>PART>DET': 439,\n",
       " 'ADP>NUM>VERB': 440,\n",
       " 'NOUN>CONJ>ADP': 441,\n",
       " 'CONJ>VERB>PRON': 442,\n",
       " 'PUNCT>NOUN>PART': 443,\n",
       " 'VERB>PUNCT>ADP': 444,\n",
       " 'NUM>ADP>PROPN': 445,\n",
       " 'PART>NOUN>CONJ': 446,\n",
       " 'DET>NOUN>PROPN': 447,\n",
       " 'DET>NOUN>PRON': 448,\n",
       " 'NOUN>ADV>ADJ': 449,\n",
       " 'PUNCT>VERB>PART': 450,\n",
       " 'VERB>PRON>PART': 451,\n",
       " 'PROPN>ADJ>NOUN': 452,\n",
       " 'CONJ>ADJ>PUNCT': 453,\n",
       " 'NOUN>VERB>CONJ': 454,\n",
       " 'DET>PROPN>PART': 455,\n",
       " 'NUM>NOUN>NUM': 456,\n",
       " 'DET>VERB>ADV': 457,\n",
       " 'ADV>PUNCT>ADV': 458,\n",
       " 'ADJ>ADP>VERB': 459,\n",
       " 'ADP>ADP>NUM': 460,\n",
       " 'PUNCT>VERB>PRON': 461,\n",
       " 'ADP>ADV>VERB': 462,\n",
       " 'DET>PUNCT>NOUN': 463,\n",
       " 'SYM>NUM>NUM': 464,\n",
       " 'PRON>ADP>NOUN': 465,\n",
       " 'VERB>NOUN>ADV': 466,\n",
       " 'PRON>VERB>PROPN': 467,\n",
       " 'PART>VERB>PART': 468,\n",
       " 'ADP>ADJ>VERB': 469,\n",
       " 'ADJ>PUNCT>ADP': 470,\n",
       " 'ADV>ADV>ADJ': 471,\n",
       " 'NUM>PUNCT>ADV': 472,\n",
       " 'PART>ADP>DET': 473,\n",
       " 'DET>PROPN>CONJ': 474,\n",
       " 'ADJ>PROPN>VERB': 475,\n",
       " 'NOUN>NOUN>DET': 476,\n",
       " 'PUNCT>CONJ>NUM': 477,\n",
       " 'ADP>ADJ>CONJ': 478,\n",
       " 'VERB>VERB>PROPN': 479,\n",
       " 'ADJ>CONJ>VERB': 480,\n",
       " 'ADP>VERB>PUNCT': 481,\n",
       " 'NUM>PUNCT>ADJ': 482,\n",
       " 'PROPN>PROPN>ADV': 483,\n",
       " 'VERB>PART>PUNCT': 484,\n",
       " 'DET>NOUN>NUM': 485,\n",
       " 'PUNCT>NOUN>ADV': 486,\n",
       " 'ADV>NOUN>ADP': 487,\n",
       " 'PROPN>VERB>PRON': 488,\n",
       " 'PRON>DET>NOUN': 489,\n",
       " 'ADJ>ADV>VERB': 490,\n",
       " 'PUNCT>ADV>ADV': 491,\n",
       " 'NUM>NOUN>ADJ': 492,\n",
       " 'PROPN>NUM>ADP': 493,\n",
       " 'ADV>NOUN>PUNCT': 494,\n",
       " 'NUM>PROPN>PROPN': 495,\n",
       " 'ADV>VERB>CONJ': 496,\n",
       " 'ADV>VERB>PRON': 497,\n",
       " 'PROPN>PUNCT>PRON': 498,\n",
       " 'ADJ>PRON>VERB': 499,\n",
       " 'PUNCT>DET>VERB': 500,\n",
       " 'PUNCT>PROPN>NOUN': 501,\n",
       " 'VERB>PART>NOUN': 502,\n",
       " 'ADV>CONJ>VERB': 503,\n",
       " 'PUNCT>ADV>ADJ': 504,\n",
       " 'VERB>VERB>NUM': 505,\n",
       " 'VERB>PUNCT>DET': 506,\n",
       " 'PART>ADJ>ADJ': 507,\n",
       " 'VERB>DET>ADP': 508,\n",
       " 'ADP>VERB>VERB': 509,\n",
       " 'DET>NUM>ADJ': 510,\n",
       " 'PROPN>DET>NOUN': 511,\n",
       " 'PUNCT>ADP>VERB': 512,\n",
       " 'PUNCT>ADV>DET': 513,\n",
       " 'NOUN>ADV>DET': 514,\n",
       " 'ADP>ADV>ADJ': 515,\n",
       " 'ADV>ADP>VERB': 516,\n",
       " 'NOUN>PROPN>PUNCT': 517,\n",
       " 'DET>ADV>PUNCT': 518,\n",
       " 'VERB>PUNCT>ADV': 519,\n",
       " 'PUNCT>NUM>ADP': 520,\n",
       " 'NOUN>NOUN>PROPN': 521,\n",
       " 'ADP>SYM>NUM': 522,\n",
       " 'PROPN>NOUN>CONJ': 523,\n",
       " 'VERB>PUNCT>NOUN': 524,\n",
       " 'PART>DET>NOUN': 525,\n",
       " 'ADJ>PUNCT>DET': 526,\n",
       " 'NUM>NOUN>PART': 527,\n",
       " 'PUNCT>PART>VERB': 528,\n",
       " 'VERB>ADV>CONJ': 529,\n",
       " 'PUNCT>ADV>PRON': 530,\n",
       " 'CONJ>PROPN>NOUN': 531,\n",
       " 'ADV>ADJ>ADJ': 532,\n",
       " 'VERB>ADP>PUNCT': 533,\n",
       " 'ADP>ADV>PUNCT': 534,\n",
       " 'NOUN>NUM>ADP': 535,\n",
       " 'PRON>DET>ADJ': 536,\n",
       " 'ADV>PROPN>VERB': 537,\n",
       " 'VERB>NOUN>ADJ': 538,\n",
       " 'PART>PROPN>PROPN': 539,\n",
       " 'ADJ>NOUN>PRON': 540,\n",
       " 'ADJ>PROPN>ADP': 541,\n",
       " 'DET>NUM>PROPN': 542,\n",
       " 'PUNCT>NOUN>ADJ': 543,\n",
       " 'ADV>ADJ>CONJ': 544,\n",
       " 'PART>NUM>NOUN': 545,\n",
       " 'DET>ADJ>ADV': 546,\n",
       " 'NUM>NUM>NOUN': 547,\n",
       " 'ADJ>PUNCT>ADV': 548,\n",
       " 'PART>VERB>CONJ': 549,\n",
       " 'PUNCT>ADP>ADP': 550,\n",
       " 'ADJ>ADJ>ADP': 551,\n",
       " 'DET>DET>NOUN': 552,\n",
       " 'DET>PUNCT>DET': 553,\n",
       " 'CONJ>ADV>ADJ': 554,\n",
       " 'PUNCT>ADP>PRON': 555,\n",
       " 'NOUN>CONJ>PROPN': 556,\n",
       " 'PUNCT>DET>ADP': 557,\n",
       " 'PRON>ADP>ADJ': 558,\n",
       " 'NUM>PROPN>VERB': 559,\n",
       " 'VERB>PRON>DET': 560,\n",
       " 'PUNCT>PRON>ADV': 561,\n",
       " 'PROPN>NOUN>PART': 562,\n",
       " 'PUNCT>ADP>PUNCT': 563,\n",
       " 'NUM>PRON>VERB': 564,\n",
       " 'PUNCT>ADV>NOUN': 565,\n",
       " 'CONJ>ADP>ADJ': 566,\n",
       " 'CONJ>NOUN>ADV': 567,\n",
       " 'ADP>NOUN>DET': 568,\n",
       " 'CONJ>ADP>NOUN': 569,\n",
       " 'VERB>PROPN>CONJ': 570,\n",
       " 'NUM>VERB>VERB': 571,\n",
       " 'VERB>PART>ADJ': 572,\n",
       " 'VERB>ADV>NOUN': 573,\n",
       " 'ADP>ADP>PROPN': 574,\n",
       " 'CONJ>NOUN>PART': 575,\n",
       " 'PART>NOUN>PART': 576,\n",
       " 'PROPN>NUM>NOUN': 577,\n",
       " 'ADJ>CONJ>NOUN': 578,\n",
       " 'VERB>PROPN>NOUN': 579,\n",
       " 'ADP>PUNCT>PRON': 580,\n",
       " 'ADP>VERB>ADV': 581,\n",
       " 'ADP>PROPN>ADV': 582,\n",
       " 'ADJ>ADV>PUNCT': 583,\n",
       " 'CONJ>ADJ>ADP': 584,\n",
       " 'PROPN>DET>ADJ': 585,\n",
       " 'ADP>NOUN>PROPN': 586,\n",
       " 'VERB>PUNCT>PROPN': 587,\n",
       " 'ADP>ADJ>DET': 588,\n",
       " 'ADJ>ADJ>CONJ': 589,\n",
       " 'PART>VERB>NUM': 590,\n",
       " 'NUM>VERB>ADP': 591,\n",
       " 'ADP>VERB>PART': 592,\n",
       " 'NUM>NUM>PUNCT': 593,\n",
       " 'VERB>PRON>ADV': 594,\n",
       " 'CONJ>DET>VERB': 595,\n",
       " 'VERB>VERB>PRON': 596,\n",
       " 'CONJ>ADP>NUM': 597,\n",
       " 'ADV>ADJ>PART': 598,\n",
       " 'ADP>PUNCT>VERB': 599,\n",
       " 'PROPN>ADP>VERB': 600,\n",
       " 'PUNCT>PROPN>ADV': 601,\n",
       " 'ADV>NOUN>VERB': 602,\n",
       " 'NUM>VERB>NOUN': 603,\n",
       " 'PUNCT>ADP>ADV': 604,\n",
       " 'VERB>ADV>PART': 605,\n",
       " 'ADJ>PUNCT>PROPN': 606,\n",
       " 'PART>NOUN>ADV': 607,\n",
       " 'CONJ>PROPN>ADP': 608,\n",
       " 'CONJ>VERB>PROPN': 609,\n",
       " 'PROPN>CONJ>NOUN': 610,\n",
       " 'NUM>NOUN>DET': 611,\n",
       " 'VERB>PRON>ADJ': 612,\n",
       " 'PUNCT>ADV>NUM': 613,\n",
       " 'DET>ADP>NUM': 614,\n",
       " 'CONJ>NUM>ADJ': 615,\n",
       " 'ADJ>ADP>PRON': 616,\n",
       " 'NOUN>ADP>PUNCT': 617,\n",
       " 'NUM>PART>VERB': 618,\n",
       " 'NOUN>PUNCT>PART': 619,\n",
       " 'ADJ>CONJ>ADV': 620,\n",
       " 'CONJ>ADV>ADP': 621,\n",
       " 'CONJ>NOUN>CONJ': 622,\n",
       " 'NUM>DET>NOUN': 623,\n",
       " 'PROPN>ADV>ADP': 624,\n",
       " 'PART>ADP>NOUN': 625,\n",
       " 'ADP>ADV>DET': 626,\n",
       " 'ADP>NUM>PRON': 627,\n",
       " 'NOUN>ADJ>ADJ': 628,\n",
       " 'DET>VERB>NUM': 629,\n",
       " 'VERB>ADJ>PROPN': 630,\n",
       " 'ADJ>NOUN>NUM': 631,\n",
       " 'PRON>VERB>PRON': 632,\n",
       " 'VERB>PUNCT>ADJ': 633,\n",
       " 'ADP>PRON>ADP': 634,\n",
       " 'PUNCT>PROPN>ADP': 635,\n",
       " 'NOUN>PROPN>NOUN': 636,\n",
       " 'VERB>ADJ>ADV': 637,\n",
       " 'PROPN>NUM>CONJ': 638,\n",
       " 'ADP>VERB>PROPN': 639,\n",
       " 'VERB>NUM>CONJ': 640,\n",
       " 'PROPN>NOUN>PROPN': 641,\n",
       " 'PUNCT>DET>ADV': 642,\n",
       " 'VERB>CONJ>NOUN': 643,\n",
       " 'DET>NUM>VERB': 644,\n",
       " 'ADP>NUM>DET': 645,\n",
       " 'PROPN>PUNCT>NUM': 646,\n",
       " 'ADP>PART>VERB': 647,\n",
       " 'ADP>VERB>NUM': 648,\n",
       " 'PUNCT>ADJ>ADV': 649,\n",
       " 'DET>VERB>PROPN': 650,\n",
       " 'VERB>SYM>NUM': 651,\n",
       " 'VERB>ADJ>VERB': 652,\n",
       " 'NOUN>ADV>NOUN': 653,\n",
       " 'ADJ>PUNCT>PRON': 654,\n",
       " 'PUNCT>NOUN>PROPN': 655,\n",
       " 'ADJ>ADV>ADP': 656,\n",
       " 'NUM>ADJ>PUNCT': 657,\n",
       " 'CONJ>NUM>ADP': 658,\n",
       " 'PUNCT>VERB>CONJ': 659,\n",
       " 'ADP>NOUN>PRON': 660,\n",
       " 'ADJ>ADJ>PROPN': 661,\n",
       " 'PUNCT>ADJ>CONJ': 662,\n",
       " 'PART>ADV>VERB': 663,\n",
       " 'ADV>NUM>PUNCT': 664,\n",
       " 'PROPN>NOUN>ADV': 665,\n",
       " 'PART>PROPN>PUNCT': 666,\n",
       " 'PUNCT>DET>NUM': 667,\n",
       " 'DET>VERB>PUNCT': 668,\n",
       " 'ADV>CONJ>ADV': 669,\n",
       " 'CONJ>ADV>PUNCT': 670,\n",
       " 'ADV>NUM>ADJ': 671,\n",
       " 'ADP>PUNCT>ADJ': 672,\n",
       " 'CONJ>NOUN>ADJ': 673,\n",
       " 'VERB>CONJ>DET': 674,\n",
       " 'CONJ>ADP>PROPN': 675,\n",
       " 'ADV>ADP>ADP': 676,\n",
       " 'ADJ>ADV>ADJ': 677,\n",
       " 'NOUN>ADV>CONJ': 678,\n",
       " 'VERB>PUNCT>PRON': 679,\n",
       " 'PROPN>ADV>PUNCT': 680,\n",
       " 'PRON>ADV>ADP': 681,\n",
       " 'ADJ>DET>ADJ': 682,\n",
       " 'PUNCT>ADJ>PROPN': 683,\n",
       " 'PRON>ADJ>NOUN': 684,\n",
       " 'NUM>ADJ>ADJ': 685,\n",
       " 'ADV>PROPN>PROPN': 686,\n",
       " 'ADV>ADP>PRON': 687,\n",
       " 'NUM>NUM>ADP': 688,\n",
       " 'CONJ>ADV>ADV': 689,\n",
       " 'VERB>CONJ>ADJ': 690,\n",
       " 'VERB>DET>PUNCT': 691,\n",
       " 'NOUN>PART>NUM': 692,\n",
       " 'NUM>VERB>DET': 693,\n",
       " 'CONJ>PROPN>PART': 694,\n",
       " 'ADV>NOUN>NOUN': 695,\n",
       " 'VERB>CONJ>ADV': 696,\n",
       " 'NOUN>NOUN>NUM': 697,\n",
       " 'NOUN>PART>ADV': 698,\n",
       " 'ADP>ADJ>PRON': 699,\n",
       " 'DET>PUNCT>ADJ': 700,\n",
       " 'DET>PROPN>ADV': 701,\n",
       " 'PROPN>PRON>VERB': 702,\n",
       " 'ADP>NUM>PART': 703,\n",
       " 'ADP>NUM>ADV': 704,\n",
       " 'VERB>PROPN>VERB': 705,\n",
       " 'DET>PROPN>NUM': 706,\n",
       " 'CONJ>NUM>VERB': 707,\n",
       " 'NOUN>ADV>PRON': 708,\n",
       " 'NUM>PROPN>NOUN': 709,\n",
       " 'ADP>ADV>ADP': 710,\n",
       " 'SYM>NUM>PUNCT': 711,\n",
       " 'PUNCT>PRON>ADP': 712,\n",
       " 'ADJ>ADJ>VERB': 713,\n",
       " 'PROPN>ADV>ADV': 714,\n",
       " 'ADP>NUM>NUM': 715,\n",
       " 'CONJ>DET>NUM': 716,\n",
       " 'ADJ>NUM>ADP': 717,\n",
       " 'PART>ADP>ADJ': 718,\n",
       " 'PUNCT>CONJ>PUNCT': 719,\n",
       " 'ADJ>VERB>PART': 720,\n",
       " 'PUNCT>ADV>PROPN': 721,\n",
       " 'PROPN>PART>NUM': 722,\n",
       " 'ADP>PUNCT>NUM': 723,\n",
       " 'PUNCT>PRON>DET': 724,\n",
       " 'PROPN>PROPN>ADJ': 725,\n",
       " 'ADV>ADV>ADV': 726,\n",
       " 'NUM>VERB>PUNCT': 727,\n",
       " 'VERB>PART>ADV': 728,\n",
       " 'ADP>ADJ>ADV': 729,\n",
       " 'NOUN>DET>VERB': 730,\n",
       " 'DET>DET>ADJ': 731,\n",
       " 'NUM>VERB>ADJ': 732,\n",
       " 'NOUN>ADJ>CONJ': 733,\n",
       " 'DET>ADJ>PART': 734,\n",
       " 'PRON>ADP>NUM': 735,\n",
       " 'DET>ADP>PROPN': 736,\n",
       " 'PRON>ADV>PUNCT': 737,\n",
       " 'VERB>ADP>SYM': 738,\n",
       " 'ADJ>VERB>NUM': 739,\n",
       " 'ADV>NUM>ADP': 740,\n",
       " 'DET>PUNCT>PRON': 741,\n",
       " 'NUM>CONJ>DET': 742,\n",
       " 'NOUN>NUM>CONJ': 743,\n",
       " 'NOUN>ADP>CONJ': 744,\n",
       " 'ADV>DET>PROPN': 745,\n",
       " 'PUNCT>NUM>ADJ': 746,\n",
       " 'SYM>NUM>ADP': 747,\n",
       " 'PROPN>VERB>CONJ': 748,\n",
       " 'ADP>PROPN>ADJ': 749,\n",
       " 'PART>ADP>NUM': 750,\n",
       " 'NOUN>CONJ>PUNCT': 751,\n",
       " 'VERB>NUM>VERB': 752,\n",
       " 'ADV>ADV>DET': 753,\n",
       " 'ADJ>ADP>ADP': 754,\n",
       " 'PROPN>CONJ>ADV': 755,\n",
       " 'CONJ>ADJ>PROPN': 756,\n",
       " 'ADP>VERB>PRON': 757,\n",
       " 'ADJ>CONJ>DET': 758,\n",
       " 'PRON>ADP>VERB': 759,\n",
       " 'PART>ADP>PROPN': 760,\n",
       " 'CONJ>ADV>DET': 761,\n",
       " 'NUM>CONJ>ADV': 762,\n",
       " 'PART>NOUN>PROPN': 763,\n",
       " 'DET>PART>VERB': 764,\n",
       " 'PUNCT>ADJ>PRON': 765,\n",
       " 'ADV>ADP>PUNCT': 766,\n",
       " 'PUNCT>NOUN>DET': 767,\n",
       " 'ADJ>VERB>PROPN': 768,\n",
       " 'DET>PUNCT>VERB': 769,\n",
       " 'VERB>PROPN>NUM': 770,\n",
       " 'PART>ADV>ADJ': 771,\n",
       " 'ADP>VERB>CONJ': 772,\n",
       " 'NOUN>ADV>PART': 773,\n",
       " 'PROPN>NUM>PROPN': 774,\n",
       " 'NOUN>NOUN>PRON': 775,\n",
       " 'CONJ>PROPN>ADV': 776,\n",
       " 'PART>PROPN>ADP': 777,\n",
       " 'ADP>PRON>ADV': 778,\n",
       " 'DET>PROPN>ADJ': 779,\n",
       " 'ADJ>PROPN>CONJ': 780,\n",
       " 'CONJ>ADJ>VERB': 781,\n",
       " 'PRON>ADP>PROPN': 782,\n",
       " 'DET>ADV>ADP': 783,\n",
       " 'ADP>CONJ>ADP': 784,\n",
       " 'DET>VERB>PART': 785,\n",
       " 'NOUN>CONJ>PRON': 786,\n",
       " 'VERB>ADV>PROPN': 787,\n",
       " 'VERB>ADP>PART': 788,\n",
       " 'NOUN>ADP>SYM': 789,\n",
       " 'ADP>ADV>ADV': 790,\n",
       " 'ADP>PUNCT>ADP': 791,\n",
       " 'NOUN>ADJ>ADV': 792,\n",
       " 'DET>PUNCT>ADP': 793,\n",
       " 'DET>ADV>ADV': 794,\n",
       " 'PROPN>ADV>DET': 795,\n",
       " 'PRON>PUNCT>VERB': 796,\n",
       " 'PROPN>NUM>VERB': 797,\n",
       " 'NOUN>PROPN>ADP': 798,\n",
       " 'NOUN>DET>PROPN': 799,\n",
       " 'CONJ>PUNCT>ADP': 800,\n",
       " 'ADJ>NUM>ADJ': 801,\n",
       " 'ADJ>VERB>PUNCT': 802,\n",
       " 'VERB>PROPN>ADV': 803,\n",
       " 'PART>DET>ADJ': 804,\n",
       " 'PUNCT>NUM>VERB': 805,\n",
       " 'PROPN>PROPN>NUM': 806,\n",
       " 'PUNCT>NOUN>NUM': 807,\n",
       " 'VERB>PRON>NOUN': 808,\n",
       " 'PRON>CONJ>VERB': 809,\n",
       " 'NOUN>PROPN>CONJ': 810,\n",
       " 'PROPN>ADJ>VERB': 811,\n",
       " 'VERB>NOUN>PROPN': 812,\n",
       " 'VERB>ADJ>NUM': 813,\n",
       " 'ADP>DET>DET': 814,\n",
       " 'DET>ADJ>DET': 815,\n",
       " 'ADJ>ADJ>NUM': 816,\n",
       " 'NOUN>PRON>PUNCT': 817,\n",
       " 'PRON>NUM>NOUN': 818,\n",
       " 'CONJ>PART>VERB': 819,\n",
       " 'ADJ>VERB>PRON': 820,\n",
       " 'PRON>ADV>ADV': 821,\n",
       " 'ADV>ADJ>VERB': 822,\n",
       " 'PRON>PUNCT>CONJ': 823,\n",
       " 'VERB>ADJ>DET': 824,\n",
       " 'VERB>NOUN>DET': 825,\n",
       " 'PART>PART>VERB': 826,\n",
       " 'PUNCT>NUM>PROPN': 827,\n",
       " 'CONJ>PROPN>CONJ': 828,\n",
       " 'PART>NOUN>DET': 829,\n",
       " 'PROPN>ADP>PRON': 830,\n",
       " 'NUM>PROPN>ADP': 831,\n",
       " 'PROPN>CONJ>NUM': 832,\n",
       " 'NOUN>ADV>NUM': 833,\n",
       " 'VERB>PART>PART': 834,\n",
       " 'NOUN>PART>ADP': 835,\n",
       " 'ADV>ADV>CONJ': 836,\n",
       " 'VERB>PART>NUM': 837,\n",
       " 'PUNCT>NUM>CONJ': 838,\n",
       " 'VERB>CONJ>NUM': 839,\n",
       " 'NUM>ADP>VERB': 840,\n",
       " 'X>PUNCT>NOUN': 841,\n",
       " 'NOUN>PART>PROPN': 842,\n",
       " 'ADJ>ADP>PUNCT': 843,\n",
       " 'ADP>PROPN>DET': 844,\n",
       " 'PROPN>CONJ>ADP': 845,\n",
       " 'NUM>CONJ>ADJ': 846,\n",
       " 'ADV>NOUN>CONJ': 847,\n",
       " 'PRON>CONJ>ADJ': 848,\n",
       " 'PRON>ADV>ADJ': 849,\n",
       " 'NUM>ADV>PUNCT': 850,\n",
       " 'NUM>VERB>ADV': 851,\n",
       " 'DET>CONJ>NOUN': 852,\n",
       " 'VERB>PROPN>DET': 853,\n",
       " 'PRON>ADJ>ADP': 854,\n",
       " 'DET>PUNCT>ADV': 855,\n",
       " 'NUM>ADP>PRON': 856,\n",
       " 'PRON>NOUN>ADP': 857,\n",
       " 'ADP>ADP>PUNCT': 858,\n",
       " 'ADP>ADV>NOUN': 859,\n",
       " 'NUM>ADJ>NUM': 860,\n",
       " 'VERB>PART>CONJ': 861,\n",
       " 'PROPN>NUM>DET': 862,\n",
       " 'ADV>DET>VERB': 863,\n",
       " 'ADV>ADV>NUM': 864,\n",
       " 'ADJ>ADP>ADV': 865,\n",
       " 'NOUN>ADJ>PROPN': 866,\n",
       " 'PART>NOUN>ADJ': 867,\n",
       " 'X>PUNCT>ADJ': 868,\n",
       " 'NOUN>ADV>PROPN': 869,\n",
       " 'NUM>VERB>NUM': 870,\n",
       " 'DET>PUNCT>NUM': 871,\n",
       " 'ADV>DET>ADP': 872,\n",
       " 'CONJ>ADV>NOUN': 873,\n",
       " 'PART>NUM>PUNCT': 874,\n",
       " 'PROPN>ADP>ADP': 875,\n",
       " 'NUM>PART>NUM': 876,\n",
       " 'ADV>PUNCT>NUM': 877,\n",
       " 'DET>ADV>NOUN': 878,\n",
       " 'NUM>ADV>ADV': 879,\n",
       " 'NOUN>NUM>VERB': 880,\n",
       " 'ADJ>NUM>VERB': 881,\n",
       " 'VERB>NOUN>NUM': 882,\n",
       " 'PART>ADJ>PUNCT': 883,\n",
       " 'PROPN>PROPN>DET': 884,\n",
       " 'NOUN>PART>PUNCT': 885,\n",
       " 'DET>NUM>ADP': 886,\n",
       " 'PART>CONJ>VERB': 887,\n",
       " 'ADP>PRON>CONJ': 888,\n",
       " 'CONJ>PRON>ADV': 889,\n",
       " 'VERB>ADP>CONJ': 890,\n",
       " 'CONJ>VERB>CONJ': 891,\n",
       " 'ADV>ADP>ADV': 892,\n",
       " 'NOUN>ADJ>PART': 893,\n",
       " 'ADJ>NUM>CONJ': 894,\n",
       " 'ADP>PROPN>PRON': 895,\n",
       " 'PUNCT>PRON>NUM': 896,\n",
       " 'ADV>SYM>NUM': 897,\n",
       " 'PROPN>NOUN>ADJ': 898,\n",
       " 'PROPN>PUNCT>PART': 899,\n",
       " 'ADP>PUNCT>ADV': 900,\n",
       " 'PRON>VERB>CONJ': 901,\n",
       " 'ADV>NUM>VERB': 902,\n",
       " 'NUM>ADV>VERB': 903,\n",
       " 'PROPN>PART>ADV': 904,\n",
       " 'CONJ>NOUN>PROPN': 905,\n",
       " 'ADV>ADV>NOUN': 906,\n",
       " 'PROPN>ADJ>ADP': 907,\n",
       " 'ADP>PUNCT>PROPN': 908,\n",
       " 'CONJ>DET>ADV': 909,\n",
       " 'VERB>PRON>CONJ': 910,\n",
       " 'ADV>ADJ>DET': 911,\n",
       " 'CONJ>NUM>PROPN': 912,\n",
       " 'ADJ>ADV>ADV': 913,\n",
       " 'NOUN>PRON>ADV': 914,\n",
       " 'NUM>PROPN>CONJ': 915,\n",
       " 'ADV>PROPN>PUNCT': 916,\n",
       " 'VERB>NUM>PROPN': 917,\n",
       " 'PUNCT>NOUN>PRON': 918,\n",
       " 'ADV>ADJ>PROPN': 919,\n",
       " 'ADJ>PUNCT>NUM': 920,\n",
       " 'PRON>ADV>DET': 921,\n",
       " 'PART>PROPN>NOUN': 922,\n",
       " 'DET>PUNCT>PROPN': 923,\n",
       " 'PUNCT>ADJ>NUM': 924,\n",
       " 'ADP>ADP>VERB': 925,\n",
       " 'DET>ADV>DET': 926,\n",
       " 'NOUN>VERB>SYM': 927,\n",
       " 'PROPN>ADJ>PUNCT': 928,\n",
       " 'PUNCT>ADJ>DET': 929,\n",
       " 'VERB>NOUN>PRON': 930,\n",
       " 'PROPN>ADP>ADV': 931,\n",
       " 'PROPN>NUM>PRON': 932,\n",
       " 'VERB>PUNCT>NUM': 933,\n",
       " 'NUM>DET>ADJ': 934,\n",
       " 'DET>VERB>PRON': 935,\n",
       " 'CONJ>ADJ>CONJ': 936,\n",
       " 'NOUN>ADJ>DET': 937,\n",
       " 'CONJ>ADV>NUM': 938,\n",
       " 'ADV>ADJ>ADV': 939,\n",
       " 'VERB>PART>PROPN': 940,\n",
       " 'VERB>ADV>PRON': 941,\n",
       " 'NOUN>NUM>ADJ': 942,\n",
       " 'PUNCT>DET>PUNCT': 943,\n",
       " 'NUM>ADJ>VERB': 944,\n",
       " 'VERB>NUM>NUM': 945,\n",
       " 'NOUN>ADJ>PRON': 946,\n",
       " 'PROPN>DET>PROPN': 947,\n",
       " 'PART>PUNCT>VERB': 948,\n",
       " 'ADJ>PROPN>PART': 949,\n",
       " 'PROPN>ADV>ADJ': 950,\n",
       " 'NOUN>DET>NUM': 951,\n",
       " 'VERB>NUM>ADV': 952,\n",
       " 'ADV>DET>NUM': 953,\n",
       " 'ADV>DET>ADV': 954,\n",
       " 'ADP>ADJ>PART': 955,\n",
       " 'NOUN>CONJ>PART': 956,\n",
       " 'PART>PUNCT>CONJ': 957,\n",
       " 'ADJ>PROPN>NUM': 958,\n",
       " 'NUM>CONJ>NOUN': 959,\n",
       " 'VERB>PROPN>ADJ': 960,\n",
       " 'PRON>CONJ>PROPN': 961,\n",
       " 'NUM>VERB>CONJ': 962,\n",
       " 'PROPN>PART>PUNCT': 963,\n",
       " 'PROPN>ADV>PRON': 964,\n",
       " 'PRON>PUNCT>ADP': 965,\n",
       " 'ADV>PUNCT>PART': 966,\n",
       " 'NUM>CONJ>PROPN': 967,\n",
       " 'CONJ>PROPN>NUM': 968,\n",
       " 'PROPN>DET>VERB': 969,\n",
       " 'PROPN>ADJ>ADJ': 970,\n",
       " 'ADJ>CONJ>ADP': 971,\n",
       " 'DET>ADV>NUM': 972,\n",
       " 'NOUN>PROPN>PART': 973,\n",
       " 'PUNCT>PRON>ADJ': 974,\n",
       " 'NOUN>DET>ADV': 975,\n",
       " 'CONJ>NOUN>NUM': 976,\n",
       " 'NUM>ADP>ADP': 977,\n",
       " 'DET>PUNCT>CONJ': 978,\n",
       " 'ADP>CONJ>VERB': 979,\n",
       " 'VERB>PUNCT>PART': 980,\n",
       " 'PRON>ADJ>PUNCT': 981,\n",
       " 'NOUN>PUNCT>X': 982,\n",
       " 'VERB>CONJ>PRON': 983,\n",
       " 'VERB>CONJ>ADP': 984,\n",
       " 'PRON>ADJ>ADJ': 985,\n",
       " 'X>NOUN>PUNCT': 986,\n",
       " 'ADP>CONJ>NUM': 987,\n",
       " 'ADJ>CONJ>PROPN': 988,\n",
       " 'ADP>ADP>PRON': 989,\n",
       " 'PUNCT>ADJ>PART': 990,\n",
       " 'NUM>ADP>ADV': 991,\n",
       " 'CONJ>ADP>PUNCT': 992,\n",
       " 'ADP>CONJ>DET': 993,\n",
       " 'ADV>ADJ>NUM': 994,\n",
       " 'X>X>PUNCT': 995,\n",
       " 'NOUN>ADP>X': 996,\n",
       " 'PRON>NOUN>PUNCT': 997,\n",
       " 'SYM>NUM>NOUN': 998,\n",
       " 'CONJ>NOUN>DET': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "word2idx = {}\n",
    "for key, val in csv.reader(open(\"./vocabindex.csv\")):\n",
    "    word2idx[key] = int(val)\n",
    "    \n",
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataprep methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def textStringToPOSArray(text):\n",
    "    doc = nlp(text)\n",
    "    tags = []\n",
    "    for word in doc:\n",
    "        tags.append(word.pos_)\n",
    "    return tags\n",
    "\n",
    "def find_ngrams(input_list, n):\n",
    "  return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def getPOSTrigramsForTextString(text):\n",
    "    tags = textStringToPOSArray(text)\n",
    "    tgrams = list(trigrams(tags))\n",
    "    return tgrams\n",
    "\n",
    "def trigramsToDictKeys(trigrams):\n",
    "    keys = []\n",
    "    for trigram in trigrams:\n",
    "        keys.append('>'.join(trigram))\n",
    "    return keys\n",
    "\n",
    "def textToTrigrams(text): \n",
    "    return trigramsToDictKeys(getPOSTrigramsForTextString(text))\n",
    "\n",
    "def text_to_vector(text):\n",
    "    wordVector = np.zeros(1200)\n",
    "    for word in textToTrigrams(text):\n",
    "        index = word2idx.get(word, None)\n",
    "        if index != None:\n",
    "            wordVector[index] += 1\n",
    "    return wordVector\n",
    "\n",
    "def test_sentence(sentence):\n",
    "    positive_prob = model.predict([text_to_vector(sentence)])[0][1]\n",
    "    print('Sentence: {}'.format(sentence))\n",
    "    print('P(positive) = {:.3f} :'.format(positive_prob), \n",
    "          'Positive' if positive_prob > 0.5 else 'Negative')\n",
    "    return positive_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Since she never saw that movie.\n",
      "P(positive) = 1.000 : Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999998807907104"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Since she never saw that movie.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: We should invite her, since she never saw that movie.\n",
      "P(positive) = 1.000 : Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"We should invite her, since she never saw that movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Standing on the edge of the cliff looking down.\n",
      "P(positive) = 0.998 : Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.998099148273468"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Standing on the edge of the cliff looking down.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Donald\n",
      "P(positive) = 0.993 : Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9931533336639404"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Donald\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Standing on the edge of the cliff looking down, Donald could see a boat.\n",
      "P(positive) = 0.918 : Positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.918357789516449"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"Standing on the edge of the cliff looking down, Donald could see a boat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [\"Ate the Cake.\",\n",
    "\"Washed the dishes.\",\n",
    "\"Did my homework.\",\n",
    "\"Ran a mile.\",\n",
    "\"Went fishing.\",\n",
    "\"Made the bed today.\",\n",
    "\"Traveled to Europe.\",\n",
    "\"Saw a movie.\",\n",
    "\"Sharpened the pencil.\",\n",
    "\"Playing the guitar.\",\n",
    "\"Completing the assignment.\",\n",
    "\"Celebrating the birthday.\",\n",
    "\"Always working before unfriendly crowds.\",\n",
    "\"Dragging his heels a little in the fine dust.\",\n",
    "\"Creeping warily under the shadows of tottering walls.\",\n",
    "\"Watching the mower at work, feeling the warm, soft sunshine seep into his bones.\",\n",
    "\"Worrying that a meteor or chunk of space debris will conk her on the head.\",\n",
    "\"Invented by an Indiana housewife in.\",\n",
    "\"Driven by a steam engine.\",\n",
    "\"Stuck in the back of the closet behind the obsolete computer.\",\n",
    "\"Punctuated by the white lightning of hunger and the flickering of fear.\",\n",
    "\"Caged in a dingy mesh of fire escapes.\",\n",
    "\"Propelled by short sweeps of its crescent tail.\",\n",
    "\"And dashed through the downpour as raindrops softened the hairspray shell holding her elaborate coif in place.\",\n",
    "\"But knew that all of his effort would prove useless in the long run.\",\n",
    "\"Took the thick book and, with a heavy sigh, loaded it on top of her research pile.\",\n",
    "\"And let the raccoons, opossums, and armadillos that visit the yard eat the leftovers..\",\n",
    "\"A red convertible with fancy rims and fuzzy dice hanging from the rearview mirror.\",\n",
    "\"The unprepared student who was always begging for an extra pencil and a couple sheets of blank paper.\",\n",
    "\"A slacker wasting his afternoon in front of the television.\",\n",
    "\"A dog around whom people need to guard their fingers and food.\",\n",
    "\"A beautiful day, perfect for a picnic.\",\n",
    "\"The best teacher in the world.\",\n",
    "\"A world class chess player.\",\n",
    "\"A young Peace Corps worker.\",\n",
    "\"The student slurping hot soup.\",\n",
    "\"A young woman whose hair reaches her waist.\",\n",
    "\"To explain why he had brought Squeeze, his seven-foot pet python, to Mr Parker’s English class.\",\n",
    "\"To figure out what we’re doing wrong.\",\n",
    "\"To keep the floor clean.\",\n",
    "\"To stay in shape.\",\n",
    "\"To gain her mother’s approval.\",\n",
    "\"To make more friends.\",\n",
    "\"To get to know people in the neighborhood.\",\n",
    "\"To smash a spider.\",\n",
    "\"To kick the ball past the dazed goalie.\",\n",
    "\"To lick the grease from his shiny fingers despite the disapproving glances of his girlfriend Gloria.\",\n",
    "\"To finish her shift without spilling another pizza into a customer’s lap.\",\n",
    "\"To keep their customers happy.\",\n",
    "\"To figure out how to improve my painting.\",\n",
    "\"How to do it.\",\n",
    "\"Including the dog with three legs and the cat with one eye.\",\n",
    "\"Such as leaving the stove on and teasing mean dogs.\",\n",
    "\"After the movie is over.\",\n",
    "\"After the rain stops.\",\n",
    "\"Although I’m not hungry.\",\n",
    "\"As I was walking home.\",\n",
    "\"As if it were by divine providence.\",\n",
    "\"As long as you behave yourself.\",\n",
    "\"As soon as I finish my homework.\",\n",
    "\"As though she really knew how to sew.\",\n",
    "\"As his ex-girlfriend Gigi chased him down the interstate.\",\n",
    "\"Because he was so angry.\",\n",
    "\"Because I like it.\",\n",
    "\"Because his car is in the shop.\",\n",
    "\"Before I go to bed.\",\n",
    "\"Even little kids.\",\n",
    "\"If you do that again.\",\n",
    "\"If you want to go.\",\n",
    "\"Even though I don’t like pasta.\",\n",
    "\"In case I’m late.\",\n",
    "\"In that both cats and dogs are pets.\",\n",
    "\"In order that we don’t lose track of attendance.\",\n",
    "\"Insofar as we are friends.\",\n",
    "\"Just as I got home.\",\n",
    "\"No matter how hard I try.\",\n",
    "\"Now that you’re here.\",\n",
    "\"Once I finish my homework.\",\n",
    "\"Provided that you behave.\",\n",
    "\"Rather than bake a cake.\",\n",
    "\"So I don’t forget.\",\n",
    "\"So that we don’t get lost.\",\n",
    "\"Than.\",\n",
    "\"That thing you do.\",\n",
    "\"Though she doesn’t speak French.\",\n",
    "\"Till I get home from work.\",\n",
    "\"Unless I earn enough money.\",\n",
    "\"Until I’m old enough.\",\n",
    "\"When you finally take the test.\",\n",
    "\"Whenever I ask how you’re doing.\",\n",
    "\"Where you go to school.\",\n",
    "\"Whereas chimpanzees use tools.\",\n",
    "\"Wherever we end up.\",\n",
    "\"Whether or not we succeed.\",\n",
    "\"Since you asked.\",\n",
    "\"Since we finished the test.\",\n",
    "\"Since Sarah ate cake.\",\n",
    "\"While we were fishing.\",\n",
    "\"While some primates live in groups.\",\n",
    "\"While I was sleeping.\",\n",
    "\"Which makes me hungry.\",\n",
    "\"Whichever you choose.\",\n",
    "\"Who participated in the program.\",\n",
    "\"Whoever wants to improve the writing skill.\",\n",
    "\"Whom I met yesterday.\",\n",
    "\"Whomever you care about.\",\n",
    "\"Whose water bottle is on the table.\",\n",
    "\"Where the wind blows.\",\n",
    "\"When I finish my homework.\",\n",
    "\"Why this happened.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Ate the Cake.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Washed the dishes.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Did my homework.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Ran a mile.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Went fishing.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Made the bed today.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Traveled to Europe.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Saw a movie.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Sharpened the pencil.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Playing the guitar.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Completing the assignment.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Celebrating the birthday.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Always working before unfriendly crowds.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Dragging his heels a little in the fine dust.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Creeping warily under the shadows of tottering walls.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Watching the mower at work, feeling the warm, soft sunshine seep into his bones.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Worrying that a meteor or chunk of space debris will conk her on the head.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Invented by an Indiana housewife in.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Driven by a steam engine.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Stuck in the back of the closet behind the obsolete computer.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Punctuated by the white lightning of hunger and the flickering of fear.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Caged in a dingy mesh of fire escapes.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Propelled by short sweeps of its crescent tail.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: And dashed through the downpour as raindrops softened the hairspray shell holding her elaborate coif in place.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: But knew that all of his effort would prove useless in the long run.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Took the thick book and, with a heavy sigh, loaded it on top of her research pile.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: And let the raccoons, opossums, and armadillos that visit the yard eat the leftovers..\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A red convertible with fancy rims and fuzzy dice hanging from the rearview mirror.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: The unprepared student who was always begging for an extra pencil and a couple sheets of blank paper.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A slacker wasting his afternoon in front of the television.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A dog around whom people need to guard their fingers and food.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A beautiful day, perfect for a picnic.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: The best teacher in the world.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A world class chess player.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A young Peace Corps worker.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: The student slurping hot soup.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: A young woman whose hair reaches her waist.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To explain why he had brought Squeeze, his seven-foot pet python, to Mr Parker’s English class.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To figure out what we’re doing wrong.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To keep the floor clean.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To stay in shape.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To gain her mother’s approval.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To make more friends.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To get to know people in the neighborhood.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To smash a spider.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To kick the ball past the dazed goalie.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To lick the grease from his shiny fingers despite the disapproving glances of his girlfriend Gloria.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To finish her shift without spilling another pizza into a customer’s lap.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To keep their customers happy.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: To figure out how to improve my painting.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: How to do it.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Including the dog with three legs and the cat with one eye.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Such as leaving the stove on and teasing mean dogs.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: After the movie is over.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: After the rain stops.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Although I’m not hungry.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As I was walking home.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As if it were by divine providence.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As long as you behave yourself.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As soon as I finish my homework.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As though she really knew how to sew.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: As his ex-girlfriend Gigi chased him down the interstate.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Because he was so angry.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Because I like it.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Because his car is in the shop.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Before I go to bed.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Even little kids.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: If you do that again.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: If you want to go.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Even though I don’t like pasta.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: In case I’m late.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: In that both cats and dogs are pets.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: In order that we don’t lose track of attendance.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Insofar as we are friends.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Just as I got home.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: No matter how hard I try.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Now that you’re here.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Once I finish my homework.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Provided that you behave.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Rather than bake a cake.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: So I don’t forget.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: So that we don’t get lost.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Than.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: That thing you do.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Though she doesn’t speak French.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Till I get home from work.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Unless I earn enough money.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Until I’m old enough.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: When you finally take the test.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whenever I ask how you’re doing.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Where you go to school.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whereas chimpanzees use tools.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Wherever we end up.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whether or not we succeed.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Since you asked.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Since we finished the test.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Since Sarah ate cake.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: While we were fishing.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: While some primates live in groups.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: While I was sleeping.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Which makes me hungry.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whichever you choose.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Who participated in the program.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whoever wants to improve the writing skill.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whom I met yesterday.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whomever you care about.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Whose water bottle is on the table.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Where the wind blows.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: When I finish my homework.\n",
      "P(positive) = 0.000 : Negative\n",
      "Sentence: Why this happened.\n",
      "P(positive) = 0.000 : Negative\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for sentence in data:\n",
    "    if test_sentence(sentence) < 0.5:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 9427QD\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37365  | total loss: \u001b[1m\u001b[32m0.02047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 015 | loss: 0.02047 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37366  | total loss: \u001b[1m\u001b[32m0.01848\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 016 | loss: 0.01848 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37367  | total loss: \u001b[1m\u001b[32m0.01669\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 017 | loss: 0.01669 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37368  | total loss: \u001b[1m\u001b[32m0.01507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 018 | loss: 0.01507 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37369  | total loss: \u001b[1m\u001b[32m0.01362\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 019 | loss: 0.01362 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37370  | total loss: \u001b[1m\u001b[32m0.01231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 020 | loss: 0.01231 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37371  | total loss: \u001b[1m\u001b[32m0.01112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 021 | loss: 0.01112 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37372  | total loss: \u001b[1m\u001b[32m0.01006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 022 | loss: 0.01006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37373  | total loss: \u001b[1m\u001b[32m0.00910\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 023 | loss: 0.00910 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37374  | total loss: \u001b[1m\u001b[32m0.00823\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 024 | loss: 0.00823 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 9AFZA5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37375  | total loss: \u001b[1m\u001b[32m0.00745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 025 | loss: 0.00745 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37376  | total loss: \u001b[1m\u001b[32m0.00680\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 026 | loss: 0.00680 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37377  | total loss: \u001b[1m\u001b[32m0.00621\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 027 | loss: 0.00621 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37378  | total loss: \u001b[1m\u001b[32m0.00567\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 028 | loss: 0.00567 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37379  | total loss: \u001b[1m\u001b[32m0.00518\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 029 | loss: 0.00518 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37380  | total loss: \u001b[1m\u001b[32m0.00474\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 030 | loss: 0.00474 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37381  | total loss: \u001b[1m\u001b[32m0.00434\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 031 | loss: 0.00434 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37382  | total loss: \u001b[1m\u001b[32m0.00397\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 032 | loss: 0.00397 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37383  | total loss: \u001b[1m\u001b[32m0.00364\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 033 | loss: 0.00364 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37384  | total loss: \u001b[1m\u001b[32m0.00334\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 034 | loss: 0.00334 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: VPUEMO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37385  | total loss: \u001b[1m\u001b[32m0.00306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 035 | loss: 0.00306 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37386  | total loss: \u001b[1m\u001b[32m0.00297\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 036 | loss: 0.00297 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37387  | total loss: \u001b[1m\u001b[32m0.00286\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 037 | loss: 0.00286 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37388  | total loss: \u001b[1m\u001b[32m0.00274\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 038 | loss: 0.00274 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37389  | total loss: \u001b[1m\u001b[32m0.00262\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 039 | loss: 0.00262 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37390  | total loss: \u001b[1m\u001b[32m0.00249\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 040 | loss: 0.00249 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37391  | total loss: \u001b[1m\u001b[32m0.00237\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 041 | loss: 0.00237 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37392  | total loss: \u001b[1m\u001b[32m0.00225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 042 | loss: 0.00225 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37393  | total loss: \u001b[1m\u001b[32m0.00213\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 043 | loss: 0.00213 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37394  | total loss: \u001b[1m\u001b[32m0.00202\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 044 | loss: 0.00202 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PJ82FF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37395  | total loss: \u001b[1m\u001b[32m0.00191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 045 | loss: 0.00191 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37396  | total loss: \u001b[1m\u001b[32m0.00172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 046 | loss: 0.00172 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37397  | total loss: \u001b[1m\u001b[32m0.00155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 047 | loss: 0.00155 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37398  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 048 | loss: 0.00140 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37399  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 049 | loss: 0.00126 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37400  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 050 | loss: 0.00114 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37401  | total loss: \u001b[1m\u001b[32m0.00103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 051 | loss: 0.00103 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37402  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 052 | loss: 0.00093 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37403  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 053 | loss: 0.00084 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37404  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 054 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: U65GT9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37405  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 055 | loss: 0.00068 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37406  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 056 | loss: 0.00063 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37407  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 057 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37408  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 058 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37409  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 059 | loss: 0.00051 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37410  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 060 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37411  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 061 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37412  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 062 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37413  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 063 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37414  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 064 | loss: 0.00037 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: SH9V8N\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37415  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 065 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37416  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 066 | loss: 0.00034 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37417  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 067 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37418  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 068 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37419  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 069 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37420  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 070 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37421  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 071 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37422  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 072 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37423  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 073 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37424  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 074 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 9S2FYU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37425  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 075 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37426  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 076 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37427  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 077 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37428  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 078 | loss: 0.00067 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37429  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 079 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37430  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 080 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37431  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 081 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37432  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 082 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37433  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 083 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37434  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 084 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PSLMLC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37435  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 085 | loss: 0.00075 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37436  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 086 | loss: 0.00071 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37437  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 087 | loss: 0.00068 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37438  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 088 | loss: 0.00064 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37439  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 089 | loss: 0.00061 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37440  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 090 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37441  | total loss: \u001b[1m\u001b[32m0.00056\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 091 | loss: 0.00056 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37442  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 092 | loss: 0.00054 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37443  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 093 | loss: 0.00052 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37444  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 094 | loss: 0.00050 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Q4EFIJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37445  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 095 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37446  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 096 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37447  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 097 | loss: 0.00044 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37448  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 098 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37449  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 099 | loss: 0.00041 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37450  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 100 | loss: 0.00040 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37451  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 101 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37452  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 102 | loss: 0.00037 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37453  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 103 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37454  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 104 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CF8Z7R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37455  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 105 | loss: 0.00034 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37456  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 106 | loss: 0.00033 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37457  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 107 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37458  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 108 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37459  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 109 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37460  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 110 | loss: 0.00030 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37461  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 111 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37462  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 112 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37463  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 113 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37464  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 114 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7PN0R2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37465  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 115 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37466  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 116 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37467  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 117 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37468  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 118 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37469  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 119 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37470  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 120 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37471  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 121 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37472  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 122 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37473  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 123 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37474  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 124 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5WFUH5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37475  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 125 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37476  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 126 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37477  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 127 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37478  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 128 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37479  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 129 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37480  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 130 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37481  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 131 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37482  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 132 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37483  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 133 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37484  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 134 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: VMPBRH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37485  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 135 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37486  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 136 | loss: 0.00154 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37487  | total loss: \u001b[1m\u001b[32m0.00141\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 137 | loss: 0.00141 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37488  | total loss: \u001b[1m\u001b[32m0.00130\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 138 | loss: 0.00130 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37489  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 139 | loss: 0.00120 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37490  | total loss: \u001b[1m\u001b[32m0.00111\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 140 | loss: 0.00111 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37491  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 141 | loss: 0.00102 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37492  | total loss: \u001b[1m\u001b[32m0.00095\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 142 | loss: 0.00095 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37493  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 143 | loss: 0.00088 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37494  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 144 | loss: 0.00081 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: OXKV1D\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37495  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 145 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37496  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 146 | loss: 0.00068 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37497  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 147 | loss: 0.00061 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37498  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 148 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37499  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 149 | loss: 0.00050 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37500  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 150 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37501  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 151 | loss: 0.00041 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37502  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 152 | loss: 0.00037 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37503  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.00033 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37504  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 154 | loss: 0.00030 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: GJOC8E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37505  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 155 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37506  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 156 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37507  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 157 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37508  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 158 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37509  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 159 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37510  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 160 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37511  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 161 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37512  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 162 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37513  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 163 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37514  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 164 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: BHMHZF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37515  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 165 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37516  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 166 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37517  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 167 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37518  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 168 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37519  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 169 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37520  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 170 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37521  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 171 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37522  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 172 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37523  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 173 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37524  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 174 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "[ 2.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: XHCBML\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37525  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 175 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37526  | total loss: \u001b[1m\u001b[32m0.01303\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 176 | loss: 0.01303 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37527  | total loss: \u001b[1m\u001b[32m0.01173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 177 | loss: 0.01173 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37528  | total loss: \u001b[1m\u001b[32m0.01056\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.01056 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37529  | total loss: \u001b[1m\u001b[32m0.00950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 179 | loss: 0.00950 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37530  | total loss: \u001b[1m\u001b[32m0.00855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 180 | loss: 0.00855 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37531  | total loss: \u001b[1m\u001b[32m0.00770\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 181 | loss: 0.00770 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37532  | total loss: \u001b[1m\u001b[32m0.00693\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 182 | loss: 0.00693 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37533  | total loss: \u001b[1m\u001b[32m0.00623\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 183 | loss: 0.00623 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37534  | total loss: \u001b[1m\u001b[32m0.00561\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 184 | loss: 0.00561 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: H4NDB8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37535  | total loss: \u001b[1m\u001b[32m0.00505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 185 | loss: 0.00505 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37536  | total loss: \u001b[1m\u001b[32m0.00457\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 186 | loss: 0.00457 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37537  | total loss: \u001b[1m\u001b[32m0.00413\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 187 | loss: 0.00413 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37538  | total loss: \u001b[1m\u001b[32m0.00374\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 188 | loss: 0.00374 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37539  | total loss: \u001b[1m\u001b[32m0.00339\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 189 | loss: 0.00339 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37540  | total loss: \u001b[1m\u001b[32m0.00307\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 190 | loss: 0.00307 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37541  | total loss: \u001b[1m\u001b[32m0.00278\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 191 | loss: 0.00278 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37542  | total loss: \u001b[1m\u001b[32m0.00252\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 192 | loss: 0.00252 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37543  | total loss: \u001b[1m\u001b[32m0.00229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 193 | loss: 0.00229 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37544  | total loss: \u001b[1m\u001b[32m0.00208\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 194 | loss: 0.00208 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 1GQEOE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37545  | total loss: \u001b[1m\u001b[32m0.00189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 195 | loss: 0.00189 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37546  | total loss: \u001b[1m\u001b[32m0.00170\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 196 | loss: 0.00170 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37547  | total loss: \u001b[1m\u001b[32m0.00153\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 197 | loss: 0.00153 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37548  | total loss: \u001b[1m\u001b[32m0.00138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 198 | loss: 0.00138 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37549  | total loss: \u001b[1m\u001b[32m0.00124\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 199 | loss: 0.00124 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37550  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 200 | loss: 0.00112 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37551  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 201 | loss: 0.00101 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37552  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 202 | loss: 0.00091 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37553  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 203 | loss: 0.00082 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37554  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 204 | loss: 0.00074 -- iter: 1/1\n",
      "--\n",
      "[ 2.  2.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: TW1LD6\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37555  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 205 | loss: 0.00067 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37556  | total loss: \u001b[1m\u001b[32m0.00084\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 206 | loss: 0.00084 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37557  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 207 | loss: 0.00090 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37558  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 208 | loss: 0.00091 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37559  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 209 | loss: 0.00090 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37560  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 210 | loss: 0.00088 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37561  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 211 | loss: 0.00085 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37562  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 212 | loss: 0.00082 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37563  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 213 | loss: 0.00079 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37564  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 214 | loss: 0.00075 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3CGZMQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37565  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 215 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37566  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 216 | loss: 0.00065 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37567  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 217 | loss: 0.00058 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37568  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 218 | loss: 0.00052 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37569  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 219 | loss: 0.00047 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37570  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 220 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37571  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 221 | loss: 0.00038 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37572  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 222 | loss: 0.00034 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37573  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 223 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37574  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 224 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: W4KNDK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37575  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 225 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37576  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 226 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37577  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 227 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37578  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 228 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37579  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 229 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37580  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 230 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37581  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 231 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37582  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 232 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37583  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 233 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37584  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 234 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: KV7QH2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37585  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 235 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37586  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 236 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37587  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 237 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37588  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 238 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37589  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 239 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37590  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 240 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37591  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 241 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37592  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 242 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37593  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 243 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37594  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 244 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LA406T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37595  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 245 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37596  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 246 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37597  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 247 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37598  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 248 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37599  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 249 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37600  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 250 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37601  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 251 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37602  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 252 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37603  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 253 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37604  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 254 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WYQJ9A\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37605  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 255 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37606  | total loss: \u001b[1m\u001b[32m0.00097\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 256 | loss: 0.00097 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37607  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 257 | loss: 0.00088 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37608  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 258 | loss: 0.00080 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37609  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 259 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37610  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 260 | loss: 0.00066 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37611  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 261 | loss: 0.00060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37612  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 262 | loss: 0.00054 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37613  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 263 | loss: 0.00049 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37614  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 264 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3FVC8R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37615  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 265 | loss: 0.00041 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37616  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 266 | loss: 0.00037 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37617  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 267 | loss: 0.00033 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37618  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 268 | loss: 0.00030 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37619  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 269 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37620  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 270 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37621  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 271 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37622  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 272 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37623  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 273 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37624  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 274 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: IP4WSW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37625  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 275 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37626  | total loss: \u001b[1m\u001b[32m0.01059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 276 | loss: 0.01059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37627  | total loss: \u001b[1m\u001b[32m0.00953\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 277 | loss: 0.00953 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37628  | total loss: \u001b[1m\u001b[32m0.00858\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 278 | loss: 0.00858 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37629  | total loss: \u001b[1m\u001b[32m0.00772\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 279 | loss: 0.00772 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37630  | total loss: \u001b[1m\u001b[32m0.00695\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 280 | loss: 0.00695 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37631  | total loss: \u001b[1m\u001b[32m0.00625\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 281 | loss: 0.00625 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37632  | total loss: \u001b[1m\u001b[32m0.00563\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 282 | loss: 0.00563 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37633  | total loss: \u001b[1m\u001b[32m0.00506\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 283 | loss: 0.00506 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37634  | total loss: \u001b[1m\u001b[32m0.00456\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 284 | loss: 0.00456 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ITY0FA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37635  | total loss: \u001b[1m\u001b[32m0.00410\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 285 | loss: 0.00410 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37636  | total loss: \u001b[1m\u001b[32m0.00382\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 286 | loss: 0.00382 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37637  | total loss: \u001b[1m\u001b[32m0.00355\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 287 | loss: 0.00355 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37638  | total loss: \u001b[1m\u001b[32m0.00330\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 288 | loss: 0.00330 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37639  | total loss: \u001b[1m\u001b[32m0.00306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 289 | loss: 0.00306 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37640  | total loss: \u001b[1m\u001b[32m0.00283\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 290 | loss: 0.00283 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37641  | total loss: \u001b[1m\u001b[32m0.00262\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 291 | loss: 0.00262 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37642  | total loss: \u001b[1m\u001b[32m0.00243\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 292 | loss: 0.00243 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37643  | total loss: \u001b[1m\u001b[32m0.00225\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 293 | loss: 0.00225 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37644  | total loss: \u001b[1m\u001b[32m0.00208\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 294 | loss: 0.00208 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: MVKPO2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37645  | total loss: \u001b[1m\u001b[32m0.00193\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 295 | loss: 0.00193 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37646  | total loss: \u001b[1m\u001b[32m0.00180\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 296 | loss: 0.00180 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37647  | total loss: \u001b[1m\u001b[32m0.00167\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 297 | loss: 0.00167 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37648  | total loss: \u001b[1m\u001b[32m0.00155\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 298 | loss: 0.00155 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37649  | total loss: \u001b[1m\u001b[32m0.00143\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 299 | loss: 0.00143 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37650  | total loss: \u001b[1m\u001b[32m0.00132\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 300 | loss: 0.00132 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37651  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 301 | loss: 0.00122 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37652  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 302 | loss: 0.00113 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37653  | total loss: \u001b[1m\u001b[32m0.00104\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 303 | loss: 0.00104 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37654  | total loss: \u001b[1m\u001b[32m0.00096\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 304 | loss: 0.00096 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Y0CZ0C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37655  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 305 | loss: 0.00088 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37656  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 306 | loss: 0.00085 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37657  | total loss: \u001b[1m\u001b[32m0.00082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 307 | loss: 0.00082 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37658  | total loss: \u001b[1m\u001b[32m0.00079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 308 | loss: 0.00079 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37659  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 309 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37660  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 310 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37661  | total loss: \u001b[1m\u001b[32m0.00069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 311 | loss: 0.00069 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37662  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 312 | loss: 0.00066 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37663  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 313 | loss: 0.00063 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37664  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 314 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: K2EQK2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37665  | total loss: \u001b[1m\u001b[32m0.00057\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 315 | loss: 0.00057 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37666  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 316 | loss: 0.00051 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37667  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 317 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37668  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 318 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37669  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 319 | loss: 0.00038 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37670  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 320 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37671  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 321 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37672  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 322 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37673  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 323 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37674  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 324 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 759AC5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37675  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 325 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37676  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 326 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37677  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 327 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37678  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 328 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37679  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 329 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37680  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 330 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37681  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 331 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37682  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 332 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37683  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 333 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37684  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 334 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: UT3D0M\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37685  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 335 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37686  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 336 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37687  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 337 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37688  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 338 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37689  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 339 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37690  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 340 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37691  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 341 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37692  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 342 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37693  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 343 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37694  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 344 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 9FIAZ0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37695  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 345 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37696  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 346 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37697  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 347 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37698  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 348 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37699  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 349 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37700  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 350 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37701  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 351 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37702  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 352 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37703  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 353 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37704  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 354 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: UANAA7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37705  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 355 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37706  | total loss: \u001b[1m\u001b[32m0.00377\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 356 | loss: 0.00377 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37707  | total loss: \u001b[1m\u001b[32m0.00340\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 357 | loss: 0.00340 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37708  | total loss: \u001b[1m\u001b[32m0.00306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 358 | loss: 0.00306 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37709  | total loss: \u001b[1m\u001b[32m0.00275\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 359 | loss: 0.00275 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37710  | total loss: \u001b[1m\u001b[32m0.00248\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 360 | loss: 0.00248 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37711  | total loss: \u001b[1m\u001b[32m0.00223\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 361 | loss: 0.00223 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37712  | total loss: \u001b[1m\u001b[32m0.00201\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 362 | loss: 0.00201 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37713  | total loss: \u001b[1m\u001b[32m0.00181\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 363 | loss: 0.00181 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37714  | total loss: \u001b[1m\u001b[32m0.00162\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 364 | loss: 0.00162 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: GMHMTR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37715  | total loss: \u001b[1m\u001b[32m0.00146\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 365 | loss: 0.00146 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37716  | total loss: \u001b[1m\u001b[32m0.00137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 366 | loss: 0.00137 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37717  | total loss: \u001b[1m\u001b[32m0.00129\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 367 | loss: 0.00129 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37718  | total loss: \u001b[1m\u001b[32m0.00121\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 368 | loss: 0.00121 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37719  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 369 | loss: 0.00114 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37720  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 370 | loss: 0.00108 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37721  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 371 | loss: 0.00101 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37722  | total loss: \u001b[1m\u001b[32m0.00095\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 372 | loss: 0.00095 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37723  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 373 | loss: 0.00090 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37724  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 374 | loss: 0.00085 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LG4ZFB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37725  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 375 | loss: 0.00080 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37726  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 376 | loss: 0.00073 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37727  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 377 | loss: 0.00067 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37728  | total loss: \u001b[1m\u001b[32m0.00061\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 378 | loss: 0.00061 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37729  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 379 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37730  | total loss: \u001b[1m\u001b[32m0.00051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 380 | loss: 0.00051 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37731  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 381 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37732  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 382 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37733  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 383 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37734  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 384 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: R2HQI7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37735  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 385 | loss: 0.00033 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37736  | total loss: \u001b[1m\u001b[32m0.00612\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 386 | loss: 0.00612 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37737  | total loss: \u001b[1m\u001b[32m0.00551\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 387 | loss: 0.00551 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37738  | total loss: \u001b[1m\u001b[32m0.00496\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 388 | loss: 0.00496 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37739  | total loss: \u001b[1m\u001b[32m0.00446\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 389 | loss: 0.00446 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37740  | total loss: \u001b[1m\u001b[32m0.00402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 390 | loss: 0.00402 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37741  | total loss: \u001b[1m\u001b[32m0.00361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 391 | loss: 0.00361 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37742  | total loss: \u001b[1m\u001b[32m0.00325\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 392 | loss: 0.00325 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37743  | total loss: \u001b[1m\u001b[32m0.00293\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 393 | loss: 0.00293 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37744  | total loss: \u001b[1m\u001b[32m0.00264\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 394 | loss: 0.00264 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WHJRBC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37745  | total loss: \u001b[1m\u001b[32m0.00237\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 395 | loss: 0.00237 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37746  | total loss: \u001b[1m\u001b[32m0.00213\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 396 | loss: 0.00213 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37747  | total loss: \u001b[1m\u001b[32m0.00192\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 397 | loss: 0.00192 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37748  | total loss: \u001b[1m\u001b[32m0.00173\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 398 | loss: 0.00173 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37749  | total loss: \u001b[1m\u001b[32m0.00156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 399 | loss: 0.00156 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37750  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 400 | loss: 0.00140 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37751  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 401 | loss: 0.00126 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37752  | total loss: \u001b[1m\u001b[32m0.00113\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 402 | loss: 0.00113 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37753  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 403 | loss: 0.00102 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37754  | total loss: \u001b[1m\u001b[32m0.00092\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 404 | loss: 0.00092 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CNQ9UX\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37755  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 405 | loss: 0.00083 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37756  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 406 | loss: 0.00074 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37757  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 407 | loss: 0.00067 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37758  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 408 | loss: 0.00060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37759  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 409 | loss: 0.00054 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37760  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 410 | loss: 0.00049 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37761  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 411 | loss: 0.00044 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37762  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 412 | loss: 0.00040 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37763  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 413 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37764  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 414 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: C531X8\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37765  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 415 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37766  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 416 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37767  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 417 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37768  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 418 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37769  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 419 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37770  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 420 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37771  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 421 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37772  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 422 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37773  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 423 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37774  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 424 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LNYSAI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37775  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 425 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37776  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 426 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37777  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 427 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37778  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 428 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37779  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 429 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37780  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 430 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37781  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 431 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37782  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 432 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37783  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 433 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37784  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 434 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JRVVXF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37785  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 435 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37786  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 436 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37787  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 437 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37788  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 438 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37789  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 439 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37790  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 440 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37791  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 441 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37792  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 442 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37793  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 443 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37794  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 444 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: VCCRKJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37795  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 445 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37796  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 446 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37797  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 447 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37798  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 448 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37799  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 449 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37800  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 450 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37801  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 451 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37802  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 452 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37803  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 453 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37804  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 454 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: SXZ9IS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37805  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 455 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37806  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 456 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37807  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 457 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37808  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 458 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37809  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 459 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37810  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 460 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37811  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 461 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37812  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 462 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37813  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 463 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37814  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 464 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  1.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: H4PDTL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37815  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 465 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37816  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 466 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37817  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 467 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37818  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 468 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37819  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 469 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37820  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 470 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37821  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 471 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37822  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 472 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37823  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 473 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37824  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 474 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7ETZVT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37825  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 475 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37826  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 476 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37827  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 477 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37828  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 478 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37829  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 479 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37830  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 480 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37831  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 481 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37832  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 482 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37833  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 483 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37834  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 484 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 0GG944\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37835  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 485 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37836  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 486 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37837  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 487 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37838  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 488 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37839  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 489 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37840  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 490 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37841  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 491 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37842  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 492 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37843  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 493 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37844  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 494 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: VVH4H5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37845  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 495 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37846  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 496 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37847  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 497 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37848  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 498 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37849  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 499 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37850  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 500 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37851  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 501 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37852  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 502 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37853  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 503 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37854  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 504 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 1CTVJK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37855  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 505 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37856  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 506 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37857  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 507 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37858  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 508 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37859  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 509 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37860  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 510 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37861  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 511 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37862  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 512 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37863  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 513 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37864  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 514 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: YFEFMO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37865  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 515 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37866  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 516 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37867  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 517 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37868  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 518 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37869  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 519 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37870  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 520 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37871  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 521 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37872  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 522 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37873  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 523 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37874  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 524 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: DYAGZ9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37875  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 525 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37876  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 526 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37877  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 527 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37878  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 528 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37879  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 529 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37880  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 530 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37881  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 531 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37882  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 532 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37883  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 533 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37884  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 534 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7S25N1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37885  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 535 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37886  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 536 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37887  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 537 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37888  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 538 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37889  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 539 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37890  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 540 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37891  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 541 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37892  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 542 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37893  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 543 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37894  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 544 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FXOQK1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37895  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 545 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37896  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 546 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37897  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 547 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37898  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 548 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37899  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 549 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37900  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 550 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37901  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37902  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 552 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37903  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 553 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37904  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 554 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: MWHEB7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37905  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 555 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37906  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 556 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37907  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 557 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37908  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 558 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37909  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 559 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37910  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 560 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37911  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 561 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37912  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 562 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37913  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 563 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37914  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 564 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 2MH5ZQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37915  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 565 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37916  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 566 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37917  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 567 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37918  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 568 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37919  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 569 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37920  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 570 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37921  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 571 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37922  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 572 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37923  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 573 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37924  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 574 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: NCNJGM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37925  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 575 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37926  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 576 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37927  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 577 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37928  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 578 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37929  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 579 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37930  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 580 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37931  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 581 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37932  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 582 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37933  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 583 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37934  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 584 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3YX8JG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37935  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 585 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37936  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 586 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37937  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 587 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37938  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 588 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37939  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 589 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37940  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 590 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37941  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 591 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37942  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 592 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37943  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 593 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37944  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 594 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5JZ175\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37945  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 595 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37946  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 596 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37947  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 597 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37948  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 598 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37949  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 599 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37950  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 600 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37951  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 601 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37952  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 602 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37953  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 603 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37954  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 604 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: U55M8O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37955  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 605 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37956  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 606 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37957  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 607 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37958  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 608 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37959  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 609 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37960  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 610 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37961  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 611 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37962  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 612 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37963  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 613 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37964  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 614 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: AVUUC7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37965  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 615 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37966  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 616 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37967  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 617 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37968  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 618 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37969  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 619 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37970  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 620 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37971  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 621 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37972  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 622 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37973  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 623 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37974  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 624 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JQJYS4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37975  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 625 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37976  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 626 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37977  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 627 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37978  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 628 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37979  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 629 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37980  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 630 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37981  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 631 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37982  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 632 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37983  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 633 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37984  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 634 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: EF7CEO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37985  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 635 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37986  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 636 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37987  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 637 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37988  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 638 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37989  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 639 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37990  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 640 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37991  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 641 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37992  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 642 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37993  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 643 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37994  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 644 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ICTA2V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37995  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 645 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37996  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 646 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37997  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 647 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37998  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 648 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37999  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 649 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38000  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 650 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38001  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 651 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38002  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 652 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38003  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 653 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38004  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 654 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: KJ3X6Y\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38005  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 655 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38006  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 656 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38007  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 657 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38008  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 658 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38009  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 659 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38010  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 660 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38011  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 661 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38012  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 662 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38013  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 663 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38014  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 664 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 76CF7E\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38015  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 665 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38016  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 666 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38017  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 667 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38018  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 668 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38019  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 669 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38020  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 670 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38021  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 671 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38022  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 672 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38023  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 673 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38024  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 674 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 1NS804\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38025  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 675 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38026  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 676 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38027  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 677 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38028  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 678 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38029  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 679 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38030  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 680 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38031  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 681 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38032  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 682 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38033  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 683 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38034  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 684 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: YOBALT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38035  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 685 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38036  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 686 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38037  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 687 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38038  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 688 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38039  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 689 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38040  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 690 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38041  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 691 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38042  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 692 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38043  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 693 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38044  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 694 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 6QVE5Q\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38045  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 695 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38046  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 696 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38047  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 697 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38048  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 698 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38049  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 699 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38050  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 700 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38051  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 701 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38052  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 702 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38053  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 703 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38054  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 704 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: T0YYDK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38055  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 705 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38056  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 706 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38057  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 707 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38058  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 708 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38059  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 709 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38060  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 710 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38061  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 711 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38062  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 712 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38063  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 713 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38064  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 714 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: IPSVDC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38065  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 715 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38066  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 716 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38067  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 717 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38068  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 718 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38069  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 719 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38070  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 720 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38071  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 721 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38072  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 722 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38073  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 723 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38074  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 724 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 40J5FJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38075  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 725 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38076  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 726 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38077  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 727 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38078  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 728 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38079  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 729 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38080  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 730 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38081  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 731 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38082  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 732 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38083  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 733 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38084  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 734 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: W0C3Y3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38085  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 735 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38086  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 736 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38087  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 737 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38088  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 738 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38089  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 739 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38090  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 740 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38091  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 741 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38092  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 742 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38093  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 743 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38094  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 744 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: DG4JBC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38095  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 745 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38096  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 746 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38097  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 747 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38098  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 748 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38099  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 749 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38100  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 750 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38101  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 751 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38102  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 752 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38103  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 753 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38104  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 754 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: IUG9WM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38105  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 755 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38106  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 756 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38107  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 757 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38108  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 758 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38109  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 759 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38110  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 760 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38111  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 761 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38112  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 762 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38113  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 763 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38114  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 764 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Y5HD3V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38115  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 765 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38116  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 766 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38117  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 767 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38118  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 768 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38119  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 769 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38120  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 770 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38121  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 771 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38122  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 772 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38123  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 773 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38124  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 774 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HSIYSH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38125  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 775 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38126  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 776 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38127  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 777 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38128  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 778 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38129  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 779 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38130  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 780 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38131  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 781 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38132  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 782 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38133  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 783 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38134  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 784 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7MCZ2X\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38135  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 785 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38136  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 786 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38137  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 787 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38138  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 788 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38139  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 789 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38140  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 790 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38141  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 791 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38142  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 792 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38143  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 793 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38144  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 794 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: M3WECC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38145  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 795 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38146  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 796 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38147  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 797 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38148  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 798 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38149  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 799 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38150  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 800 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38151  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 801 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38152  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 802 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38153  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 803 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38154  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 804 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5QB7NO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38155  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 805 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38156  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 806 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38157  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 807 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38158  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 808 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38159  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 809 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38160  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 810 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38161  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 811 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38162  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 812 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38163  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 813 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38164  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 814 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: F6706T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38165  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 815 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38166  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 816 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38167  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 817 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38168  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 818 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38169  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 819 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38170  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 820 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38171  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 821 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38172  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 822 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38173  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 823 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38174  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 824 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HJ11FG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38175  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 825 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38176  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 826 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38177  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 827 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38178  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 828 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38179  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 829 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38180  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 830 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38181  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 831 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38182  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 832 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38183  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 833 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38184  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 834 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 0EG0JB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38185  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 835 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38186  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 836 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38187  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 837 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38188  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 838 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38189  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 839 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38190  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 840 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38191  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 841 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38192  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 842 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38193  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 843 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38194  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 844 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 210B5U\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38195  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 845 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38196  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 846 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38197  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 847 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38198  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 848 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38199  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 849 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38200  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 850 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38201  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 851 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38202  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 852 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38203  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 853 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38204  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 854 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QFWEHW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38205  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 855 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38206  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 856 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38207  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 857 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38208  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 858 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38209  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 859 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38210  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 860 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38211  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 861 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38212  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 862 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38213  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 863 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38214  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 864 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: BWWLAO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38215  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 865 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38216  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 866 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38217  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 867 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38218  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 868 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38219  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 869 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38220  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 870 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38221  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 871 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38222  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 872 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38223  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 873 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38224  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 874 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: XEJNAN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38225  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 875 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38226  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 876 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38227  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 877 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38228  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 878 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38229  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 879 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38230  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 880 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38231  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 881 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38232  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 882 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38233  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 883 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38234  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 884 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HASXBO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38235  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 885 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38236  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 886 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38237  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 887 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38238  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 888 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38239  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 889 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38240  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 890 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38241  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 891 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38242  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 892 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38243  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 893 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38244  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 894 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JL3H4W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38245  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 895 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38246  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 896 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38247  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 897 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38248  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 898 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38249  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 899 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38250  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 900 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38251  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 901 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38252  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 902 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38253  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 903 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38254  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 904 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QIBNXV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38255  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 905 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38256  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 906 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38257  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 907 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38258  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 908 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38259  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 909 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38260  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 910 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38261  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 911 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38262  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 912 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38263  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 913 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38264  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 914 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 4SS9UL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38265  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 915 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38266  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 916 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38267  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 917 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38268  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 918 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38269  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 919 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38270  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 920 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38271  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 921 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38272  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 922 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38273  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 923 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38274  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 924 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FG8TKY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38275  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 925 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38276  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 926 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38277  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 927 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38278  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 928 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38279  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 929 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38280  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 930 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38281  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 931 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38282  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 932 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38283  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 933 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38284  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 934 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JIOU6P\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38285  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 935 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38286  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 936 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38287  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 937 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38288  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 938 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38289  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 939 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38290  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 940 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38291  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 941 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38292  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 942 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38293  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 943 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38294  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 944 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PLSX0C\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38295  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 945 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38296  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 946 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38297  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 947 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38298  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 948 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38299  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 949 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38300  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 950 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38301  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 951 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38302  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 952 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38303  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 953 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38304  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 954 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: IBZEEI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38305  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 955 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38306  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 956 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38307  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 957 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38308  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 958 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38309  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 959 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38310  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 960 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38311  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 961 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38312  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 962 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38313  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 963 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38314  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 964 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 0T90J1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38315  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 965 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38316  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 966 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38317  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 967 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38318  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 968 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38319  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 969 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38320  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 970 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38321  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 971 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38322  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 972 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38323  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 973 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38324  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 974 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: TWFP2X\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38325  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 975 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38326  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 976 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38327  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 977 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38328  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 978 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38329  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 979 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38330  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 980 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38331  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 981 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38332  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 982 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38333  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 983 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38334  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 984 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7DY0A0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38335  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 985 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38336  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 986 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38337  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 987 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38338  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 988 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38339  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 989 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38340  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 990 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38341  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 991 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38342  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 992 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38343  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 993 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38344  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 994 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: U2NXS4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38345  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 995 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38346  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 996 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38347  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 997 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38348  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 998 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38349  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 999 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38350  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1000 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38351  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1001 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38352  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1002 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38353  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1003 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38354  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1004 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FLGRH9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38355  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1005 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38356  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1006 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38357  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1007 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38358  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1008 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38359  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1009 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38360  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1010 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38361  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1011 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38362  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1012 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38363  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1013 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38364  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1014 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: J2ZL01\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38365  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1015 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38366  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1016 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38367  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1017 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38368  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1018 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38369  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1019 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38370  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1020 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38371  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1021 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38372  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1022 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38373  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1023 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38374  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1024 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LP3V7J\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38375  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1025 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38376  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1026 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38377  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1027 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38378  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1028 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38379  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1029 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38380  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1030 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38381  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1031 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38382  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1032 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38383  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1033 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38384  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1034 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: W3F4NS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38385  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1035 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38386  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1036 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38387  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1037 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38388  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1038 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38389  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1039 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38390  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1040 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38391  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1041 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38392  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1042 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38393  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1043 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38394  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1044 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: A23ANT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38395  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1045 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38396  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1046 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38397  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1047 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38398  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1048 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38399  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1049 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38400  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1050 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38401  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1051 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38402  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1052 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38403  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1053 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38404  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1054 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HT8J14\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38405  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1055 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38406  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1056 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38407  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1057 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38408  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1058 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38409  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1059 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38410  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1060 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38411  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1061 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38412  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1062 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38413  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1063 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38414  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1064 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: F5O8ZR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38415  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1065 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38416  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1066 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38417  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1067 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38418  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1068 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38419  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1069 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38420  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1070 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38421  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1071 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38422  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1072 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38423  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1073 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38424  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1074 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: BHRCAQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38425  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1075 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38426  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1076 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38427  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1077 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38428  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1078 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38429  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1079 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38430  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1080 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38431  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1081 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38432  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1082 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38433  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1083 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38434  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1084 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Z7Z2GQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38435  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1085 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38436  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1086 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38437  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1087 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38438  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1088 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38439  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1089 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38440  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1090 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38441  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1091 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38442  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1092 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38443  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1093 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38444  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1094 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WSMFCE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38445  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1095 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38446  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1096 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38447  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1097 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38448  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1098 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38449  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1099 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38450  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1100 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38451  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1101 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38452  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1102 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38453  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1103 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38454  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1104 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QT8VH7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38455  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1105 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38456  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1106 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38457  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1107 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38458  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1108 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38459  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1109 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38460  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1110 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38461  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1111 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38462  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1112 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38463  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1113 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38464  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1114 | loss: 0.00000 -- iter: 1/1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for sentence in data:\n",
    "  print(text_to_vector(sentence))\n",
    "  print(0.)\n",
    "  model.fit([text_to_vector(sentence)], to_categorical([0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 9GW1UN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 37355  | total loss: \u001b[1m\u001b[32m0.05602\u001b[0m\u001b[0m | time: 0.035s\n",
      "| SGD | epoch: 005 | loss: 0.05602 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37356  | total loss: \u001b[1m\u001b[32m0.05156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 006 | loss: 0.05156 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37357  | total loss: \u001b[1m\u001b[32m0.04652\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 007 | loss: 0.04652 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37358  | total loss: \u001b[1m\u001b[32m0.04197\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 008 | loss: 0.04197 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37359  | total loss: \u001b[1m\u001b[32m0.03787\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 009 | loss: 0.03787 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37360  | total loss: \u001b[1m\u001b[32m0.03417\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 010 | loss: 0.03417 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37361  | total loss: \u001b[1m\u001b[32m0.03083\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 011 | loss: 0.03083 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37362  | total loss: \u001b[1m\u001b[32m0.02783\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 012 | loss: 0.02783 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37363  | total loss: \u001b[1m\u001b[32m0.02511\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 013 | loss: 0.02511 -- iter: 1/1\n",
      "--\n",
      "Training Step: 37364  | total loss: \u001b[1m\u001b[32m0.02267\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 014 | loss: 0.02267 -- iter: 1/1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit([text_to_vector(data[0])], to_categorical([0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_vector(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical([1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c8a104a6df53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/donald/miniconda2/envs/py3/lib/python3.6/site-packages/tflearn/data_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, nb_classes)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "to_categorical([0, 1, 3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jjdata = [\"John ate the cake. \",\n",
    "\"Donald and Ryan washed the dishes.\",\n",
    "\"Did my homework.\",\n",
    "\"I ran a mile.\",\n",
    "\"We went fishing.\",\n",
    "\"Sharon made the bed today.\",\n",
    "\"They traveled to Europe.\",\n",
    "\"You saw a movie.\",\n",
    "\"The student sharpened the pencil.\",\n",
    "\"I’m playing the guitar.\",\n",
    "\"She is completing the assignment.\",\n",
    "\"We are celebrating the birthday.\",\n",
    "\"The artist is always working before unfriendly crowds.\",\n",
    "\"Brent’s dragging his heels a little in the fine dust.\",\n",
    "\"They were creeping warily under the shadows of tottering walls.\",\n",
    "\"He’s watching the mower at work, feeling the warm, soft sunshine seep into his bones.\",\n",
    "\"Jenny is worrying that a meteor or chunk of space debris will conk her on the head.\",\n",
    "\"It was invented by an Indiana housewife in the winter.\",\n",
    "\"The train is driven by a steam engine.\",\n",
    "\"The book is stuck in the back of the closet behind the obsolete computer.\",\n",
    "\"Every day is punctuated by the white lightning of hunger and the flickering of fear.\",\n",
    "\"You’re caged in a dingy mesh of fire escapes.\",\n",
    "\"The bird’s flight is propelled by short sweeps of its crescent tail.\",\n",
    "\"Tina dashed through the downpour as raindrops softened the hairspray shell holding her elaborate coif in place.\",\n",
    "\"Ryan tried, but knew that all of his efforts would prove useless in the long run.\",\n",
    "\"The professor took the thick book and, with a heavy sigh, loaded it on top of her research pile.\",\n",
    "\"Just relax and let the raccoons, opossums, and armadillos that visit the yard eat the leftovers.\",\n",
    "\"I drive a red convertible with fancy rims and fuzzy dice hanging from the rearview mirror.\",\n",
    "\"The unprepared student who was always begging for an extra pencil and a couple sheets of blank paper was failing the class.\",\n",
    "\"I feel like a slacker wasting his afternoon in front of the television.\",\n",
    "\"Maxwell’s a dog around whom people need to guard their fingers and food.\",\n",
    "\"This is a beautiful day, perfect for a picnic.\",\n",
    "\"The best teacher in the world is in this room.\",\n",
    "\"He’s a world class chess player.\",\n",
    "\"My best friend is a young Peace Corps worker.\",\n",
    "\"Who’s the student slurping hot soup?\",\n",
    "\"Rachel is a young woman whose hair reaches her waist.\",\n",
    "\"Tim had to explain why he had brought Squeeze, his seven-foot pet python, to Mr Parker's English class.\",\n",
    "\"It’s time to figure out what we’re doing wrong.\",\n",
    "\"To keep the floor clean, use soap.\",\n",
    "\"I want to stay in shape.\",\n",
    "\"She wants to gain her mother’s approval.\",\n",
    "\"Bryan needs to make more friends.\",\n",
    "\"To get to know people in the neighborhood, do activities.\",\n",
    "\"I smash a spider.\",\n",
    "\"I’ll try to kick the ball past the dazed goalie.\",\n",
    "\"Bryan decided to lick the grease from his shiny fingers despite the disapproving glances of his girlfriend Gloria.\",\n",
    "\"Tammy finished her shift without spilling another pizza into a customer's lap.\",\n",
    "\"Businesses try to keep their customers happy.\",\n",
    "\"I want to figure out how to improve my painting.\",\n",
    "\"I know how to do it.\",\n",
    "\"Including the dog with three legs and the cat with one eye.\",\n",
    "\"I make mistakes, such as leaving the stove on and teasing mean dogs.\",\n",
    "\"After the movie is over, they leave.\",\n",
    "\"We’ll play after the rain stops.\",\n",
    "\"Although I’m not hungry, I eat.\",\n",
    "\"I laughed as I was walking home.\",\n",
    "\"As if it were by divine providence, it happened.\",\n",
    "\"You’ll get candy as long as you behave yourself.\",\n",
    "\"Let’s go as soon as I finish my homework.\",\n",
    "\"She offered, as though she really knew how to sew.\",\n",
    "\"He cried as his ex-girlfriend Gigi chased him down the interstate.\",\n",
    "\"Because he was so angry, Steven yelled.\",\n",
    "\"I bought it because I like it.\",\n",
    "\"Because his car is in the shop, John had to walk.\",\n",
    "\"Before I go to bed, I pray.\",\n",
    "\"Even little kids can do addition.\",\n",
    "\"If you do that again, you’re in trouble.\",\n",
    "\"We can go if you want to go.\",\n",
    "\"Even though I don’t like pasta, I’ll eat it.\",\n",
    "\"Leave without me, in case I’m late.\",\n",
    "\"In that both cats and dogs are pets, they’re similar.\",\n",
    "\"Let’s take notes, in order that we don’t lose track of attendance.\",\n",
    "\"I like you insofar as we are friends.\",\n",
    "\"You arrived just as I got home.\",\n",
    "\"No matter how hard I try, I fail.\",\n",
    "\"Now that you’re here, Bill’s happy.\",\n",
    "\"I’ll do it once I finish my homework.\",\n",
    "\"You’ll get candy provided that you behave.\",\n",
    "\"Rather than bake a cake, I want to dance.\",\n",
    "\"I write so I don’t forget.\",\n",
    "\"Let’s bring a map s that we don’t get lost.\",\n",
    "\"I’m better than that.\",\n",
    "\"That thing you do is funny.\",\n",
    "\"Though she doesn’t speak French, she acts French.\",\n",
    "\"I’ll talk till I get home from work.\",\n",
    "\"I won’t quit unless I earn enough money.\",\n",
    "\"You can wait until I’m old enough.\",\n",
    "\"We’ll see when you finally take the test.\",\n",
    "\"Whenever I ask how you’re doing, you say “fine.”\",\n",
    "\"I forget where you go to school.\",\n",
    "\"Ants only use their bodies, whereas chimpanzees use tools.\",\n",
    "\"Wherever we end up, we’ll be together.\",\n",
    "\"It doesn’t matter whether or not we succeed.\",\n",
    "\"I’ll tell you, since you asked.\",\n",
    "\"Since we finished the test, let’s celebrate.\",\n",
    "\"Bryan is hungry, since Sarah ate cake.\",\n",
    "\"While we were fishing, a fish escaped.\",\n",
    "\"Humans live alone, while some primates live in groups.\",\n",
    "\"While I was sleeping, I dreamt of you.\",\n",
    "\"I skipped breakfast, which makes me hungry.\",\n",
    "\"Whichever you choose, choose well.\",\n",
    "\"I know a guy who participated in the program.\",\n",
    "\"Whoever wants to improve the writing skill uses Quill.\",\n",
    "\"That’s the girl whom I met yesterday.\",\n",
    "\"Be nice to whomever you care about.\",\n",
    "\"Ryan, whose water bottle is on the table, is late.\",\n",
    "\"Brad lives where the wind blows.\",\n",
    "\"When I finish my homework, I go to sleep.\",\n",
    "\"Who knows why this happened.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jjdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PKE0SS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38465  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1115 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38466  | total loss: \u001b[1m\u001b[32m1.15629\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1116 | loss: 1.15629 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38467  | total loss: \u001b[1m\u001b[32m1.16820\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1117 | loss: 1.16820 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38468  | total loss: \u001b[1m\u001b[32m1.05139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1118 | loss: 1.05139 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38469  | total loss: \u001b[1m\u001b[32m0.94626\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1119 | loss: 0.94626 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38470  | total loss: \u001b[1m\u001b[32m0.85164\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1120 | loss: 0.85164 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38471  | total loss: \u001b[1m\u001b[32m0.76649\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1121 | loss: 0.76649 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38472  | total loss: \u001b[1m\u001b[32m0.68985\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1122 | loss: 0.68985 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38473  | total loss: \u001b[1m\u001b[32m0.62087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1123 | loss: 0.62087 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38474  | total loss: \u001b[1m\u001b[32m0.55880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1124 | loss: 0.55880 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 7I7N8G\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38475  | total loss: \u001b[1m\u001b[32m0.50293\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1125 | loss: 0.50293 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38476  | total loss: \u001b[1m\u001b[32m0.45264\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1126 | loss: 0.45264 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38477  | total loss: \u001b[1m\u001b[32m0.40739\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1127 | loss: 0.40739 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38478  | total loss: \u001b[1m\u001b[32m0.36666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1128 | loss: 0.36666 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38479  | total loss: \u001b[1m\u001b[32m0.33001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1129 | loss: 0.33001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38480  | total loss: \u001b[1m\u001b[32m0.29701\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1130 | loss: 0.29701 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38481  | total loss: \u001b[1m\u001b[32m0.26732\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1131 | loss: 0.26732 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38482  | total loss: \u001b[1m\u001b[32m0.24060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1132 | loss: 0.24060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38483  | total loss: \u001b[1m\u001b[32m0.21655\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1133 | loss: 0.21655 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38484  | total loss: \u001b[1m\u001b[32m0.19490\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1134 | loss: 0.19490 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 08ZRS2\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38485  | total loss: \u001b[1m\u001b[32m0.17542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1135 | loss: 0.17542 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38486  | total loss: \u001b[1m\u001b[32m1.02385\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1136 | loss: 1.02385 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38487  | total loss: \u001b[1m\u001b[32m0.93143\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1137 | loss: 0.93143 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38488  | total loss: \u001b[1m\u001b[32m0.83839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1138 | loss: 0.83839 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38489  | total loss: \u001b[1m\u001b[32m0.75465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1139 | loss: 0.75465 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38490  | total loss: \u001b[1m\u001b[32m0.67928\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1140 | loss: 0.67928 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38491  | total loss: \u001b[1m\u001b[32m0.61144\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1141 | loss: 0.61144 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38492  | total loss: \u001b[1m\u001b[32m0.55039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1142 | loss: 0.55039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38493  | total loss: \u001b[1m\u001b[32m0.49544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1143 | loss: 0.49544 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38494  | total loss: \u001b[1m\u001b[32m0.44598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1144 | loss: 0.44598 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: XIKHHY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38495  | total loss: \u001b[1m\u001b[32m0.40147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1145 | loss: 0.40147 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38496  | total loss: \u001b[1m\u001b[32m0.36200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1146 | loss: 0.36200 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38497  | total loss: \u001b[1m\u001b[32m0.32615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1147 | loss: 0.32615 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38498  | total loss: \u001b[1m\u001b[32m0.29379\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1148 | loss: 0.29379 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38499  | total loss: \u001b[1m\u001b[32m0.26460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1149 | loss: 0.26460 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38500  | total loss: \u001b[1m\u001b[32m0.23830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1150 | loss: 0.23830 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38501  | total loss: \u001b[1m\u001b[32m0.21461\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1151 | loss: 0.21461 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38502  | total loss: \u001b[1m\u001b[32m0.19327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1152 | loss: 0.19327 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38503  | total loss: \u001b[1m\u001b[32m0.17406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1153 | loss: 0.17406 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38504  | total loss: \u001b[1m\u001b[32m0.15675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1154 | loss: 0.15675 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Z3I9TW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38505  | total loss: \u001b[1m\u001b[32m0.14117\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1155 | loss: 0.14117 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38506  | total loss: \u001b[1m\u001b[32m0.63762\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1156 | loss: 0.63762 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38507  | total loss: \u001b[1m\u001b[32m0.57386\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1157 | loss: 0.57386 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38508  | total loss: \u001b[1m\u001b[32m0.51647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1158 | loss: 0.51647 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38509  | total loss: \u001b[1m\u001b[32m0.46483\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1159 | loss: 0.46483 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38510  | total loss: \u001b[1m\u001b[32m0.41834\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1160 | loss: 0.41834 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38511  | total loss: \u001b[1m\u001b[32m0.37651\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1161 | loss: 0.37651 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38512  | total loss: \u001b[1m\u001b[32m0.33886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1162 | loss: 0.33886 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38513  | total loss: \u001b[1m\u001b[32m0.30498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1163 | loss: 0.30498 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38514  | total loss: \u001b[1m\u001b[32m0.27448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1164 | loss: 0.27448 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 40N456\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38515  | total loss: \u001b[1m\u001b[32m0.24703\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1165 | loss: 0.24703 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38516  | total loss: \u001b[1m\u001b[32m0.22233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1166 | loss: 0.22233 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38517  | total loss: \u001b[1m\u001b[32m0.20011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1167 | loss: 0.20011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38518  | total loss: \u001b[1m\u001b[32m0.18010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1168 | loss: 0.18010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38519  | total loss: \u001b[1m\u001b[32m0.16210\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1169 | loss: 0.16210 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38520  | total loss: \u001b[1m\u001b[32m0.14589\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1170 | loss: 0.14589 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38521  | total loss: \u001b[1m\u001b[32m0.13131\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1171 | loss: 0.13131 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38522  | total loss: \u001b[1m\u001b[32m0.11818\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1172 | loss: 0.11818 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38523  | total loss: \u001b[1m\u001b[32m0.10637\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1173 | loss: 0.10637 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38524  | total loss: \u001b[1m\u001b[32m0.09574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1174 | loss: 0.09574 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: U5D2TJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38525  | total loss: \u001b[1m\u001b[32m0.08617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1175 | loss: 0.08617 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38526  | total loss: \u001b[1m\u001b[32m0.07757\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1176 | loss: 0.07757 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38527  | total loss: \u001b[1m\u001b[32m0.06984\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1177 | loss: 0.06984 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38528  | total loss: \u001b[1m\u001b[32m0.06287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1178 | loss: 0.06287 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38529  | total loss: \u001b[1m\u001b[32m0.05661\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1179 | loss: 0.05661 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38530  | total loss: \u001b[1m\u001b[32m0.05096\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1180 | loss: 0.05096 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38531  | total loss: \u001b[1m\u001b[32m0.04589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1181 | loss: 0.04589 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38532  | total loss: \u001b[1m\u001b[32m0.04131\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1182 | loss: 0.04131 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38533  | total loss: \u001b[1m\u001b[32m0.03720\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1183 | loss: 0.03720 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38534  | total loss: \u001b[1m\u001b[32m0.03350\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1184 | loss: 0.03350 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5DNBW4\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38535  | total loss: \u001b[1m\u001b[32m0.03016\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1185 | loss: 0.03016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38536  | total loss: \u001b[1m\u001b[32m0.02717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1186 | loss: 0.02717 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38537  | total loss: \u001b[1m\u001b[32m0.02447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1187 | loss: 0.02447 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38538  | total loss: \u001b[1m\u001b[32m0.02204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1188 | loss: 0.02204 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38539  | total loss: \u001b[1m\u001b[32m0.01986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1189 | loss: 0.01986 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38540  | total loss: \u001b[1m\u001b[32m0.01789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1190 | loss: 0.01789 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38541  | total loss: \u001b[1m\u001b[32m0.01612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1191 | loss: 0.01612 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38542  | total loss: \u001b[1m\u001b[32m0.01453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1192 | loss: 0.01453 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38543  | total loss: \u001b[1m\u001b[32m0.01309\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1193 | loss: 0.01309 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38544  | total loss: \u001b[1m\u001b[32m0.01180\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1194 | loss: 0.01180 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ZA7EFZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38545  | total loss: \u001b[1m\u001b[32m0.01064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1195 | loss: 0.01064 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38546  | total loss: \u001b[1m\u001b[32m0.01250\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1196 | loss: 0.01250 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38547  | total loss: \u001b[1m\u001b[32m0.01128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1197 | loss: 0.01128 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38548  | total loss: \u001b[1m\u001b[32m0.01017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1198 | loss: 0.01017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38549  | total loss: \u001b[1m\u001b[32m0.00918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1199 | loss: 0.00918 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38550  | total loss: \u001b[1m\u001b[32m0.00828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1200 | loss: 0.00828 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38551  | total loss: \u001b[1m\u001b[32m0.00748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1201 | loss: 0.00748 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38552  | total loss: \u001b[1m\u001b[32m0.00675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1202 | loss: 0.00675 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38553  | total loss: \u001b[1m\u001b[32m0.00610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1203 | loss: 0.00610 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38554  | total loss: \u001b[1m\u001b[32m0.00551\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1204 | loss: 0.00551 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: AXCHAR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38555  | total loss: \u001b[1m\u001b[32m0.00498\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1205 | loss: 0.00498 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38556  | total loss: \u001b[1m\u001b[32m0.00449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1206 | loss: 0.00449 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38557  | total loss: \u001b[1m\u001b[32m0.00406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1207 | loss: 0.00406 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38558  | total loss: \u001b[1m\u001b[32m0.00366\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1208 | loss: 0.00366 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38559  | total loss: \u001b[1m\u001b[32m0.00331\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1209 | loss: 0.00331 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38560  | total loss: \u001b[1m\u001b[32m0.00299\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1210 | loss: 0.00299 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38561  | total loss: \u001b[1m\u001b[32m0.00270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1211 | loss: 0.00270 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38562  | total loss: \u001b[1m\u001b[32m0.00245\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1212 | loss: 0.00245 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38563  | total loss: \u001b[1m\u001b[32m0.00221\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1213 | loss: 0.00221 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38564  | total loss: \u001b[1m\u001b[32m0.00200\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1214 | loss: 0.00200 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: SOJSMG\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38565  | total loss: \u001b[1m\u001b[32m0.00182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1215 | loss: 0.00182 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38566  | total loss: \u001b[1m\u001b[32m0.00165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1216 | loss: 0.00165 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38567  | total loss: \u001b[1m\u001b[32m0.00149\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1217 | loss: 0.00149 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38568  | total loss: \u001b[1m\u001b[32m0.00136\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1218 | loss: 0.00136 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38569  | total loss: \u001b[1m\u001b[32m0.00123\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1219 | loss: 0.00123 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38570  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1220 | loss: 0.00112 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38571  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1221 | loss: 0.00102 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38572  | total loss: \u001b[1m\u001b[32m0.00093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1222 | loss: 0.00093 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38573  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1223 | loss: 0.00085 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38574  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1224 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 13VYKV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38575  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1225 | loss: 0.00071 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38576  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1226 | loss: 0.00065 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38577  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1227 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38578  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1228 | loss: 0.00054 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38579  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1229 | loss: 0.00050 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38580  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1230 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38581  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1231 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38582  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1232 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38583  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1233 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38584  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1234 | loss: 0.00034 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 01J2J7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38585  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1235 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38586  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1236 | loss: 0.00053 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38587  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1237 | loss: 0.00065 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38588  | total loss: \u001b[1m\u001b[32m0.00071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1238 | loss: 0.00071 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38589  | total loss: \u001b[1m\u001b[32m0.00075\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1239 | loss: 0.00075 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38590  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1240 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38591  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1241 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38592  | total loss: \u001b[1m\u001b[32m0.00077\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1242 | loss: 0.00077 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38593  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1243 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38594  | total loss: \u001b[1m\u001b[32m0.00074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1244 | loss: 0.00074 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: UINL2W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38595  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1245 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38596  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1246 | loss: 0.00089 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38597  | total loss: \u001b[1m\u001b[32m0.00088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1247 | loss: 0.00088 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38598  | total loss: \u001b[1m\u001b[32m0.00085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1248 | loss: 0.00085 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38599  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1249 | loss: 0.00081 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38600  | total loss: \u001b[1m\u001b[32m0.00076\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1250 | loss: 0.00076 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38601  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1251 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38602  | total loss: \u001b[1m\u001b[32m0.00067\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1252 | loss: 0.00067 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38603  | total loss: \u001b[1m\u001b[32m0.00063\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1253 | loss: 0.00063 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38604  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1254 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Y15YOM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38605  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1255 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38606  | total loss: \u001b[1m\u001b[32m0.00234\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1256 | loss: 0.00234 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38607  | total loss: \u001b[1m\u001b[32m0.00210\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1257 | loss: 0.00210 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38608  | total loss: \u001b[1m\u001b[32m0.00189\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1258 | loss: 0.00189 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38609  | total loss: \u001b[1m\u001b[32m0.00171\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1259 | loss: 0.00171 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38610  | total loss: \u001b[1m\u001b[32m0.00154\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1260 | loss: 0.00154 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38611  | total loss: \u001b[1m\u001b[32m0.00138\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1261 | loss: 0.00138 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38612  | total loss: \u001b[1m\u001b[32m0.00125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1262 | loss: 0.00125 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38613  | total loss: \u001b[1m\u001b[32m0.00112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1263 | loss: 0.00112 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38614  | total loss: \u001b[1m\u001b[32m0.00101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1264 | loss: 0.00101 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 2NDYCO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38615  | total loss: \u001b[1m\u001b[32m0.00091\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1265 | loss: 0.00091 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38616  | total loss: \u001b[1m\u001b[32m0.00264\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1266 | loss: 0.00264 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38617  | total loss: \u001b[1m\u001b[32m0.00238\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1267 | loss: 0.00238 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38618  | total loss: \u001b[1m\u001b[32m0.00214\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1268 | loss: 0.00214 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38619  | total loss: \u001b[1m\u001b[32m0.00193\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1269 | loss: 0.00193 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38620  | total loss: \u001b[1m\u001b[32m0.00173\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1270 | loss: 0.00173 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38621  | total loss: \u001b[1m\u001b[32m0.00156\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1271 | loss: 0.00156 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38622  | total loss: \u001b[1m\u001b[32m0.00140\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1272 | loss: 0.00140 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38623  | total loss: \u001b[1m\u001b[32m0.00126\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1273 | loss: 0.00126 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38624  | total loss: \u001b[1m\u001b[32m0.00114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1274 | loss: 0.00114 -- iter: 1/1\n",
      "--\n",
      "[ 2.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FLXDLO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38625  | total loss: \u001b[1m\u001b[32m0.00102\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1275 | loss: 0.00102 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38626  | total loss: \u001b[1m\u001b[32m1.05173\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1276 | loss: 1.05173 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38627  | total loss: \u001b[1m\u001b[32m0.94655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1277 | loss: 0.94655 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38628  | total loss: \u001b[1m\u001b[32m0.85190\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1278 | loss: 0.85190 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38629  | total loss: \u001b[1m\u001b[32m0.76671\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1279 | loss: 0.76671 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38630  | total loss: \u001b[1m\u001b[32m0.69004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1280 | loss: 0.69004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38631  | total loss: \u001b[1m\u001b[32m0.62103\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1281 | loss: 0.62103 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38632  | total loss: \u001b[1m\u001b[32m0.55893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1282 | loss: 0.55893 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38633  | total loss: \u001b[1m\u001b[32m0.50304\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1283 | loss: 0.50304 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38634  | total loss: \u001b[1m\u001b[32m0.45273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1284 | loss: 0.45273 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: TF6SW0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38635  | total loss: \u001b[1m\u001b[32m0.40746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1285 | loss: 0.40746 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38636  | total loss: \u001b[1m\u001b[32m0.36672\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1286 | loss: 0.36672 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38637  | total loss: \u001b[1m\u001b[32m0.33004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1287 | loss: 0.33004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38638  | total loss: \u001b[1m\u001b[32m0.29704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1288 | loss: 0.29704 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38639  | total loss: \u001b[1m\u001b[32m0.26734\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1289 | loss: 0.26734 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38640  | total loss: \u001b[1m\u001b[32m0.24061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1290 | loss: 0.24061 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38641  | total loss: \u001b[1m\u001b[32m0.21655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1291 | loss: 0.21655 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38642  | total loss: \u001b[1m\u001b[32m0.19489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1292 | loss: 0.19489 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38643  | total loss: \u001b[1m\u001b[32m0.17540\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1293 | loss: 0.17540 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38644  | total loss: \u001b[1m\u001b[32m0.15787\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1294 | loss: 0.15787 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3D7913\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38645  | total loss: \u001b[1m\u001b[32m0.14208\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1295 | loss: 0.14208 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38646  | total loss: \u001b[1m\u001b[32m0.12789\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1296 | loss: 0.12789 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38647  | total loss: \u001b[1m\u001b[32m0.11512\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1297 | loss: 0.11512 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38648  | total loss: \u001b[1m\u001b[32m0.10363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1298 | loss: 0.10363 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38649  | total loss: \u001b[1m\u001b[32m0.09328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1299 | loss: 0.09328 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38650  | total loss: \u001b[1m\u001b[32m0.08397\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1300 | loss: 0.08397 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38651  | total loss: \u001b[1m\u001b[32m0.07559\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1301 | loss: 0.07559 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38652  | total loss: \u001b[1m\u001b[32m0.06805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1302 | loss: 0.06805 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38653  | total loss: \u001b[1m\u001b[32m0.06126\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1303 | loss: 0.06126 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38654  | total loss: \u001b[1m\u001b[32m0.05515\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1304 | loss: 0.05515 -- iter: 1/1\n",
      "--\n",
      "[ 2.  2.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5Q4NVR\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38655  | total loss: \u001b[1m\u001b[32m0.04965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1305 | loss: 0.04965 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38656  | total loss: \u001b[1m\u001b[32m0.04484\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1306 | loss: 0.04484 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38657  | total loss: \u001b[1m\u001b[32m0.04047\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1307 | loss: 0.04047 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38658  | total loss: \u001b[1m\u001b[32m0.03652\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1308 | loss: 0.03652 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38659  | total loss: \u001b[1m\u001b[32m0.03294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1309 | loss: 0.03294 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38660  | total loss: \u001b[1m\u001b[32m0.02971\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1310 | loss: 0.02971 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38661  | total loss: \u001b[1m\u001b[32m0.02680\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1311 | loss: 0.02680 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38662  | total loss: \u001b[1m\u001b[32m0.02417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1312 | loss: 0.02417 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38663  | total loss: \u001b[1m\u001b[32m0.02180\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1313 | loss: 0.02180 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38664  | total loss: \u001b[1m\u001b[32m0.01966\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1314 | loss: 0.01966 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CCDKWA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38665  | total loss: \u001b[1m\u001b[32m0.01774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1315 | loss: 0.01774 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38666  | total loss: \u001b[1m\u001b[32m0.01625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1316 | loss: 0.01625 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38667  | total loss: \u001b[1m\u001b[32m0.01476\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1317 | loss: 0.01476 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38668  | total loss: \u001b[1m\u001b[32m0.01338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1318 | loss: 0.01338 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38669  | total loss: \u001b[1m\u001b[32m0.01212\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1319 | loss: 0.01212 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38670  | total loss: \u001b[1m\u001b[32m0.01097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1320 | loss: 0.01097 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38671  | total loss: \u001b[1m\u001b[32m0.00993\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1321 | loss: 0.00993 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38672  | total loss: \u001b[1m\u001b[32m0.00898\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1322 | loss: 0.00898 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38673  | total loss: \u001b[1m\u001b[32m0.00812\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1323 | loss: 0.00812 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38674  | total loss: \u001b[1m\u001b[32m0.00735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1324 | loss: 0.00735 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: SAIE1O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38675  | total loss: \u001b[1m\u001b[32m0.00665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1325 | loss: 0.00665 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38676  | total loss: \u001b[1m\u001b[32m0.00674\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1326 | loss: 0.00674 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38677  | total loss: \u001b[1m\u001b[32m0.00613\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1327 | loss: 0.00613 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38678  | total loss: \u001b[1m\u001b[32m0.00558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1328 | loss: 0.00558 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38679  | total loss: \u001b[1m\u001b[32m0.00507\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1329 | loss: 0.00507 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38680  | total loss: \u001b[1m\u001b[32m0.00460\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1330 | loss: 0.00460 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38681  | total loss: \u001b[1m\u001b[32m0.00418\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1331 | loss: 0.00418 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38682  | total loss: \u001b[1m\u001b[32m0.00379\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1332 | loss: 0.00379 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38683  | total loss: \u001b[1m\u001b[32m0.00344\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1333 | loss: 0.00344 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38684  | total loss: \u001b[1m\u001b[32m0.00312\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1334 | loss: 0.00312 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Z9O3MV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38685  | total loss: \u001b[1m\u001b[32m0.00284\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1335 | loss: 0.00284 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38686  | total loss: \u001b[1m\u001b[32m0.00264\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1336 | loss: 0.00264 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38687  | total loss: \u001b[1m\u001b[32m0.00243\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1337 | loss: 0.00243 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38688  | total loss: \u001b[1m\u001b[32m0.00223\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1338 | loss: 0.00223 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38689  | total loss: \u001b[1m\u001b[32m0.00205\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1339 | loss: 0.00205 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38690  | total loss: \u001b[1m\u001b[32m0.00187\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1340 | loss: 0.00187 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38691  | total loss: \u001b[1m\u001b[32m0.00171\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1341 | loss: 0.00171 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38692  | total loss: \u001b[1m\u001b[32m0.00157\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1342 | loss: 0.00157 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38693  | total loss: \u001b[1m\u001b[32m0.00143\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1343 | loss: 0.00143 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38694  | total loss: \u001b[1m\u001b[32m0.00131\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1344 | loss: 0.00131 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: GFUU83\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38695  | total loss: \u001b[1m\u001b[32m0.00120\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1345 | loss: 0.00120 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38696  | total loss: \u001b[1m\u001b[32m0.00108\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1346 | loss: 0.00108 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38697  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1347 | loss: 0.00098 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38698  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1348 | loss: 0.00089 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38699  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1349 | loss: 0.00080 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38700  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1350 | loss: 0.00073 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38701  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1351 | loss: 0.00066 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38702  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1352 | loss: 0.00060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38703  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1353 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38704  | total loss: \u001b[1m\u001b[32m0.00050\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1354 | loss: 0.00050 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: UQB7CM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38705  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1355 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38706  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1356 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38707  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1357 | loss: 0.00049 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38708  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1358 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38709  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1359 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38710  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1360 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38711  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1361 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38712  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1362 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38713  | total loss: \u001b[1m\u001b[32m0.00042\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1363 | loss: 0.00042 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38714  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1364 | loss: 0.00040 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: XFN7WM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38715  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1365 | loss: 0.00038 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38716  | total loss: \u001b[1m\u001b[32m0.02030\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1366 | loss: 0.02030 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38717  | total loss: \u001b[1m\u001b[32m0.01827\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1367 | loss: 0.01827 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38718  | total loss: \u001b[1m\u001b[32m0.01644\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1368 | loss: 0.01644 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38719  | total loss: \u001b[1m\u001b[32m0.01480\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1369 | loss: 0.01480 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38720  | total loss: \u001b[1m\u001b[32m0.01332\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1370 | loss: 0.01332 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38721  | total loss: \u001b[1m\u001b[32m0.01199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1371 | loss: 0.01199 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38722  | total loss: \u001b[1m\u001b[32m0.01079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1372 | loss: 0.01079 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38723  | total loss: \u001b[1m\u001b[32m0.00971\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1373 | loss: 0.00971 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38724  | total loss: \u001b[1m\u001b[32m0.00874\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1374 | loss: 0.00874 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: MQTT7Y\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38725  | total loss: \u001b[1m\u001b[32m0.00787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1375 | loss: 0.00787 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38726  | total loss: \u001b[1m\u001b[32m0.00708\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1376 | loss: 0.00708 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38727  | total loss: \u001b[1m\u001b[32m0.00638\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1377 | loss: 0.00638 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38728  | total loss: \u001b[1m\u001b[32m0.00574\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1378 | loss: 0.00574 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38729  | total loss: \u001b[1m\u001b[32m0.00517\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1379 | loss: 0.00517 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38730  | total loss: \u001b[1m\u001b[32m0.00466\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1380 | loss: 0.00466 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38731  | total loss: \u001b[1m\u001b[32m0.00420\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1381 | loss: 0.00420 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38732  | total loss: \u001b[1m\u001b[32m0.00378\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1382 | loss: 0.00378 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38733  | total loss: \u001b[1m\u001b[32m0.00341\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1383 | loss: 0.00341 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38734  | total loss: \u001b[1m\u001b[32m0.00307\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1384 | loss: 0.00307 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Q4WPCT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38735  | total loss: \u001b[1m\u001b[32m0.00276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1385 | loss: 0.00276 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38736  | total loss: \u001b[1m\u001b[32m0.00249\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1386 | loss: 0.00249 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38737  | total loss: \u001b[1m\u001b[32m0.00225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1387 | loss: 0.00225 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38738  | total loss: \u001b[1m\u001b[32m0.00203\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1388 | loss: 0.00203 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38739  | total loss: \u001b[1m\u001b[32m0.00183\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1389 | loss: 0.00183 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38740  | total loss: \u001b[1m\u001b[32m0.00166\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1390 | loss: 0.00166 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38741  | total loss: \u001b[1m\u001b[32m0.00150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1391 | loss: 0.00150 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38742  | total loss: \u001b[1m\u001b[32m0.00135\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1392 | loss: 0.00135 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38743  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1393 | loss: 0.00122 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38744  | total loss: \u001b[1m\u001b[32m0.00111\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1394 | loss: 0.00111 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 9EA352\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38745  | total loss: \u001b[1m\u001b[32m0.00100\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1395 | loss: 0.00100 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38746  | total loss: \u001b[1m\u001b[32m0.00090\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1396 | loss: 0.00090 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38747  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1397 | loss: 0.00081 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38748  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1398 | loss: 0.00073 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38749  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1399 | loss: 0.00066 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38750  | total loss: \u001b[1m\u001b[32m0.00059\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1400 | loss: 0.00059 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38751  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1401 | loss: 0.00053 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38752  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1402 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38753  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1403 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38754  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1404 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "[ 2.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: D0532H\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38755  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1405 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38756  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1406 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38757  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1407 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38758  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1408 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38759  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1409 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38760  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1410 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38761  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1411 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38762  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1412 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38763  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1413 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38764  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1414 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FFPGJ0\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38765  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1415 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38766  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1416 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38767  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1417 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38768  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1418 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38769  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1419 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38770  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1420 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38771  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1421 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38772  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1422 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38773  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1423 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38774  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1424 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: N2E19Z\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38775  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1425 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38776  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1426 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38777  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1427 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38778  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1428 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38779  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1429 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38780  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1430 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38781  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1431 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38782  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1432 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38783  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1433 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38784  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1434 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 2.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CLP5OI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38785  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1435 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38786  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1436 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38787  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1437 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38788  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1438 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38789  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1439 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38790  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1440 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38791  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1441 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38792  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1442 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38793  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1443 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38794  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1444 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: RWU1G9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38795  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1445 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38796  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1446 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38797  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1447 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38798  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1448 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38799  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1449 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38800  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1450 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38801  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1451 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38802  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1452 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38803  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1453 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38804  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1454 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: S8MS26\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38805  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1455 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38806  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1456 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38807  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1457 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38808  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1458 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38809  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1459 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38810  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1460 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38811  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1461 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38812  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1462 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38813  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1463 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38814  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1464 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 38QROB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38815  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1465 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38816  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1466 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38817  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1467 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38818  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1468 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38819  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1469 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38820  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1470 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38821  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1471 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38822  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1472 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38823  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1473 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38824  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1474 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HGL0PN\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38825  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1475 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38826  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1476 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38827  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1477 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38828  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1478 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38829  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1479 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38830  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1480 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38831  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1481 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38832  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1482 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38833  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1483 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38834  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1484 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: SA861D\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38835  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1485 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38836  | total loss: \u001b[1m\u001b[32m1.09207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1486 | loss: 1.09207 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38837  | total loss: \u001b[1m\u001b[32m0.98286\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1487 | loss: 0.98286 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38838  | total loss: \u001b[1m\u001b[32m0.88457\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1488 | loss: 0.88457 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38839  | total loss: \u001b[1m\u001b[32m0.79612\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1489 | loss: 0.79612 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38840  | total loss: \u001b[1m\u001b[32m0.71651\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1490 | loss: 0.71651 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38841  | total loss: \u001b[1m\u001b[32m0.64485\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1491 | loss: 0.64485 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38842  | total loss: \u001b[1m\u001b[32m0.58037\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1492 | loss: 0.58037 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38843  | total loss: \u001b[1m\u001b[32m0.52233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1493 | loss: 0.52233 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38844  | total loss: \u001b[1m\u001b[32m0.47010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1494 | loss: 0.47010 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: HYRHWO\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38845  | total loss: \u001b[1m\u001b[32m0.42309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1495 | loss: 0.42309 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38846  | total loss: \u001b[1m\u001b[32m0.38078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1496 | loss: 0.38078 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38847  | total loss: \u001b[1m\u001b[32m0.34270\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1497 | loss: 0.34270 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38848  | total loss: \u001b[1m\u001b[32m0.30843\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1498 | loss: 0.30843 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38849  | total loss: \u001b[1m\u001b[32m0.27759\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1499 | loss: 0.27759 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38850  | total loss: \u001b[1m\u001b[32m0.24983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1500 | loss: 0.24983 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38851  | total loss: \u001b[1m\u001b[32m0.22485\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1501 | loss: 0.22485 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38852  | total loss: \u001b[1m\u001b[32m0.20236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1502 | loss: 0.20236 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38853  | total loss: \u001b[1m\u001b[32m0.18213\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1503 | loss: 0.18213 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38854  | total loss: \u001b[1m\u001b[32m0.16391\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1504 | loss: 0.16391 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 8SOPE7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38855  | total loss: \u001b[1m\u001b[32m0.14752\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1505 | loss: 0.14752 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38856  | total loss: \u001b[1m\u001b[32m0.13282\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1506 | loss: 0.13282 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38857  | total loss: \u001b[1m\u001b[32m0.11958\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1507 | loss: 0.11958 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38858  | total loss: \u001b[1m\u001b[32m0.10765\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1508 | loss: 0.10765 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38859  | total loss: \u001b[1m\u001b[32m0.09692\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1509 | loss: 0.09692 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38860  | total loss: \u001b[1m\u001b[32m0.08725\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1510 | loss: 0.08725 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38861  | total loss: \u001b[1m\u001b[32m0.07855\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1511 | loss: 0.07855 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38862  | total loss: \u001b[1m\u001b[32m0.07072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1512 | loss: 0.07072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38863  | total loss: \u001b[1m\u001b[32m0.06367\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1513 | loss: 0.06367 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38864  | total loss: \u001b[1m\u001b[32m0.05732\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1514 | loss: 0.05732 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: TUOX4S\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38865  | total loss: \u001b[1m\u001b[32m0.05161\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1515 | loss: 0.05161 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38866  | total loss: \u001b[1m\u001b[32m0.04698\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1516 | loss: 0.04698 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38867  | total loss: \u001b[1m\u001b[32m0.04243\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1517 | loss: 0.04243 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38868  | total loss: \u001b[1m\u001b[32m0.03829\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1518 | loss: 0.03829 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38869  | total loss: \u001b[1m\u001b[32m0.03454\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1519 | loss: 0.03454 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38870  | total loss: \u001b[1m\u001b[32m0.03115\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1520 | loss: 0.03115 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38871  | total loss: \u001b[1m\u001b[32m0.02809\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1521 | loss: 0.02809 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38872  | total loss: \u001b[1m\u001b[32m0.02533\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1522 | loss: 0.02533 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38873  | total loss: \u001b[1m\u001b[32m0.02284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1523 | loss: 0.02284 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38874  | total loss: \u001b[1m\u001b[32m0.02060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1524 | loss: 0.02060 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: KIA96U\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38875  | total loss: \u001b[1m\u001b[32m0.01857\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1525 | loss: 0.01857 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38876  | total loss: \u001b[1m\u001b[32m0.01672\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1526 | loss: 0.01672 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38877  | total loss: \u001b[1m\u001b[32m0.01504\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1527 | loss: 0.01504 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38878  | total loss: \u001b[1m\u001b[32m0.01354\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1528 | loss: 0.01354 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38879  | total loss: \u001b[1m\u001b[32m0.01219\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1529 | loss: 0.01219 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38880  | total loss: \u001b[1m\u001b[32m0.01097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1530 | loss: 0.01097 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38881  | total loss: \u001b[1m\u001b[32m0.00987\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1531 | loss: 0.00987 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38882  | total loss: \u001b[1m\u001b[32m0.00888\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1532 | loss: 0.00888 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38883  | total loss: \u001b[1m\u001b[32m0.00800\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1533 | loss: 0.00800 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38884  | total loss: \u001b[1m\u001b[32m0.00720\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1534 | loss: 0.00720 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: XBIZJL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38885  | total loss: \u001b[1m\u001b[32m0.00648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1535 | loss: 0.00648 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38886  | total loss: \u001b[1m\u001b[32m0.00583\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1536 | loss: 0.00583 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38887  | total loss: \u001b[1m\u001b[32m0.00525\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1537 | loss: 0.00525 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38888  | total loss: \u001b[1m\u001b[32m0.00472\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1538 | loss: 0.00472 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38889  | total loss: \u001b[1m\u001b[32m0.00425\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1539 | loss: 0.00425 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38890  | total loss: \u001b[1m\u001b[32m0.00382\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1540 | loss: 0.00382 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38891  | total loss: \u001b[1m\u001b[32m0.00344\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1541 | loss: 0.00344 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38892  | total loss: \u001b[1m\u001b[32m0.00310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1542 | loss: 0.00310 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38893  | total loss: \u001b[1m\u001b[32m0.00279\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1543 | loss: 0.00279 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38894  | total loss: \u001b[1m\u001b[32m0.00251\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1544 | loss: 0.00251 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 6EIN5N\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38895  | total loss: \u001b[1m\u001b[32m0.00226\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1545 | loss: 0.00226 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38896  | total loss: \u001b[1m\u001b[32m0.00205\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1546 | loss: 0.00205 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38897  | total loss: \u001b[1m\u001b[32m0.00187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1547 | loss: 0.00187 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38898  | total loss: \u001b[1m\u001b[32m0.00170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1548 | loss: 0.00170 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38899  | total loss: \u001b[1m\u001b[32m0.00155\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1549 | loss: 0.00155 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38900  | total loss: \u001b[1m\u001b[32m0.00141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1550 | loss: 0.00141 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38901  | total loss: \u001b[1m\u001b[32m0.00128\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1551 | loss: 0.00128 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38902  | total loss: \u001b[1m\u001b[32m0.00117\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1552 | loss: 0.00117 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38903  | total loss: \u001b[1m\u001b[32m0.00107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1553 | loss: 0.00107 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38904  | total loss: \u001b[1m\u001b[32m0.00098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1554 | loss: 0.00098 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PIOYWI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38905  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1555 | loss: 0.00089 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38906  | total loss: \u001b[1m\u001b[32m0.00080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1556 | loss: 0.00080 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38907  | total loss: \u001b[1m\u001b[32m0.00072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1557 | loss: 0.00072 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38908  | total loss: \u001b[1m\u001b[32m0.00065\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1558 | loss: 0.00065 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38909  | total loss: \u001b[1m\u001b[32m0.00058\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1559 | loss: 0.00058 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38910  | total loss: \u001b[1m\u001b[32m0.00053\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1560 | loss: 0.00053 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38911  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1561 | loss: 0.00047 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38912  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1562 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38913  | total loss: \u001b[1m\u001b[32m0.00038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1563 | loss: 0.00038 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38914  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1564 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "[ 0.  1.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5GB7W5\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38915  | total loss: \u001b[1m\u001b[32m0.00031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1565 | loss: 0.00031 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38916  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1566 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38917  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1567 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38918  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1568 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38919  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1569 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38920  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1570 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38921  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1571 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38922  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1572 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38923  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1573 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38924  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1574 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "[ 0.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3TAO9K\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38925  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1575 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38926  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1576 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38927  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1577 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38928  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1578 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38929  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1579 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38930  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1580 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38931  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1581 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38932  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1582 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38933  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1583 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38934  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1584 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 1.  1.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 548UFQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38935  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1585 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38936  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1586 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38937  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1587 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38938  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1588 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38939  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1589 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38940  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1590 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38941  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1591 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38942  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1592 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38943  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1593 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38944  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1594 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: IZMUSY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38945  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1595 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38946  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1596 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38947  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1597 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38948  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1598 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38949  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1599 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38950  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1600 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38951  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1601 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38952  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1602 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38953  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1603 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38954  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1604 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: DNCUPV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38955  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1605 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38956  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1606 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38957  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1607 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38958  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1608 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38959  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1609 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38960  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1610 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38961  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1611 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38962  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1612 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38963  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1613 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38964  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1614 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 2OQWKT\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38965  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1615 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38966  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1616 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38967  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1617 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38968  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1618 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38969  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1619 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38970  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1620 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38971  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1621 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38972  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1622 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38973  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1623 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38974  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1624 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: BW8DJW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38975  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1625 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38976  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1626 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38977  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1627 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38978  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1628 | loss: 0.00041 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38979  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1629 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38980  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1630 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38981  | total loss: \u001b[1m\u001b[32m0.00034\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1631 | loss: 0.00034 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38982  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1632 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38983  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1633 | loss: 0.00030 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38984  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1634 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: B5DBPC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38985  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1635 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38986  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1636 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38987  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1637 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38988  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1638 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38989  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1639 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38990  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1640 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38991  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1641 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38992  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1642 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38993  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1643 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38994  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1644 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: AOUEDW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 38995  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1645 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38996  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1646 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38997  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1647 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38998  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1648 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 38999  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1649 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39000  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1650 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39001  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1651 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39002  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1652 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39003  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1653 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39004  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1654 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 1IN21J\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39005  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1655 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39006  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1656 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39007  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1657 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39008  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1658 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39009  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1659 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39010  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1660 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39011  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1661 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39012  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1662 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39013  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1663 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39014  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1664 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WTLV0Y\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39015  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1665 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39016  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1666 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39017  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1667 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39018  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1668 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39019  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1669 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39020  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1670 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39021  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1671 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39022  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1672 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39023  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1673 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39024  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1674 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: A0Q883\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39025  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1675 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39026  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1676 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39027  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1677 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39028  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1678 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39029  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1679 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39030  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1680 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39031  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1681 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39032  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1682 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39033  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1683 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39034  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1684 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CH0YKA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39035  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1685 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39036  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1686 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39037  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1687 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39038  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1688 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39039  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1689 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39040  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1690 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39041  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1691 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39042  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1692 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39043  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1693 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39044  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1694 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 6I6JFV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39045  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1695 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39046  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1696 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39047  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1697 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39048  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1698 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39049  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1699 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39050  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1700 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39051  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1701 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39052  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1702 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39053  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1703 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39054  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1704 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: PLPBK9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39055  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1705 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39056  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1706 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39057  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1707 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39058  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1708 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39059  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1709 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39060  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1710 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39061  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1711 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39062  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1712 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39063  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1713 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39064  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1714 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: KF1G3J\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39065  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1715 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39066  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1716 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39067  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1717 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39068  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1718 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39069  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1719 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39070  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1720 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39071  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1721 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39072  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1722 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39073  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1723 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39074  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1724 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: CQVYBC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39075  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1725 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39076  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1726 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39077  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1727 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39078  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1728 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39079  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1729 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39080  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1730 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39081  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1731 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39082  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1732 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39083  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1733 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39084  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1734 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5FWSJ3\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39085  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1735 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39086  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1736 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39087  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1737 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39088  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1738 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39089  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1739 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39090  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1740 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39091  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1741 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39092  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1742 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39093  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1743 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39094  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1744 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: P6WKZV\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39095  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1745 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39096  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1746 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39097  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1747 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39098  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1748 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39099  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1749 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39100  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1750 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39101  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1751 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39102  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1752 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39103  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1753 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39104  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1754 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: R5ZAT7\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39105  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1755 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39106  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1756 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39107  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1757 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39108  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1758 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39109  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1759 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39110  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1760 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39111  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1761 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39112  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1762 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39113  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1763 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39114  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1764 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: S94C89\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39115  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1765 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39116  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1766 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39117  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1767 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39118  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1768 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39119  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1769 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39120  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1770 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39121  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1771 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39122  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1772 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39123  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1773 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39124  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1774 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QC3ZHZ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39125  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1775 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39126  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1776 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39127  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1777 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39128  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1778 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39129  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1779 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39130  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1780 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39131  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1781 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39132  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1782 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39133  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1783 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39134  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1784 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: W5DBRC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39135  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1785 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39136  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1786 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39137  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1787 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39138  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1788 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39139  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1789 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39140  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1790 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39141  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1791 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39142  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1792 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39143  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1793 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39144  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1794 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QSN77V\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39145  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1795 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39146  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1796 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39147  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1797 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39148  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1798 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39149  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1799 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39150  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1800 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39151  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1801 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39152  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1802 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39153  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1803 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39154  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1804 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: YQNHVP\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39155  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1805 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39156  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1806 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39157  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1807 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39158  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1808 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39159  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1809 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39160  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1810 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39161  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1811 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39162  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1812 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39163  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1813 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39164  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1814 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 8WKJVA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39165  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1815 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39166  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1816 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39167  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1817 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39168  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1818 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39169  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1819 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39170  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1820 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39171  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1821 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39172  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1822 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39173  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1823 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39174  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1824 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: DJWXSS\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39175  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1825 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39176  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1826 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39177  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1827 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39178  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1828 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39179  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1829 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39180  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1830 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39181  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1831 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39182  | total loss: \u001b[1m\u001b[32m0.00028\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1832 | loss: 0.00028 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39183  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1833 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39184  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1834 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: U5Z1KA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39185  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1835 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39186  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1836 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39187  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1837 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39188  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1838 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39189  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1839 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39190  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1840 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39191  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1841 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39192  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1842 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39193  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1843 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39194  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1844 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JC2IVA\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39195  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1845 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39196  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1846 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39197  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1847 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39198  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1848 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39199  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1849 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39200  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1850 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39201  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1851 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39202  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1852 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39203  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1853 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39204  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1854 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 4QME91\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39205  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1855 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39206  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1856 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39207  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1857 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39208  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1858 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39209  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1859 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39210  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1860 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39211  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1861 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39212  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1862 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39213  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1863 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39214  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1864 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: RL7KEK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39215  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1865 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39216  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1866 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39217  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1867 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39218  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1868 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39219  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1869 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39220  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1870 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39221  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1871 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39222  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1872 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39223  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1873 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39224  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1874 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: H68Y1R\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39225  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1875 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39226  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1876 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39227  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1877 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39228  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1878 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39229  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1879 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39230  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1880 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39231  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1881 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39232  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1882 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39233  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1883 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39234  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1884 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: TSA1RQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39235  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1885 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39236  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1886 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39237  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1887 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39238  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1888 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39239  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1889 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39240  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1890 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39241  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1891 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39242  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1892 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39243  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1893 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39244  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1894 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 879UVM\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39245  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1895 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39246  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1896 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39247  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1897 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39248  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1898 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39249  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1899 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39250  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1900 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39251  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1901 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39252  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1902 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39253  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1903 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39254  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1904 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 1JA6JY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39255  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1905 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39256  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1906 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39257  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1907 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39258  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1908 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39259  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1909 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39260  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1910 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39261  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1911 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39262  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1912 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39263  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1913 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39264  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1914 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: X3C90O\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39265  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1915 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39266  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1916 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39267  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1917 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39268  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1918 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39269  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1919 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39270  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1920 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39271  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1921 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39272  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1922 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39273  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1923 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39274  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1924 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: BX7KMW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39275  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1925 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39276  | total loss: \u001b[1m\u001b[32m0.00087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1926 | loss: 0.00087 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39277  | total loss: \u001b[1m\u001b[32m0.00083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1927 | loss: 0.00083 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39278  | total loss: \u001b[1m\u001b[32m0.00078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1928 | loss: 0.00078 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39279  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1929 | loss: 0.00073 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39280  | total loss: \u001b[1m\u001b[32m0.00068\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1930 | loss: 0.00068 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39281  | total loss: \u001b[1m\u001b[32m0.00064\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1931 | loss: 0.00064 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39282  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1932 | loss: 0.00060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39283  | total loss: \u001b[1m\u001b[32m0.00055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1933 | loss: 0.00055 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39284  | total loss: \u001b[1m\u001b[32m0.00052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1934 | loss: 0.00052 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 5BPPRL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39285  | total loss: \u001b[1m\u001b[32m0.00048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1935 | loss: 0.00048 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39286  | total loss: \u001b[1m\u001b[32m0.00043\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1936 | loss: 0.00043 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39287  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1937 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39288  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1938 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39289  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1939 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39290  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1940 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39291  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1941 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39292  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1942 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39293  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1943 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39294  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1944 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 0E2P26\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39295  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1945 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39296  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1946 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39297  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1947 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39298  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1948 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39299  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1949 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39300  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1950 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39301  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1951 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39302  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1952 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39303  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1953 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39304  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1954 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: GMK2E1\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39305  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1955 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39306  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1956 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39307  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1957 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39308  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1958 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39309  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1959 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39310  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1960 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39311  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1961 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39312  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1962 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39313  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1963 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39314  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1964 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ZRQ1WU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39315  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1965 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39316  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1966 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39317  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1967 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39318  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1968 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39319  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1969 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39320  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1970 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39321  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1971 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39322  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1972 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39323  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1973 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39324  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1974 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: FTB5AQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39325  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1975 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39326  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1976 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39327  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1977 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39328  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1978 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39329  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1979 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39330  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1980 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39331  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1981 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39332  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1982 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39333  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1983 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39334  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1984 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: MZY1YC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39335  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1985 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39336  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1986 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39337  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1987 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39338  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1988 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39339  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1989 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39340  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1990 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39341  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1991 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39342  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1992 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39343  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1993 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39344  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1994 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3WIRUB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39345  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1995 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39346  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1996 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39347  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1997 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39348  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1998 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39349  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1999 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39350  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2000 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39351  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2001 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39352  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2002 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39353  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2003 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39354  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2004 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Z47ICF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39355  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2005 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39356  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2006 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39357  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2007 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39358  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2008 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39359  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2009 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39360  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2010 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39361  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2011 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39362  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2012 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39363  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2013 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39364  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2014 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WXAEMH\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39365  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2015 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39366  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2016 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39367  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2017 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39368  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2018 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39369  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2019 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39370  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2020 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39371  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2021 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39372  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2022 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39373  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2023 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39374  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2024 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 84CUBU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39375  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2025 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39376  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2026 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39377  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2027 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39378  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2028 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39379  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2029 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39380  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2030 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39381  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2031 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39382  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2032 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39383  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2033 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39384  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2034 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ZIR0JJ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39385  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2035 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39386  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2036 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39387  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2037 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39388  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2038 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39389  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2039 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39390  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2040 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39391  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2041 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39392  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2042 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39393  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2043 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39394  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2044 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: ZT6DKI\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39395  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2045 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39396  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2046 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39397  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2047 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39398  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2048 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39399  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2049 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39400  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2050 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39401  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2051 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39402  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2052 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39403  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2053 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39404  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2054 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: I4C7C9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39405  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2055 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39406  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2056 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39407  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2057 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39408  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2058 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39409  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2059 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39410  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2060 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39411  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2061 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39412  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2062 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39413  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2063 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39414  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2064 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: YLWFF9\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39415  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2065 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39416  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2066 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39417  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2067 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39418  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2068 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39419  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2069 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39420  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2070 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39421  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2071 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39422  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2072 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39423  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2073 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39424  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2074 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LQMQUQ\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39425  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2075 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39426  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2076 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39427  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2077 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39428  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2078 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39429  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2079 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39430  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2080 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39431  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2081 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39432  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2082 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39433  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2083 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39434  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2084 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: Q73J29\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39435  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2085 | loss: 0.00000 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39436  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2086 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39437  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2087 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39438  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2088 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39439  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2089 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39440  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2090 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39441  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2091 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39442  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2092 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39443  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2093 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39444  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2094 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: JCL6CU\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39445  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2095 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39446  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2096 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39447  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2097 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39448  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2098 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39449  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2099 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39450  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2100 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39451  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2101 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39452  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2102 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39453  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2103 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39454  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2104 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: EM3P37\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39455  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2105 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39456  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2106 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39457  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2107 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39458  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2108 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39459  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2109 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39460  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2110 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39461  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2111 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39462  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2112 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39463  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2113 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39464  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2114 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: KVI49D\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39465  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2115 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39466  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2116 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39467  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2117 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39468  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2118 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39469  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2119 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39470  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2120 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39471  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2121 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39472  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2122 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39473  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2123 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39474  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2124 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 8F7VAF\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39475  | total loss: \u001b[1m\u001b[32m0.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2125 | loss: 0.00001 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39476  | total loss: \u001b[1m\u001b[32m0.00025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2126 | loss: 0.00025 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39477  | total loss: \u001b[1m\u001b[32m0.00036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2127 | loss: 0.00036 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39478  | total loss: \u001b[1m\u001b[32m0.00041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2128 | loss: 0.00041 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39479  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2129 | loss: 0.00044 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39480  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2130 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39481  | total loss: \u001b[1m\u001b[32m0.00047\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2131 | loss: 0.00047 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39482  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2132 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39483  | total loss: \u001b[1m\u001b[32m0.00046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2133 | loss: 0.00046 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39484  | total loss: \u001b[1m\u001b[32m0.00045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2134 | loss: 0.00045 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: G1W2VY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39485  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2135 | loss: 0.00044 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39486  | total loss: \u001b[1m\u001b[32m0.00039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2136 | loss: 0.00039 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39487  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2137 | loss: 0.00035 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39488  | total loss: \u001b[1m\u001b[32m0.00032\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2138 | loss: 0.00032 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39489  | total loss: \u001b[1m\u001b[32m0.00029\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2139 | loss: 0.00029 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39490  | total loss: \u001b[1m\u001b[32m0.00026\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2140 | loss: 0.00026 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39491  | total loss: \u001b[1m\u001b[32m0.00023\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2141 | loss: 0.00023 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39492  | total loss: \u001b[1m\u001b[32m0.00021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2142 | loss: 0.00021 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39493  | total loss: \u001b[1m\u001b[32m0.00019\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2143 | loss: 0.00019 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39494  | total loss: \u001b[1m\u001b[32m0.00017\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2144 | loss: 0.00017 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 6XHIUB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39495  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2145 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39496  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2146 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39497  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2147 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39498  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2148 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39499  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2149 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39500  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2150 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39501  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2151 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39502  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2152 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39503  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2153 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39504  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2154 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: LIBVMC\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39505  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2155 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39506  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2156 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39507  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2157 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39508  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2158 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39509  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2159 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39510  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2160 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39511  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2161 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39512  | total loss: \u001b[1m\u001b[32m0.00003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2162 | loss: 0.00003 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39513  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2163 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39514  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2164 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 0DTYDK\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39515  | total loss: \u001b[1m\u001b[32m0.00002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2165 | loss: 0.00002 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39516  | total loss: \u001b[1m\u001b[32m0.00226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2166 | loss: 0.00226 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39517  | total loss: \u001b[1m\u001b[32m0.00204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2167 | loss: 0.00204 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39518  | total loss: \u001b[1m\u001b[32m0.00184\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2168 | loss: 0.00184 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39519  | total loss: \u001b[1m\u001b[32m0.00165\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2169 | loss: 0.00165 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39520  | total loss: \u001b[1m\u001b[32m0.00149\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2170 | loss: 0.00149 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39521  | total loss: \u001b[1m\u001b[32m0.00135\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2171 | loss: 0.00135 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39522  | total loss: \u001b[1m\u001b[32m0.00122\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2172 | loss: 0.00122 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39523  | total loss: \u001b[1m\u001b[32m0.00110\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2173 | loss: 0.00110 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39524  | total loss: \u001b[1m\u001b[32m0.00099\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2174 | loss: 0.00099 -- iter: 1/1\n",
      "--\n",
      "[ 1.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: WE0D2W\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39525  | total loss: \u001b[1m\u001b[32m0.00089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2175 | loss: 0.00089 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39526  | total loss: \u001b[1m\u001b[32m0.00081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2176 | loss: 0.00081 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39527  | total loss: \u001b[1m\u001b[32m0.00073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2177 | loss: 0.00073 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39528  | total loss: \u001b[1m\u001b[32m0.00066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2178 | loss: 0.00066 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39529  | total loss: \u001b[1m\u001b[32m0.00060\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2179 | loss: 0.00060 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39530  | total loss: \u001b[1m\u001b[32m0.00054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2180 | loss: 0.00054 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39531  | total loss: \u001b[1m\u001b[32m0.00049\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2181 | loss: 0.00049 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39532  | total loss: \u001b[1m\u001b[32m0.00044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2182 | loss: 0.00044 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39533  | total loss: \u001b[1m\u001b[32m0.00040\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2183 | loss: 0.00040 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39534  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2184 | loss: 0.00037 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: QT30LB\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39535  | total loss: \u001b[1m\u001b[32m0.00033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2185 | loss: 0.00033 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39536  | total loss: \u001b[1m\u001b[32m0.00030\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2186 | loss: 0.00030 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39537  | total loss: \u001b[1m\u001b[32m0.00027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2187 | loss: 0.00027 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39538  | total loss: \u001b[1m\u001b[32m0.00024\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2188 | loss: 0.00024 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39539  | total loss: \u001b[1m\u001b[32m0.00022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2189 | loss: 0.00022 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39540  | total loss: \u001b[1m\u001b[32m0.00020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2190 | loss: 0.00020 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39541  | total loss: \u001b[1m\u001b[32m0.00018\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2191 | loss: 0.00018 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39542  | total loss: \u001b[1m\u001b[32m0.00016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2192 | loss: 0.00016 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39543  | total loss: \u001b[1m\u001b[32m0.00015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2193 | loss: 0.00015 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39544  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2194 | loss: 0.00014 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: 3QMYEW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39545  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2195 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39546  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2196 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39547  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2197 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39548  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2198 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39549  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2199 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39550  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2200 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39551  | total loss: \u001b[1m\u001b[32m0.00007\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2201 | loss: 0.00007 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39552  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2202 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39553  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2203 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39554  | total loss: \u001b[1m\u001b[32m0.00005\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2204 | loss: 0.00005 -- iter: 1/1\n",
      "--\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "---------------------------------\n",
      "Run id: GHBWBL\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "---------------------------------\n",
      "Training samples: 1\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 39555  | total loss: \u001b[1m\u001b[32m0.00004\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2205 | loss: 0.00004 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39556  | total loss: \u001b[1m\u001b[32m0.00006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2206 | loss: 0.00006 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39557  | total loss: \u001b[1m\u001b[32m0.00008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2207 | loss: 0.00008 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39558  | total loss: \u001b[1m\u001b[32m0.00009\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2208 | loss: 0.00009 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39559  | total loss: \u001b[1m\u001b[32m0.00010\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2209 | loss: 0.00010 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39560  | total loss: \u001b[1m\u001b[32m0.00011\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2210 | loss: 0.00011 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39561  | total loss: \u001b[1m\u001b[32m0.00012\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2211 | loss: 0.00012 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39562  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2212 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39563  | total loss: \u001b[1m\u001b[32m0.00013\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2213 | loss: 0.00013 -- iter: 1/1\n",
      "--\n",
      "Training Step: 39564  | total loss: \u001b[1m\u001b[32m0.00014\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2214 | loss: 0.00014 -- iter: 1/1\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for sentence in jjdata:\n",
    "  print(text_to_vector(sentence))\n",
    "  print(0.)\n",
    "  model.fit([text_to_vector(sentence)], to_categorical([1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/donald/Programming/Python/Quill-NLP-Tools-and-Datasets/model2.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./model2.tfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
